<div class="container">

<table style="width: 100%;"><tr>
<td>show_best</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Investigate best tuning parameters</h2>

<h3>Description</h3>

<p><code>show_best()</code> displays the top sub-models and their performance estimates.
</p>
<p><code>select_best()</code> finds the tuning parameter combination with the best
performance values.
</p>
<p><code>select_by_one_std_err()</code> uses the "one-standard error rule" (Breiman _el
at, 1984) that selects the most simple model that is within one standard
error of the numerically optimal results.
</p>
<p><code>select_by_pct_loss()</code> selects the most simple model whose loss of
performance is within some acceptable limit.
</p>


<h3>Usage</h3>

<pre><code class="language-R">show_best(x, ...)

## Default S3 method:
show_best(x, ...)

## S3 method for class 'tune_results'
show_best(
  x,
  ...,
  metric = NULL,
  eval_time = NULL,
  n = 5,
  call = rlang::current_env()
)

select_best(x, ...)

## Default S3 method:
select_best(x, ...)

## S3 method for class 'tune_results'
select_best(x, ..., metric = NULL, eval_time = NULL)

select_by_pct_loss(x, ...)

## Default S3 method:
select_by_pct_loss(x, ...)

## S3 method for class 'tune_results'
select_by_pct_loss(x, ..., metric = NULL, eval_time = NULL, limit = 2)

select_by_one_std_err(x, ...)

## Default S3 method:
select_by_one_std_err(x, ...)

## S3 method for class 'tune_results'
select_by_one_std_err(x, ..., metric = NULL, eval_time = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>The results of <code>tune_grid()</code> or <code>tune_bayes()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>For <code>select_by_one_std_err()</code> and <code>select_by_pct_loss()</code>, this
argument is passed directly to <code>dplyr::arrange()</code> so that the user can sort
the models from <em>most simple to most complex</em>. That is, for a parameter <code>p</code>,
pass the unquoted expression <code>p</code> if smaller values of <code>p</code> indicate a simpler
model, or <code>desc(p)</code> if larger values indicate a simpler model. At
least one term is required for these two functions. See the examples below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metric</code></td>
<td>
<p>A character value for the metric that will be used to sort
the models. (See
<a href="https://yardstick.tidymodels.org/articles/metric-types.html">https://yardstick.tidymodels.org/articles/metric-types.html</a> for
more details). Not required if a single metric exists in <code>x</code>. If there are
multiple metric and none are given, the first in the metric set is used (and
a warning is issued).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eval_time</code></td>
<td>
<p>A single numeric time point where dynamic event time
metrics should be chosen (e.g., the time-dependent ROC curve, etc). The
values should be consistent with the values used to create <code>x</code>. The <code>NULL</code>
default will automatically use the first evaluation time used by <code>x</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>An integer for the number of top results/rows to return.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>The call to be shown in errors and warnings.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>limit</code></td>
<td>
<p>The limit of loss of performance that is acceptable (in percent
units). See details below.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>For percent loss, suppose the best model has an RMSE of 0.75 and a simpler
model has an RMSE of 1. The percent loss would be <code>(1.00 - 0.75)/1.00 * 100</code>,
or 25 percent. Note that loss will always be non-negative.
</p>


<h3>Value</h3>

<p>A tibble with columns for the parameters. <code>show_best()</code> also
includes columns for performance metrics.
</p>


<h3>References</h3>

<p>Breiman, Leo; Friedman, J. H.; Olshen, R. A.; Stone, C. J. (1984).
<em>Classification and Regression Trees.</em> Monterey, CA: Wadsworth.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data("example_ames_knn")

show_best(ames_iter_search, metric = "rmse")

select_best(ames_iter_search, metric = "rsq")

# To find the least complex model within one std error of the numerically
# optimal model, the number of nearest neighbors are sorted from the largest
# number of neighbors (the least complex class boundary) to the smallest
# (corresponding to the most complex model).

select_by_one_std_err(ames_grid_search, metric = "rmse", desc(K))

# Now find the least complex model that has no more than a 5% loss of RMSE:
select_by_pct_loss(
  ames_grid_search,
  metric = "rmse",
  limit = 5, desc(K)
)

</code></pre>


</div>