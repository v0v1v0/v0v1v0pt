<div class="container">

<table style="width: 100%;"><tr>
<td>mbo_tramnet</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Model based optimization for regularized transformation models</h2>

<h3>Description</h3>

<p>Uses model based optimization to find the optimal tuning parameter(s)
in a regularized transformation model based on cross-validated log-likelihoods.
Here the tramnet package makes use of the mlrMBO interface for Bayesian
Optimization in machine learning problems to maximize the cv-logLik
as a black-box function of the tuning parameters alpha and lambda.
</p>


<h3>Usage</h3>

<pre><code class="language-R">mbo_tramnet(object, fold = 2, n_design = 5, n_iter = 5,
  minlambda = 0, maxlambda = 16, minalpha = 0, maxalpha = 1,
  folds = NULL, learner = "regr.km", pred.type = "se",
  opt_crit = makeMBOInfillCritEI(), noisy = FALSE,
  obj_type = c("lasso", "ridge", "elnet"), verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>object of class <code>tramnet</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fold</code></td>
<td>
<p>fold for cross validation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_design</code></td>
<td>
<p>results in <code>n_design</code> times the number of tuning parameters
rows for the initial design matrix based on a random latin hypercube design</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_iter</code></td>
<td>
<p>number of iterations in the model based optimization procedure</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>minlambda</code></td>
<td>
<p>minimum value for lambda (default: <code>0</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxlambda</code></td>
<td>
<p>maximum value for lambda (default: <code>16</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>minalpha</code></td>
<td>
<p>minimum value for alpha (default: <code>0</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxalpha</code></td>
<td>
<p>maximum value for alpha (default: <code>1</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>folds</code></td>
<td>
<p>self specified folds for cross validation (mainly for reproducibility
and comparability purposes)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>learner</code></td>
<td>
<p>type of leaner used for the optimization (default: <code>"regr.km"</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pred.type</code></td>
<td>
<p>prediction type of the learner (default: <code>"se"</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>opt_crit</code></td>
<td>
<p>optimization criterion, default: expected improvement</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>noisy</code></td>
<td>
<p>indicates whether folds for k-fold cross-validation should
be random for each iteration, leading to a noisy objective function
(default: <code>FALSE</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>obj_type</code></td>
<td>
<p>objective type, one of <code>"lasso"</code>, <code>"ridge"</code> or <code>"elnet"</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>toggle for a verbose output (default: <code>TRUE</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments are ignored</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>returns an object of class <code>"MBOSingleObjResult"</code> which is
documented in <code>mbo</code>
</p>


</div>