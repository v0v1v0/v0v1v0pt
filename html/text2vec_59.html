<div class="container">

<table style="width: 100%;"><tr>
<td>TfIdf</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>TfIdf</h2>

<h3>Description</h3>

<p>Creates TfIdf(Latent semantic analysis) model.
"smooth" IDF (default) is defined as follows: <code>idf = log(1 + (# documents in the corpus) / (# documents where the term appears) )</code>
"non-smooth" IDF is defined as follows: <code>idf = log((# documents in the corpus) / (# documents where the term appears) )</code>
</p>


<h3>Usage</h3>

<pre><code class="language-R">TfIdf
</code></pre>


<h3>Format</h3>

<p><code>R6Class</code> object.</p>


<h3>Details</h3>

<p>Term Frequency Inverse Document Frequency
</p>


<h3>Usage</h3>

<p>For usage details see <b>Methods, Arguments and Examples</b> sections.
</p>
<pre>
tfidf = TfIdf$new(smooth_idf = TRUE, norm = c('l1', 'l2', 'none'), sublinear_tf = FALSE)
tfidf$fit_transform(x)
tfidf$transform(x)
</pre>


<h3>Methods</h3>


<dl>
<dt><code>$new(smooth_idf = TRUE, norm = c("l1", "l2", "none"), sublinear_tf = FALSE)</code></dt>
<dd>
<p>Creates tf-idf model</p>
</dd>
<dt><code>$fit_transform(x)</code></dt>
<dd>
<p>fit model to an input sparse matrix (preferably in "dgCMatrix"
format) and then transforms it.</p>
</dd>
<dt><code>$transform(x)</code></dt>
<dd>
<p>transform new data <code>x</code> using tf-idf from train data</p>
</dd>
</dl>
<h3>Arguments</h3>


<dl>
<dt>tfidf</dt>
<dd>
<p>A <code>TfIdf</code> object</p>
</dd>
<dt>x</dt>
<dd>
<p>An input term-co-occurence matrix. Preferably in <code>dgCMatrix</code> format</p>
</dd>
<dt>smooth_idf</dt>
<dd>
<p><code>TRUE</code> smooth IDF weights by adding one to document
frequencies, as if an extra document was seen containing every term in the
collection exactly once.</p>
</dd>
<dt>norm</dt>
<dd>
<p><code>c("l1", "l2", "none")</code> Type of normalization to apply to term vectors.
<code>"l1"</code> by default, i.e., scale by the number of words in the document. </p>
</dd>
<dt>sublinear_tf</dt>
<dd>
<p><code>FALSE</code> Apply sublinear term-frequency scaling, i.e.,
replace the term frequency with <code>1 + log(TF)</code></p>
</dd>
</dl>
<h3>Examples</h3>

<pre><code class="language-R">data("movie_review")
N = 100
tokens = word_tokenizer(tolower(movie_review$review[1:N]))
dtm = create_dtm(itoken(tokens), hash_vectorizer())
model_tfidf = TfIdf$new()
dtm_tfidf = model_tfidf$fit_transform(dtm)
</code></pre>


</div>