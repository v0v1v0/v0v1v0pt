<div class="container">

<table style="width: 100%;"><tr>
<td>torch_randperm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Randperm</h2>

<h3>Description</h3>

<p>Randperm
</p>


<h3>Usage</h3>

<pre><code class="language-R">torch_randperm(
  n,
  dtype = torch_int64(),
  layout = NULL,
  device = NULL,
  requires_grad = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>(int) the upper bound (exclusive)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dtype</code></td>
<td>
<p>(<code>torch.dtype</code>, optional) the desired data type of returned tensor.        Default: <code>torch_int64</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>layout</code></td>
<td>
<p>(<code>torch.layout</code>, optional) the desired layout of returned Tensor.        Default: <code>torch_strided</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>device</code></td>
<td>
<p>(<code>torch.device</code>, optional) the desired device of returned tensor.        Default: if <code>NULL</code>, uses the current device for the default tensor type        (see <code>torch_set_default_tensor_type</code>). <code>device</code> will be the CPU        for CPU tensor types and the current CUDA device for CUDA tensor types.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>requires_grad</code></td>
<td>
<p>(bool, optional) If autograd should record operations on the        returned tensor. Default: <code>FALSE</code>.</p>
</td>
</tr>
</table>
<h3>randperm(n, out=NULL, dtype=torch.int64, layout=torch.strided, device=NULL, requires_grad=False) -&gt; LongTensor </h3>

<p>Returns a random permutation of integers from <code>0</code> to <code>n - 1</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">if (torch_is_installed()) {

torch_randperm(4)
}
</code></pre>


</div>