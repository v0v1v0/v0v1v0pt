<div class="container">

<table style="width: 100%;"><tr>
<td>util</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Preprocessing of Text Documents</h2>

<h3>Description</h3>

<p>Functions for common preprocessing tasks of text documents,
</p>


<h3>Usage</h3>

<pre><code class="language-R">tokenize(x, lines = FALSE, eol = "\n")
remove_stopwords(x, words, lines = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a vector of character.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eol</code></td>
<td>
<p>the end-of-line character to use.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>words</code></td>
<td>
<p>a vector of character (tokens).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lines</code></td>
<td>
<p>assume the components are lines of text.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>tokenize</code> is a simple regular expression based parser that
splits the components of a vector of character into tokens while
protecting infix punctuation. If <code>lines = TRUE</code> assume <code>x</code>
was imported with <code>readLines</code> and end-of-line markers need to be
added back to the components.
</p>
<p><code>remove_stopwords</code> removes the tokens given in <code>words</code> from
<code>x</code>. If <code>lines = FALSE</code> assumes the components of both
vectors contain tokens which can be compared using <code>match</code>.
Otherwise, assumes the tokens in <code>x</code> are delimited by word
boundaries (including infix punctuation) and uses regular expression
matching.
</p>


<h3>Value</h3>

<p>The same type of object as <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>Christian Buchta</p>


<h3>Examples</h3>

<pre><code class="language-R">txt &lt;- "\"It's almost noon,\" it@dot.net said."
## split
x &lt;- tokenize(txt)
x
## reconstruct
t &lt;- paste(x, collapse = "")
t

if (require("tm", quietly = TRUE)) {
    words &lt;- readLines(system.file("stopwords", "english.dat",
                       package = "tm"))
    remove_stopwords(x, words)
    remove_stopwords(t, words, lines = TRUE)
} else
    remove_stopwords(t, words = c("it", "it's"), lines = TRUE)
</code></pre>


</div>