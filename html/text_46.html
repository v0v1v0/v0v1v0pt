<div class="container">

<table style="width: 100%;"><tr>
<td>textTokenize</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Tokenize according to different huggingface transformers</h2>

<h3>Description</h3>

<p>Tokenize according to different huggingface transformers
</p>


<h3>Usage</h3>

<pre><code class="language-R">textTokenize(
  texts,
  model = "bert-base-uncased",
  max_token_to_sentence = 4,
  device = "cpu",
  tokenizer_parallelism = FALSE,
  model_max_length = NULL,
  logging_level = "error"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>texts</code></td>
<td>
<p>A character variable or a tibble/dataframe with at least one character variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>Character string specifying pre-trained language model (default 'bert-base-uncased').
For full list of options see pretrained models at
<a href="https://huggingface.co/transformers/pretrained_models.html">HuggingFace</a>.
For example use "bert-base-multilingual-cased", "openai-gpt",
"gpt2", "ctrl", "transfo-xl-wt103", "xlnet-base-cased", "xlm-mlm-enfr-1024", "distilbert-base-cased",
"roberta-base", or "xlm-roberta-base".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_token_to_sentence</code></td>
<td>
<p>(numeric) Maximum number of tokens in a string to handle before
switching to embedding text sentence by sentence.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>device</code></td>
<td>
<p>Name of device to use: 'cpu', 'gpu', 'gpu:k' or 'mps'/'mps:k' for MacOS, where k is a
specific device number.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tokenizer_parallelism</code></td>
<td>
<p>If TRUE this will turn on tokenizer parallelism. Default FALSE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model_max_length</code></td>
<td>
<p>The maximum length (in number of tokens) for the inputs to the transformer model
(default the value stored for the associated model).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logging_level</code></td>
<td>
<p>Set the logging level. Default: "warning".
Options (ordered from less logging to more logging): critical, error, warning, info, debug</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Returns tokens according to specified huggingface transformer.
</p>


<h3>See Also</h3>

<p>see <code>textEmbed</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# tokens &lt;- textTokenize("hello are you?")

</code></pre>


</div>