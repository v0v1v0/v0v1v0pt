<div class="container">

<table style="width: 100%;"><tr>
<td>eval_tree</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Print decision tree performance according to different metrics.</h2>

<h3>Description</h3>

<p>Print decision tree performance according to different metrics.
</p>


<h3>Usage</h3>

<pre><code class="language-R">eval_tree(
  dat,
  target_lab = colnames(dat)[1],
  task = c("classification", "regression"),
  metrics = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>dat</code></td>
<td>
<p>Dataframe with truths (column 'target_lab') and estimates (column 'y_hat')
of samples from original dataset.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>target_lab</code></td>
<td>
<p>Name of the column in data that contains target/label information.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>task</code></td>
<td>
<p>Character string indicating the type of problem,
either 'classification' (categorical outcome) or 'regression' (continuous outcome).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metrics</code></td>
<td>
<p>A set of metric functions to evaluate decision tree,
defaults to common metrics for classification/regression problems.
Can be defined with 'yardstick::metric_set'.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Character string of the decision tree evaluation.
</p>


<h3>Examples</h3>

<pre><code class="language-R">eval_tree(compute_tree(penguins, target_lab = 'species')$dat)

</code></pre>


</div>