<div class="container">

<table style="width: 100%;"><tr>
<td>tNSS.SD</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
NSS-SD Method for Tensor-Valued Time Series
</h2>

<h3>Description</h3>

<p>Estimates the non-stationary sources of a tensor-valued time series using separation information contained in two time intervals.
</p>


<h3>Usage</h3>

<pre><code class="language-R">tNSS.SD(x, n.cuts = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Numeric array of an order at least two. It is assumed that the last dimension corresponds to the sampling units.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.cuts</code></td>
<td>
<p>Either a 3-vector of interval cutoffs (the cutoffs are used to define the two intervals that are open below and closed above, e.g. <code class="reqn">(a, b]</code>) or <code>NULL</code> (the time range is sliced into two parts of equal size).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Assume that the observed tensor-valued time series comes from a tensorial BSS model where the sources have constant means over time but the component variances change in time. Then TNSS-SD estimates the non-stationary sources by dividing the time scale into two intervals and jointly diagonalizing the covariance matrices of the two intervals within each mode.
</p>


<h3>Value</h3>

<p>A list with class 'tbss', inheriting from class 'bss', containing the following components: 
</p>
<table>
<tr style="vertical-align: top;">
<td><code>S</code></td>
<td>
<p>Array of the same size as x containing the independent components.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>W</code></td>
<td>
<p>List containing all the unmixing matrices.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>EV</code></td>
<td>
<p>Eigenvalues obtained from the joint diagonalization.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.cuts</code></td>
<td>
<p>The interval cutoffs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xmu</code></td>
<td>
<p>The data location.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>datatype</code></td>
<td>
<p>Character string with value "ts". Relevant for <code>plot.tbss</code>.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Joni Virta
</p>


<h3>References</h3>

<p><cite>Virta J., Nordhausen K. (2017): Blind source separation for nonstationary tensor-valued time series, 2017 IEEE 27th International Workshop on Machine Learning for Signal Processing (MLSP), <a href="https://doi.org/10.1109/MLSP.2017.8168122">doi:10.1109/MLSP.2017.8168122</a></cite>
</p>


<h3>See Also</h3>

<p><code>NSS.SD</code>, <code>NSS.JD</code>, <code>NSS.TD.JD</code>, <code>tNSS.JD</code>, <code>tNSS.TD.JD</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Create innovation series with block-wise changing variances

# 9 smooth variance structures
var_1 &lt;- function(n){
  t &lt;- 1:n
  return(1 + cos((2*pi*t)/n)*sin((2*150*t)/(n*pi)))
}

var_2 &lt;- function(n){
  t &lt;- 1:n
  return(1 + sin((2*pi*t)/n)*cos((2*150*t)/(n*pi)))
}

var_3 &lt;- function(n){
  t &lt;- 1:n
  return(0.5 + 8*exp((n+1)^2/(4*t*(t - n - 1))))
}

var_4 &lt;- function(n){
  t &lt;- 1:n
  return(3.443 - 8*exp((n+1)^2/(4*t*(t - n - 1))))
}

var_5 &lt;- function(n){
  t &lt;- 1:n
  return(0.5 + 0.5*gamma(10)/(gamma(7)*gamma(3))*(t/(n + 1))^(7 - 1)*(1 - t/(n + 1))^(3 - 1))
}

var_6 &lt;- function(n){
  t &lt;- 1:n
  res &lt;- var_5(n)
  return(rev(res))
}

var_7 &lt;- function(n){
  t &lt;- 1:n
  return(0.2+2*t/(n + 1))
}

var_8 &lt;- function(n){
  t &lt;- 1:n
  return(0.2+2*(n + 1 - t)/(n + 1))
}

var_9 &lt;- function(n){
  t &lt;- 1:n
  return(1.5 + cos(4*pi*t/n))
}


# Innovation series
n &lt;- 1000

innov1 &lt;- c(rnorm(n, 0, sqrt(var_1(n))))
innov2 &lt;- c(rnorm(n, 0, sqrt(var_2(n))))
innov3 &lt;- c(rnorm(n, 0, sqrt(var_3(n))))
innov4 &lt;- c(rnorm(n, 0, sqrt(var_4(n))))
innov5 &lt;- c(rnorm(n, 0, sqrt(var_5(n))))
innov6 &lt;- c(rnorm(n, 0, sqrt(var_6(n))))
innov7 &lt;- c(rnorm(n, 0, sqrt(var_7(n))))
innov8 &lt;- c(rnorm(n, 0, sqrt(var_8(n))))
innov9 &lt;- c(rnorm(n, 0, sqrt(var_9(n))))

# Generate the observations
vecx &lt;- cbind(as.vector(arima.sim(n = n, list(ar = 0.9), innov = innov1)),
              as.vector(arima.sim(n = n, list(ar = c(0, 0.2, 0.1, -0.1, 0.7)), 
              innov = innov2)),
              as.vector(arima.sim(n = n, list(ar = c(0.5, 0.3, -0.2, 0.1)), 
              innov = innov3)),
              as.vector(arima.sim(n = n, list(ma = -0.5), innov = innov4)),
              as.vector(arima.sim(n = n, list(ma = c(0.1, 0.1, 0.3, 0.5, 0.8)), 
              innov = innov5)),
              as.vector(arima.sim(n = n, list(ma = c(0.5, -0.5, 0.5)), innov = innov6)),
              as.vector(arima.sim(n = n, list(ar = c(-0.5, -0.3), ma = c(-0.2, 0.1)), 
              innov = innov7)),
              as.vector(arima.sim(n = n, list(ar = c(0, -0.1, -0.2, 0.5), ma = c(0, 0.1, 0.1, 0.6)),
              innov = innov8)),
              as.vector(arima.sim(n = n, list(ar = c(0.8), ma = c(0.7, 0.6, 0.5, 0.1)),
              innov = innov9)))


# Vector to tensor
tenx &lt;- t(vecx)
dim(tenx) &lt;- c(3, 3, n)


# Run TNSS-SD
res &lt;- tNSS.SD(tenx)
res$W
</code></pre>


</div>