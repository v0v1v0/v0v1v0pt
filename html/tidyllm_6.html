<div class="container">

<table style="width: 100%;"><tr>
<td>groq</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Call the Groq API to interact with fast opensource models on Groq</h2>

<h3>Description</h3>

<p>Call the Groq API to interact with fast opensource models on Groq
</p>


<h3>Usage</h3>

<pre><code class="language-R">groq(
  .llm,
  .model = "llama-3.2-90b-text-preview",
  .max_tokens = 1024,
  .temperature = NULL,
  .top_p = NULL,
  .frequency_penalty = NULL,
  .presence_penalty = NULL,
  .api_url = "https://api.groq.com/",
  .timeout = 60,
  .verbose = FALSE,
  .wait = TRUE,
  .min_tokens_reset = 0L
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>.llm</code></td>
<td>
<p>An existing LLMMessage object or an initial text prompt.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.model</code></td>
<td>
<p>The model identifier (default: "llama-3.2-90b-text-preview").</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.max_tokens</code></td>
<td>
<p>The maximum number of tokens to generate (default: 1024).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.temperature</code></td>
<td>
<p>Control for randomness in response generation (optional).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.top_p</code></td>
<td>
<p>Nucleus sampling parameter (optional).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.frequency_penalty</code></td>
<td>
<p>Controls repetition frequency (optional).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.presence_penalty</code></td>
<td>
<p>Controls how much to penalize repeating content (optional)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.api_url</code></td>
<td>
<p>Base URL for the API (default: "https://api.anthropic.com/v1/messages").</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.timeout</code></td>
<td>
<p>Request timeout in seconds (default: 60).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.verbose</code></td>
<td>
<p>Should additional information be shown after the API call</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.wait</code></td>
<td>
<p>Should we wait for rate limits if necessary?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.min_tokens_reset</code></td>
<td>
<p>How many tokens should be remaining to wait until we wait for token reset?</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Returns an updated LLMMessage object.
</p>


</div>