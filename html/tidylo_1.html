<div class="container">

<table style="width: 100%;"><tr>
<td>bind_log_odds</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Bind the weighted log odds to a tidy dataset</h2>

<h3>Description</h3>

<p>Calculate and bind posterior log odds ratios, assuming a
multinomial model with a Dirichlet prior. The Dirichlet prior
parameters are set using an empirical Bayes approach by default,
but an uninformative prior is also available. Assumes that data
is in a tidy format, and adds the weighted log odds ratio
as a column. Supports non-standard evaluation through the
tidyeval framework.
</p>


<h3>Usage</h3>

<pre><code class="language-R">bind_log_odds(tbl, set, feature, n, uninformative = FALSE, unweighted = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>tbl</code></td>
<td>
<p>A tidy dataset with one row per <code>feature</code> and <code>set</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>set</code></td>
<td>
<p>Column of sets between which to compare features, such as
documents for text data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>feature</code></td>
<td>
<p>Column of features for identifying differences, such as words
or bigrams with text data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>Column containing feature-set counts.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>uninformative</code></td>
<td>
<p>Whether or not to use an uninformative Dirichlet
prior. Defaults to <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>unweighted</code></td>
<td>
<p>Whether or not to return the unweighted log odds,
in addition to the weighted log odds. Defaults to <code>FALSE</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The arguments <code>set</code>, <code>feature</code>, and <code>n</code>
are passed by expression and support
<code>rlang::quasiquotation</code>; you can unquote strings
and symbols. Grouping is preserved but ignored.
</p>
<p>The default empirical Bayes prior inflates feature counts in each group
by total feature counts across all groups. This is like using a moment
based estimator for the parameters of the Dirichlet prior. Note that
empirical Bayes estimates perform well on average, but can have
some surprising properties. If you are uncomfortable with
empirical Bayes estimates, we suggest using the uninformative prior.
</p>
<p>The weighted log odds computed by this function are also z-scores for the
log odds; this quantity is useful for comparing frequencies across sets but
its relationship to an odds ratio is not straightforward after the weighting.
</p>
<p>The dataset must have exactly one row per set-feature combination for
this calculation to succeed. Read Monroe et al (2008) for
more on the weighted log odds ratio.
</p>


<h3>Value</h3>

<p>The original tidy dataset with up to two additional columns.
</p>

<ul>
<li> <p><code>weighted_log_odds</code>: The weighted posterior log odds ratio, where
the odds ratio is for the feature distribution within that set versus
all other sets. The weighting comes from variance-stabilization
of the posterior.
</p>
</li>
<li> <p><code>log_odds</code> (optional, only returned if requested): The posterior
log odds without variance stabilization.
</p>
</li>
</ul>
<h3>References</h3>


<ol>
<li>
<p> Monroe, B. L., Colaresi, M. P. &amp; Quinn, K. M. Fightin' Words: Lexical Feature Selection and Evaluation for Identifying the Content of Political Conflict. Polit. anal. 16, 372-403 (2008). doi: <a href="https://doi.org/10.1093/pan/mpn018">10.1093/pan/mpn018</a>
</p>
</li>
<li>
<p> Minka, T. P. Estimating a Dirichlet distribution. (2012). <a href="https://tminka.github.io/papers/dirichlet/minka-dirichlet.pdf">https://tminka.github.io/papers/dirichlet/minka-dirichlet.pdf</a>
</p>
</li>
</ol>
<h3>Examples</h3>

<pre><code class="language-R">
library(dplyr)

gear_counts &lt;- mtcars %&gt;%
  count(vs, gear)

gear_counts

# find the number of gears most characteristic of each engine shape `vs`

regularized &lt;- gear_counts %&gt;%
  bind_log_odds(vs, gear, n)

regularized

unregularized &lt;- gear_counts %&gt;%
  bind_log_odds(vs, gear, n, uninformative = TRUE, unweighted = TRUE)

# these log odds will be farther from zero
# than the regularized estimates
unregularized

</code></pre>


</div>