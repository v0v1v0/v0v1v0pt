<div class="container">

<table style="width: 100%;"><tr>
<td>ADE-class</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Arbitrated Dynamic Ensemble</h2>

<h3>Description</h3>

<p>Arbitrated Dynamic Ensemble (ADE) is an ensemble approach
for adaptively combining forecasting models. A metalearning
strategy is used that specializes base models
across the time series. Each meta-learner is specifically
designed to model how apt its base counterpart is to make
a prediction for a given test example. This is accomplished
by analysing how the error incurred by a given learning model
relates to the characteristics of the data. At test time,
the base-learners are weighted according to their degree
of competence in the input observation, estimated by the
predictions of the meta-learners.
</p>


<h3>Slots</h3>


<dl>
<dt><code>base_ensemble</code></dt>
<dd>
<p>object of class <code>base_ensemble-class</code>.
It contains the base models used that can be used for predicting
new data or forecasting future values;</p>
</dd>
<dt><code>meta_model</code></dt>
<dd>
<p>a list containing the meta models, one for
each base model. The meta-models are random forests;</p>
</dd>
<dt><code>form</code></dt>
<dd>
<p>formula;</p>
</dd>
<dt><code>specs</code></dt>
<dd>
<p>object of class <code>model_specs-class</code>. Contains
the parameter setting information for training the
base models;</p>
</dd>
<dt><code>lambda</code></dt>
<dd>
<p>window size. Number of observations to compute
the recent performance of the base models, according to the
committee ratio <strong>omega</strong>. Essentially, the top <em>omega</em>
models are selected and weighted at each prediction instance, according
to their performance in the last <em>lambda</em> observations.
Defaults to 50 according to empirical experiments;</p>
</dd>
<dt><code>omega</code></dt>
<dd>
<p>committee ratio size. Essentially, the top <em>omega</em> * 100
percent of models are selected and weighted at each prediction instance, according
to their performance in the last <em>lambda</em> observations.
Defaults to .5 according to empirical experiments;</p>
</dd>
<dt><code>select_best</code></dt>
<dd>
<p>Logical. If true, at each prediction time,
a single base model is picked to make a prediction. The picked
model is the one that has the lowest loss prediction from
the meta models. Defaults to FALSE;</p>
</dd>
<dt><code>all_models</code></dt>
<dd>
<p>Logical. If true, at each prediction time,
all base models are picked to make a prediction. The
models are weighted according to their predicted loss
and the <code>aggregation</code> function. Defaults to FALSE;</p>
</dd>
<dt><code>aggregation</code></dt>
<dd>
<p>Type of aggregation used to combine the
predictions of the base models. The options are:
</p>

<dl>
<dt>softmax</dt>
<dd>
<p>default</p>
</dd>
<dt>erfc</dt>
<dd>
<p>the complementary Gaussian error function</p>
</dd>
<dt>linear</dt>
<dd>
<p>a linear scaling</p>
</dd>
</dl>
</dd>
<dt><code>sequential_reweight</code></dt>
<dd>
<p>Besides ensemble heterogeneity we encourage diversity
explicitly during the aggregation of the output of experts.
This is achieved by taking into account not only predictions
of performance produced by the arbiters, but also the
correlation among experts in a recent window of observations.</p>
</dd>
<dt><code>recent_series</code></dt>
<dd>
<p>the most recent <code>lambda</code> observations.</p>
</dd>
<dt><code>out_of_bag</code></dt>
<dd>
<p>Out of bag observations used to train arbiters.</p>
</dd>
<dt><code>meta_model_type</code></dt>
<dd>
<p>meta model to use – defaults to random forest</p>
</dd>
</dl>
<h3>References</h3>

<p>Cerqueira, Vitor; Torgo, Luis; Pinto, Fabio;
and Soares, Carlos. "Arbitrated Ensemble for Time Series
Forecasting" to appear at: Joint European Conference on Machine Learning and
Knowledge Discovery in Databases. Springer International
Publishing, 2017.
</p>
<p>V. Cerqueira, L. Torgo, and C. Soares, “Arbitrated ensemble for
solar radiation forecasting,” in International Work-Conference on
Artificial Neural Networks. Springer, Cham, 2017, pp. 720–732
</p>


<h3>See Also</h3>

<p><code>model_specs-class</code> for setting up the ensemble parameters
for an <strong>ADE</strong> model;
<code>predict</code> for the method that predicts new held out observations;
<code>update_weights</code> for the method used to update the
weights of an <strong>ADE</strong> model between successive predict or forecast calls;
<code>update_ade_meta</code> for updating (retraining) the meta models
of an <strong>ADE</strong> model; <code>update_base_models</code> for
the updating (retraining) the base models of an <strong>ADE</strong> ensemble (and respective
weights); <code>ade_hat-class</code> for the object that results from
predicting with an <strong>ADE</strong> model; and <code>update_ade</code> to update an ADE
model, combining functions <strong>update_base_models</strong>, <strong>update_meta_ade</strong>, and
<strong>update_weights</strong>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">specs &lt;- model_specs(
  learner = c("bm_ppr", "bm_glm", "bm_mars"),
  learner_pars = list(
    bm_glm = list(alpha = c(0, .5, 1)),
    bm_svr = list(kernel = c("rbfdot", "polydot"),
                  C = c(1, 3)),
    bm_ppr = list(nterms = 4)
  )
)

data("water_consumption")
train &lt;- embed_timeseries(water_consumption, 5)
train &lt;- train[1:300, ] # toy size for checks

model &lt;- ADE(target ~., train, specs)

</code></pre>


</div>