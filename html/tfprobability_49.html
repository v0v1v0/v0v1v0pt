<div class="container">

<table style="width: 100%;"><tr>
<td>mcmc_slice_sampler</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Runs one step of the slice sampler using a hit and run approach</h2>

<h3>Description</h3>

<p>Slice Sampling is a Markov Chain Monte Carlo (MCMC) algorithm based, as stated
by Neal (2003), on the observation that "...one can sample from a
distribution by sampling uniformly from the region under the plot of its
density function. A Markov chain that converges to this uniform distribution
can be constructed by alternately uniform sampling in the vertical direction
with uniform sampling from the horizontal <code>slice</code> defined by the current
vertical position, or more generally, with some update that leaves the uniform
distribution over this slice invariant". Mathematical details and derivations
can be found in Neal (2003). The one dimensional slice sampler is
extended to n-dimensions through use of a hit-and-run approach: choose a
random direction in n-dimensional space and take a step, as determined by the
one-dimensional slice sampling algorithm, along that direction
(Belisle at al. 1993).
</p>


<h3>Usage</h3>

<pre><code class="language-R">mcmc_slice_sampler(
  target_log_prob_fn,
  step_size,
  max_doublings,
  seed = NULL,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>target_log_prob_fn</code></td>
<td>
<p>Function which takes an argument like
<code>current_state</code> (if it's a list <code>current_state</code> will be unpacked) and returns its
(possibly unnormalized) log-density under the target distribution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>step_size</code></td>
<td>
<p><code>Tensor</code> or <code>list</code> of <code>Tensor</code>s representing the step
size for the leapfrog integrator. Must broadcast with the shape of
<code>current_state</code>. Larger step sizes lead to faster progress, but
too-large step sizes make rejection exponentially more likely. When
possible, it's often helpful to match per-variable step sizes to the
standard deviations of the target distribution in each variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_doublings</code></td>
<td>
<p>Scalar positive int32 <code>tf$Tensor</code>. The maximum number of
doublings to consider.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>integer to seed the random number generator.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>string prefixed to Ops created by this function.
Default value: <code>NULL</code> (i.e., 'slice_sampler_kernel').</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The <code>one_step</code> function can update multiple chains in parallel. It assumes
that all leftmost dimensions of <code>current_state</code> index independent chain states
(and are therefore updated independently). The output of
<code style="white-space: pre;">⁠target_log_prob_fn(*current_state)⁠</code> should sum log-probabilities across all
event dimensions. Slices along the rightmost dimensions may have different
target distributions; for example, <code style="white-space: pre;">⁠current_state[0, :]⁠</code> could have a
different target distribution from <code style="white-space: pre;">⁠current_state[1, :]⁠</code>. These semantics are
governed by <code style="white-space: pre;">⁠target_log_prob_fn(*current_state)⁠</code>. (The number of independent
chains is <code style="white-space: pre;">⁠tf$size(target_log_prob_fn(*current_state))⁠</code>.)
</p>
<p>Note that the sampler only supports states where all components have a common
dtype.
</p>


<h3>Value</h3>

<p>list of
<code>next_state</code> (Tensor or Python list of <code>Tensor</code>s representing the state(s)
of the Markov chain(s) at each result step. Has same shape as
and <code>current_state</code>.) and
<code>kernel_results</code> (<code>collections$namedtuple</code> of internal calculations used to
'advance the chain).
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://projecteuclid.org/download/pdf_1/euclid.aos/1056562461">Radford M. Neal. Slice Sampling. The Annals of Statistics. 2003, Vol 31, No. 3 , 705-767.</a>
</p>
</li>
<li>
<p> C.J.P. Belisle, H.E. Romeijn, R.L. Smith. <cite>Hit-and-run algorithms for generating multivariate distributions. Math. Oper. Res., 18(1993), 225-266.</cite>
</p>
</li>
</ul>
<h3>See Also</h3>

<p>Other mcmc_kernels: 
<code>mcmc_dual_averaging_step_size_adaptation()</code>,
<code>mcmc_hamiltonian_monte_carlo()</code>,
<code>mcmc_metropolis_adjusted_langevin_algorithm()</code>,
<code>mcmc_metropolis_hastings()</code>,
<code>mcmc_no_u_turn_sampler()</code>,
<code>mcmc_random_walk_metropolis()</code>,
<code>mcmc_replica_exchange_mc()</code>,
<code>mcmc_simple_step_size_adaptation()</code>,
<code>mcmc_transformed_transition_kernel()</code>,
<code>mcmc_uncalibrated_hamiltonian_monte_carlo()</code>,
<code>mcmc_uncalibrated_langevin()</code>,
<code>mcmc_uncalibrated_random_walk()</code>
</p>


</div>