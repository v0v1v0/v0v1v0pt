<div class="container">

<table style="width: 100%;"><tr>
<td>tfd_linear_gaussian_state_space_model</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Observation distribution from a linear Gaussian state space model</h2>

<h3>Description</h3>

<p>The state space model, sometimes called a Kalman filter, posits a
latent state vector <code>z_t</code> of dimension <code>latent_size</code> that evolves
over time following linear Gaussian transitions,
<code style="white-space: pre;">⁠z_{t+1} = F * z_t + N(b; Q)⁠</code>
for transition matrix <code>F</code>, bias <code>b</code> and covariance matrix
<code>Q</code>. At each timestep, we observe a noisy projection of the
latent state <code style="white-space: pre;">⁠x_t = H * z_t + N(c; R)⁠</code>. The transition and
observation models may be fixed or may vary between timesteps.
</p>


<h3>Usage</h3>

<pre><code class="language-R">tfd_linear_gaussian_state_space_model(
  num_timesteps,
  transition_matrix,
  transition_noise,
  observation_matrix,
  observation_noise,
  initial_state_prior,
  initial_step = 0L,
  validate_args = FALSE,
  allow_nan_stats = TRUE,
  name = "LinearGaussianStateSpaceModel"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>num_timesteps</code></td>
<td>
<p>Integer <code>Tensor</code> total number of timesteps.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>transition_matrix</code></td>
<td>
<p>A transition operator, represented by a Tensor or
LinearOperator of shape <code style="white-space: pre;">⁠[latent_size, latent_size]⁠</code>, or by a
callable taking as argument a scalar integer Tensor <code>t</code> and
returning a Tensor or LinearOperator representing the transition
operator from latent state at time <code>t</code> to time <code>t + 1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>transition_noise</code></td>
<td>
<p>An instance of
<code>tfd$MultivariateNormalLinearOperator</code> with event shape
<code style="white-space: pre;">⁠[latent_size]⁠</code>, representing the mean and covariance of the
transition noise model, or a callable taking as argument a
scalar integer Tensor <code>t</code> and returning such a distribution
representing the noise in the transition from time <code>t</code> to time <code>t + 1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>observation_matrix</code></td>
<td>
<p>An observation operator, represented by a Tensor
or LinearOperator of shape <code style="white-space: pre;">⁠[observation_size, latent_size]⁠</code>,
or by a callable taking as argument a scalar integer Tensor
<code>t</code> and returning a timestep-specific Tensor or LinearOperator.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>observation_noise</code></td>
<td>
<p>An instance of <code>tfd.MultivariateNormalLinearOperator</code>
with event shape <code style="white-space: pre;">⁠[observation_size]⁠</code>, representing the mean and covariance of
the observation noise model, or a callable taking as argument
a scalar integer Tensor <code>t</code> and returning a timestep-specific
noise model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>initial_state_prior</code></td>
<td>
<p>An instance of <code>MultivariateNormalLinearOperator</code>
representing the prior distribution on latent states; must
have event shape <code style="white-space: pre;">⁠[latent_size]⁠</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>initial_step</code></td>
<td>
<p>optional <code>integer</code> specifying the time of the first
modeled timestep.  This is added as an offset when passing
timesteps <code>t</code> to (optional) callables specifying
timestep-specific transition and observation models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>validate_args</code></td>
<td>
<p>Logical, default FALSE. When TRUE distribution parameters are checked
for validity despite possibly degrading runtime performance. When FALSE invalid inputs may
silently render incorrect outputs. Default value: FALSE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>allow_nan_stats</code></td>
<td>
<p>Logical, default TRUE. When TRUE, statistics (e.g., mean, mode, variance)
use the value NaN to indicate the result is undefined. When FALSE, an exception is raised if
one or more of the statistic's batch members are undefined.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>name prefixed to Ops created by this class.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This Distribution represents the marginal distribution on
observations, <code>p(x)</code>. The marginal <code>log_prob</code> is computed by
Kalman filtering, and <code>sample</code> by an efficient forward
recursion. Both operations require time linear in <code>T</code>, the total
number of timesteps.
</p>
<p>Shapes
</p>
<p>The event shape is <code style="white-space: pre;">⁠[num_timesteps, observation_size]⁠</code>, where
<code>observation_size</code> is the dimension of each observation <code>x_t</code>.
The observation and transition models must return consistent
shapes.
This implementation supports vectorized computation over a batch of
models. All of the parameters (prior distribution, transition and
observation operators and noise models) must have a consistent
batch shape.
</p>
<p>Time-varying processes
</p>
<p>Any of the model-defining parameters (prior distribution, transition
and observation operators and noise models) may be specified as a
callable taking an integer timestep <code>t</code> and returning a
time-dependent value. The dimensionality (<code>latent_size</code> and
<code>observation_size</code>) must be the same at all timesteps.
</p>
<p>Importantly, the timestep is passed as a <code>Tensor</code>, not a Python
integer, so any conditional behavior must occur <em>inside</em> the
TensorFlow graph. For example, suppose we want to use a different
transition model on even days than odd days. It does <em>not</em> work to
write
</p>
<div class="sourceCode"><pre>transition_matrix &lt;- function(t) {
if(t %% 2 == 0) even_day_matrix else odd_day_matrix
}
</pre></div>
<p>since the value of <code>t</code> is not fixed at graph-construction
time. Instead we need to write
</p>
<div class="sourceCode"><pre>transition_matrix &lt;- function(t) {
tf$cond(tf$equal(tf$mod(t, 2), 0), function() even_day_matrix, function() odd_day_matrix)
}
</pre></div>
<p>so that TensorFlow can switch between operators appropriately at runtime.
</p>


<h3>Value</h3>

<p>a distribution instance.
</p>


<h3>See Also</h3>

<p>For usage examples see e.g. <code>tfd_sample()</code>, <code>tfd_log_prob()</code>, <code>tfd_mean()</code>.
</p>
<p>Other distributions: 
<code>tfd_autoregressive()</code>,
<code>tfd_batch_reshape()</code>,
<code>tfd_bates()</code>,
<code>tfd_bernoulli()</code>,
<code>tfd_beta_binomial()</code>,
<code>tfd_beta()</code>,
<code>tfd_binomial()</code>,
<code>tfd_categorical()</code>,
<code>tfd_cauchy()</code>,
<code>tfd_chi2()</code>,
<code>tfd_chi()</code>,
<code>tfd_cholesky_lkj()</code>,
<code>tfd_continuous_bernoulli()</code>,
<code>tfd_deterministic()</code>,
<code>tfd_dirichlet_multinomial()</code>,
<code>tfd_dirichlet()</code>,
<code>tfd_empirical()</code>,
<code>tfd_exp_gamma()</code>,
<code>tfd_exp_inverse_gamma()</code>,
<code>tfd_exponential()</code>,
<code>tfd_gamma_gamma()</code>,
<code>tfd_gamma()</code>,
<code>tfd_gaussian_process_regression_model()</code>,
<code>tfd_gaussian_process()</code>,
<code>tfd_generalized_normal()</code>,
<code>tfd_geometric()</code>,
<code>tfd_gumbel()</code>,
<code>tfd_half_cauchy()</code>,
<code>tfd_half_normal()</code>,
<code>tfd_hidden_markov_model()</code>,
<code>tfd_horseshoe()</code>,
<code>tfd_independent()</code>,
<code>tfd_inverse_gamma()</code>,
<code>tfd_inverse_gaussian()</code>,
<code>tfd_johnson_s_u()</code>,
<code>tfd_joint_distribution_named_auto_batched()</code>,
<code>tfd_joint_distribution_named()</code>,
<code>tfd_joint_distribution_sequential_auto_batched()</code>,
<code>tfd_joint_distribution_sequential()</code>,
<code>tfd_kumaraswamy()</code>,
<code>tfd_laplace()</code>,
<code>tfd_lkj()</code>,
<code>tfd_log_logistic()</code>,
<code>tfd_log_normal()</code>,
<code>tfd_logistic()</code>,
<code>tfd_mixture_same_family()</code>,
<code>tfd_mixture()</code>,
<code>tfd_multinomial()</code>,
<code>tfd_multivariate_normal_diag_plus_low_rank()</code>,
<code>tfd_multivariate_normal_diag()</code>,
<code>tfd_multivariate_normal_full_covariance()</code>,
<code>tfd_multivariate_normal_linear_operator()</code>,
<code>tfd_multivariate_normal_tri_l()</code>,
<code>tfd_multivariate_student_t_linear_operator()</code>,
<code>tfd_negative_binomial()</code>,
<code>tfd_normal()</code>,
<code>tfd_one_hot_categorical()</code>,
<code>tfd_pareto()</code>,
<code>tfd_pixel_cnn()</code>,
<code>tfd_poisson_log_normal_quadrature_compound()</code>,
<code>tfd_poisson()</code>,
<code>tfd_power_spherical()</code>,
<code>tfd_probit_bernoulli()</code>,
<code>tfd_quantized()</code>,
<code>tfd_relaxed_bernoulli()</code>,
<code>tfd_relaxed_one_hot_categorical()</code>,
<code>tfd_sample_distribution()</code>,
<code>tfd_sinh_arcsinh()</code>,
<code>tfd_skellam()</code>,
<code>tfd_spherical_uniform()</code>,
<code>tfd_student_t_process()</code>,
<code>tfd_student_t()</code>,
<code>tfd_transformed_distribution()</code>,
<code>tfd_triangular()</code>,
<code>tfd_truncated_cauchy()</code>,
<code>tfd_truncated_normal()</code>,
<code>tfd_uniform()</code>,
<code>tfd_variational_gaussian_process()</code>,
<code>tfd_vector_diffeomixture()</code>,
<code>tfd_vector_exponential_diag()</code>,
<code>tfd_vector_exponential_linear_operator()</code>,
<code>tfd_vector_laplace_diag()</code>,
<code>tfd_vector_laplace_linear_operator()</code>,
<code>tfd_vector_sinh_arcsinh_diag()</code>,
<code>tfd_von_mises_fisher()</code>,
<code>tfd_von_mises()</code>,
<code>tfd_weibull()</code>,
<code>tfd_wishart_linear_operator()</code>,
<code>tfd_wishart_tri_l()</code>,
<code>tfd_wishart()</code>,
<code>tfd_zipf()</code>
</p>


</div>