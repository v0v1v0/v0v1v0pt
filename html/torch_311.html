<div class="container">

<table style="width: 100%;"><tr>
<td>nn_prune_head</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Prune top layer(s) of a network</h2>

<h3>Description</h3>

<p>Prune <code>head_size</code> last layers of a nn_module in order to
replace them by your own head, or in order to use the pruned module
as a sequential embedding module.
</p>


<h3>Usage</h3>

<pre><code class="language-R">nn_prune_head(x, head_size)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>nn_network to prune</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>head_size</code></td>
<td>
<p>number of nn_layers to prune</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a nn_sequential network with the top nn_layer removed
</p>


<h3>Examples</h3>

<pre><code class="language-R">if (torch_is_installed()) {
if (torch_is_installed()) {
x &lt;- nn_sequential(
  nn_relu(),
  nn_tanh(),
  nn_relu6(),
  nn_relu(),
  nn_linear(2,10),
  nn_batch_norm1d(10),
  nn_tanh(),
  nn_linear(10,3)
)
prune &lt;- nn_prune_head(x, 3)
prune
}
}
</code></pre>


</div>