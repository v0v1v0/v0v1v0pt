<div class="container">

<table style="width: 100%;"><tr>
<td>optimizer</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Creates a custom optimizer</h2>

<h3>Description</h3>

<p>When implementing custom optimizers you will usually need to implement
the <code>initialize</code> and <code>step</code> methods. See the example section below
for a full example.
</p>


<h3>Usage</h3>

<pre><code class="language-R">optimizer(
  name = NULL,
  inherit = Optimizer,
  ...,
  private = NULL,
  active = NULL,
  parent_env = parent.frame()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>(optional) name of the optimizer</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>inherit</code></td>
<td>
<p>(optional) you can inherit from other optimizers to re-use
some methods.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Pass any number of fields or methods. You should at least define
the <code>initialize</code> and <code>step</code> methods. See the examples section.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>private</code></td>
<td>
<p>(optional) a list of private methods for the optimizer.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>active</code></td>
<td>
<p>(optional) a list of active methods for the optimizer.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parent_env</code></td>
<td>
<p>used to capture the right environment to define the class.
The default is fine for most situations.</p>
</td>
</tr>
</table>
<h3>Warning</h3>

<p>If you need to move a model to GPU via <code style="white-space: pre;">⁠$cuda()⁠</code>, please do so before
constructing optimizers for it. Parameters of a model after <code style="white-space: pre;">⁠$cuda()⁠</code>
will be different objects from those before the call. In general, you
should make sure that the objects pointed to by model parameters subject
to optimization remain the same over the whole lifecycle of optimizer
creation and usage.
</p>


<h3>Examples</h3>

<pre><code class="language-R">if (torch_is_installed()) {

# In this example we will create a custom optimizer
# that's just a simplified version of the `optim_sgd` function.

optim_sgd2 &lt;- optimizer(
  initialize = function(params, learning_rate) {
    defaults &lt;- list(
      learning_rate = learning_rate
    )
    super$initialize(params, defaults)
  },
  step = function() {
    with_no_grad({
      for (g in seq_along(self$param_groups)) {
        group &lt;- self$param_groups[[g]]
        for (p in seq_along(group$params)) {
          param &lt;- group$params[[p]]

          if (is.null(param$grad) || is_undefined_tensor(param$grad)) {
            next
          }

          param$add_(param$grad, alpha = -group$learning_rate)
        }
      }
    })
  }
)

x &lt;- torch_randn(1, requires_grad = TRUE)
opt &lt;- optim_sgd2(x, learning_rate = 0.1)
for (i in 1:100) {
  opt$zero_grad()
  y &lt;- x^2
  y$backward()
  opt$step()
}
all.equal(x$item(), 0, tolerance = 1e-9)
}
</code></pre>


</div>