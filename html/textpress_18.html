<div class="container">

<table style="width: 100%;"><tr>
<td>nlp_tokenize_text</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Tokenize Text Data (mostly) Non-Destructively</h2>

<h3>Description</h3>

<p>This function tokenizes text data from a data frame using the 'tokenizers' package, preserving the original text structure like capitalization and punctuation.
</p>


<h3>Usage</h3>

<pre><code class="language-R">nlp_tokenize_text(
  tif,
  text_hierarchy = c("doc_id", "paragraph_id", "sentence_id")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>tif</code></td>
<td>
<p>A data frame containing the text to be tokenized and a document identifier in 'doc_id'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>text_hierarchy</code></td>
<td>
<p>A character string specifying grouping column.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A named list of tokens, where each list item corresponds to a document.
</p>


<h3>Examples</h3>

<pre><code class="language-R">tif &lt;- data.frame(doc_id = c('1', '1', '2'),
                  sentence_id = c('1', '2', '1'),
                  text = c("Hello world.",
                           "This is an example.",
                           "This is a party!"))
tokens &lt;- nlp_tokenize_text(tif, text_hierarchy = c('doc_id', 'sentence_id'))


</code></pre>


</div>