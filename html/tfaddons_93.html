<div class="container">

<table style="width: 100%;"><tr>
<td>loss_npairs_multilabel</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Npairs multilabel loss</h2>

<h3>Description</h3>

<p>Computes the npairs loss between multilabel data 'y_true' and 'y_pred'.
</p>


<h3>Usage</h3>

<pre><code class="language-R">loss_npairs_multilabel(name = "npairs_multilabel_loss")
</code></pre>


<h3>Arguments</h3>

<table><tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>Optional name for the op.</p>
</td>
</tr></table>
<h3>Details</h3>

<p>Npairs loss expects paired data where a pair is composed of samples from
the same labels and each pairs in the minibatch have different labels.
The loss takes each row of the pair-wise similarity matrix, 'y_pred',
as logits and the remapped multi-class labels, 'y_true', as labels. To deal with
multilabel inputs, the count of label intersection
is computed as follows:
“'
L_i,j = | set_of_labels_for(i) '\cap' set_of_labels_for(j) |
“'
Each row of the count based label matrix is further normalized so that
each row sums to one. 'y_true' should be a binary indicator for classes.
That is, if 'y_true[i, j] = 1', then 'i'th sample is in 'j'th class;
if 'y_true[i, j] = 0', then 'i'th sample is not in 'j'th class. The similarity matrix
'y_pred' between two embedding matrices 'a' and 'b'
with shape '[batch_size, hidden_size]' can be computed as follows:
“'
# y_pred = a * b^T
y_pred = tf.matmul(a, b, transpose_a=FALSE, transpose_b=TRUE)
“'
</p>


<h3>Value</h3>

<p>npairs_multilabel_loss: float scalar.
</p>


<h3>See</h3>

<p>http://www.nec-labs.com/uploads/images/Department-Images/MediaAnalytics/papers/nips16_npairmetriclearning.pdf
</p>


</div>