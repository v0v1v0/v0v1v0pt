<div class="container">

<table style="width: 100%;"><tr>
<td>torch_arange</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Arange</h2>

<h3>Description</h3>

<p>Arange
</p>


<h3>Usage</h3>

<pre><code class="language-R">torch_arange(
  start,
  end,
  step = 1L,
  dtype = NULL,
  layout = NULL,
  device = NULL,
  requires_grad = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>start</code></td>
<td>
<p>(Number) the starting value for the set of points. Default: <code>0</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>end</code></td>
<td>
<p>(Number) the ending value for the set of points</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>step</code></td>
<td>
<p>(Number) the gap between each pair of adjacent points. Default: <code>1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dtype</code></td>
<td>
<p>(<code>torch.dtype</code>, optional) the desired data type of returned tensor.        Default: if <code>NULL</code>, uses a global default (see <code>torch_set_default_tensor_type</code>). If <code>dtype</code> is not given, infer the data type from the other input        arguments. If any of <code>start</code>, <code>end</code>, or <code>stop</code> are floating-point, the        <code>dtype</code> is inferred to be the default dtype, see        <code>~torch.get_default_dtype</code>. Otherwise, the <code>dtype</code> is inferred to        be <code>torch.int64</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>layout</code></td>
<td>
<p>(<code>torch.layout</code>, optional) the desired layout of returned Tensor.        Default: <code>torch_strided</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>device</code></td>
<td>
<p>(<code>torch.device</code>, optional) the desired device of returned tensor.        Default: if <code>NULL</code>, uses the current device for the default tensor type        (see <code>torch_set_default_tensor_type</code>). <code>device</code> will be the CPU        for CPU tensor types and the current CUDA device for CUDA tensor types.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>requires_grad</code></td>
<td>
<p>(bool, optional) If autograd should record operations on the        returned tensor. Default: <code>FALSE</code>.</p>
</td>
</tr>
</table>
<h3>arange(start=0, end, step=1, out=NULL, dtype=NULL, layout=torch.strided, device=NULL, requires_grad=False) -&gt; Tensor </h3>

<p>Returns a 1-D tensor of size <code class="reqn">\left\lceil \frac{\mbox{end} - \mbox{start}}{\mbox{step}} \right\rceil</code>
with values from the interval <code style="white-space: pre;">⁠[start, end)⁠</code> taken with common difference
<code>step</code> beginning from <code>start</code>.
</p>
<p>Note that non-integer <code>step</code> is subject to floating point rounding errors when
comparing against <code>end</code>; to avoid inconsistency, we advise adding a small epsilon to <code>end</code>
in such cases.
</p>
<p style="text-align: center;"><code class="reqn">
    \mbox{out}_{{i+1}} = \mbox{out}_{i} + \mbox{step}
</code>
</p>



<h3>Examples</h3>

<pre><code class="language-R">if (torch_is_installed()) {

torch_arange(start = 0, end = 5)
torch_arange(1, 4)
torch_arange(1, 2.5, 0.5)
}
</code></pre>


</div>