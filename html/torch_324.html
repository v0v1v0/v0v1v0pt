<div class="container">

<table style="width: 100%;"><tr>
<td>nn_softplus</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Softplus module</h2>

<h3>Description</h3>

<p>Applies the element-wise function:
</p>
<p style="text-align: center;"><code class="reqn">
  \mbox{Softplus}(x) = \frac{1}{\beta} * \log(1 + \exp(\beta * x))
</code>
</p>



<h3>Usage</h3>

<pre><code class="language-R">nn_softplus(beta = 1, threshold = 20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>the <code class="reqn">\beta</code> value for the Softplus formulation. Default: 1</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>threshold</code></td>
<td>
<p>values above this revert to a linear function. Default: 20</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>SoftPlus is a smooth approximation to the ReLU function and can be used
to constrain the output of a machine to always be positive.
For numerical stability the implementation reverts to the linear function
when <code class="reqn">input \times \beta &gt; threshold</code>.
</p>


<h3>Shape</h3>


<ul>
<li>
<p> Input: <code class="reqn">(N, *)</code> where <code>*</code> means, any number of additional
dimensions
</p>
</li>
<li>
<p> Output: <code class="reqn">(N, *)</code>, same shape as the input
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R">if (torch_is_installed()) {
m &lt;- nn_softplus()
input &lt;- torch_randn(2)
output &lt;- m(input)
}
</code></pre>


</div>