<div class="container">

<table style="width: 100%;"><tr>
<td>tokenizers</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Split texts into tokens</h2>

<h3>Description</h3>

<p>These functions each turn a text into tokens. The <code>tokenize_ngrams</code>
functions returns shingled n-grams.
</p>


<h3>Usage</h3>

<pre><code class="language-R">tokenize_words(string, lowercase = TRUE)

tokenize_sentences(string, lowercase = TRUE)

tokenize_ngrams(string, lowercase = TRUE, n = 3)

tokenize_skip_ngrams(string, lowercase = TRUE, n = 3, k = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>string</code></td>
<td>
<p>A character vector of length 1 to be tokenized.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lowercase</code></td>
<td>
<p>Should the tokens be made lower case?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>For n-gram tokenizers, the number of words in each n-gram.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>For the skip n-gram tokenizer, the maximum skip distance between
words. The function will compute all skip n-grams between <code>0</code> and
<code>k</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>These functions will strip all punctuation.
</p>


<h3>Value</h3>

<p>A character vector containing the tokens.
</p>


<h3>Examples</h3>

<pre><code class="language-R">dylan &lt;- "How many roads must a man walk down? The answer is blowin' in the wind."
tokenize_words(dylan)
tokenize_sentences(dylan)
tokenize_ngrams(dylan, n = 2)
tokenize_skip_ngrams(dylan, n = 3, k = 2)
</code></pre>


</div>