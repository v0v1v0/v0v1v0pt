<div class="container">

<table style="width: 100%;"><tr>
<td>get_stoplist</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Gets stoplist from precompiled lists</h2>

<h3>Description</h3>

<p>Provides access to 8 precompiled stoplists, including the most commonly used
stoplist from the Snowball stemming package ("snowball2014"), <code>text2map</code>'s
tiny stoplist ("tiny2020"), a few historically important stop lists. This
aims to be a transparent and well-document collection of stoplists. Only
includes English language stoplists at the moment.
</p>


<h3>Usage</h3>

<pre><code class="language-R">get_stoplist(source = "tiny2020", language = "en", tidy = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>source</code></td>
<td>
<p>Character indicating source, default = <code>"tiny2020"</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>language</code></td>
<td>
<p>Character (default = "en") indicating language of stopwords
by ISO 639-1 code, currently only English is supported.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tidy</code></td>
<td>
<p>logical (default = <code>FALSE</code>), returns a tibble</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>There is no such thing as a <em>stopword</em>! But, there are <strong>tons</strong> of
precompiled lists of words that someone thinks we should remove from
our texts. (See for example: https://github.com/igorbrigadir/stopwords)
One of the first stoplists is from C.J. van Rijsbergen's "Information
retrieval: theory and practice" (1979) and includes 250 words.
<code>text2map</code>'s very own stoplist <code>tiny2020</code> is a lean 34 words.
</p>
<p>Below are stoplists available with get_stoplist:
</p>

<ul>
<li>
<p> "tiny2020": Tiny (2020) list of 33 words (Default)
</p>
</li>
<li>
<p> "snowball2001": Snowball stemming package's (2001) list of 127 words
</p>
</li>
<li>
<p> "snowball2014": Updated Snowball (2014) list of 175 words
</p>
</li>
<li>
<p> "van1979": C. J. van Rijsbergen's (1979) list of 250 words
</p>
</li>
<li>
<p> "fox1990": Christopher Fox's (1990) list of 421 words
</p>
</li>
<li>
<p> "smart1993": Original SMART (1993) list of 570 words
</p>
</li>
<li>
<p> "onix2000": ONIX (2000) list of 196 words
</p>
</li>
<li>
<p> "nltk2001": Python's NLTK (2009) list of 179 words
</p>
</li>
</ul>
<p>The Snowball (2014) stoplist is likely the most commonly, it is the default
in the <code>stopwords</code> package, which is used by <code>quanteda</code>, <code>tidytext</code> and
<code>tokenizers</code> packages, followed closely by the Smart (1993) stoplist,
the default in the <code>tm</code> package. The word counts for SMART (1993) and
ONIX (2000) are slightly different than in other places because of
duplicate words.
</p>


<h3>Value</h3>

<p>Character vector of words to be stopped,
if tidy = TRUE, a tibble is returned
</p>


<h3>Author(s)</h3>

<p>Dustin Stoltz
</p>


</div>