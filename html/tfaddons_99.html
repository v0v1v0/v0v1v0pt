<div class="container">

<table style="width: 100%;"><tr>
<td>loss_triplet_semihard</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Triplet semihard loss</h2>

<h3>Description</h3>

<p>Computes the triplet loss with semi-hard negative mining.
</p>


<h3>Usage</h3>

<pre><code class="language-R">loss_triplet_semihard(margin = 1, name = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>margin</code></td>
<td>
<p>Float, margin term in the loss definition. Default value is 1.0.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>Optional name for the op.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments to pass</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>triplet_loss: float scalar with dtype of y_pred.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## Not run: 
model = keras_model_sequential() %&gt;%
  layer_conv_2d(filters = 64, kernel_size = 2, padding='same', input_shape=c(28,28,1)) %&gt;%
  layer_max_pooling_2d(pool_size=2) %&gt;%
  layer_flatten() %&gt;%
  layer_dense(256, activation= NULL) %&gt;%
  layer_lambda(f = function(x) tf$math$l2_normalize(x, axis = 1L))

model %&gt;% compile(
  optimizer = optimizer_lazy_adam(),
  # apply triplet semihard loss
  loss = loss_triplet_semihard())

## End(Not run)


</code></pre>


</div>