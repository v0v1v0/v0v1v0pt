<div class="container">

<table style="width: 100%;"><tr>
<td>tokenize</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Recompute the tokens for a document or corpus</h2>

<h3>Description</h3>

<p>Given a <code>TextReuseTextDocument</code> or a
<code>TextReuseCorpus</code>, this function recomputes the tokens and hashes
with the functions specified. Optionally, it can also recompute the minhash signatures.
</p>


<h3>Usage</h3>

<pre><code class="language-R">tokenize(
  x,
  tokenizer,
  ...,
  hash_func = hash_string,
  minhash_func = NULL,
  keep_tokens = FALSE,
  keep_text = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A <code>TextReuseTextDocument</code> or
<code>TextReuseCorpus</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tokenizer</code></td>
<td>
<p>A function to split the text into tokens. See
<code>tokenizers</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Arguments passed on to the <code>tokenizer</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hash_func</code></td>
<td>
<p>A function to hash the tokens. See
<code>hash_string</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>minhash_func</code></td>
<td>
<p>A function to create minhash signatures. See
<code>minhash_generator</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keep_tokens</code></td>
<td>
<p>Should the tokens be saved in the document that is
returned or discarded?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keep_text</code></td>
<td>
<p>Should the text be saved in the document that is returned or
discarded?</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The modified <code>TextReuseTextDocument</code> or
<code>TextReuseCorpus</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">dir &lt;- system.file("extdata/legal", package = "textreuse")
corpus &lt;- TextReuseCorpus(dir = dir, tokenizer = NULL)
corpus &lt;- tokenize(corpus, tokenize_ngrams)
head(tokens(corpus[[1]]))
</code></pre>


</div>