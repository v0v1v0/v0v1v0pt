<div class="container">

<table style="width: 100%;"><tr>
<td>catch</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Fit a CATCH model and predict categorical response.
</h2>

<h3>Description</h3>

<p>The <code>catch</code> function solves classification problems and selects variables by fitting a covariate-adjusted tensor classification in high-dimensions (CATCH) model. The input training predictors include two parts: tensor data and low dimensional covariates. The tensor data could be matrix as a special case of tensor. In <code>catch</code>, tensor data should be stored in a list form. If the dataset contains no covariate, <code>catch</code> can also fit a classifier only based on the tensor predictors. If covariates are provided, the method will adjust tensor for covariates and then fit a classifier based on the adjusted tensor along with the covariates. If users specify testing data at the same time, predicted response will be obtained as well. 
</p>


<h3>Usage</h3>

<pre><code class="language-R">catch(x, z = NULL, y, testx = NULL, testz = NULL, nlambda = 100, 
lambda.factor = ifelse((nobs - nclass) &lt;= nvars, 0.2, 1E-03), 
lambda = NULL,dfmax = nobs, pmax = min(dfmax * 2 + 20, nvars), 
pf = rep(1, nvars), eps = 1e-04, maxit = 1e+05, sml = 1e-06, 
verbose = FALSE, perturb = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Input tensor (or matrix) list of length <code class="reqn">N</code>, where <code class="reqn">N</code> is the number of observations. Each element of the list is a tensor or matrix. The order of tensor can be any positive integer not less than 2. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>z</code></td>
<td>
<p>Input covariate matrix of dimension <code class="reqn">N \times q</code>, where <code class="reqn">q&lt;N</code>. <code>z</code> can be omitted if covariate is absent. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Class label. For <code>K</code> class problems, <code>y</code> takes values in <code class="reqn">\{1,\cdots,\code{K}\}</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>testx</code></td>
<td>
<p>Input testing tensor or matrix list. Each element of the list is a test case. When <code>testx</code> is not provided, the function will only fit the model and return the classifier. When <code>testx</code> is provided, the function will predict response on <code>testx</code> as well.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>testz</code></td>
<td>
<p>Input testing covariate matrix. Can be omitted if covariate is absent. However, training covariates <code>z</code> and testing covariates <code>testz</code> must be provided or not at the same time.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlambda</code></td>
<td>
<p>The number of tuning values in sequence <code>lambda</code>. If users do not specify <code>lambda</code> values, the package will generate a solution path containing <code>nlambda</code> many tuning values of <code>lambda</code>. Default is <code>100</code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.factor</code></td>
<td>
<p>When <code>lambda</code> is not supplied, <code>catch</code> first finds the largest value in <code>lambda</code> which yields <code class="reqn">\boldsymbol{\beta}=0</code>. Then the minimum value in <code>lambda</code> is obtained by <code>(largest value*lambda.factor)</code>. The sequence of <code>lambda</code> is generated by evenly sampling <code>nlambda</code> numbers within the range. Default value of <code>lambda.factor</code> is 0.2 if <code class="reqn">N&lt;p</code> and 0.0001 if <code class="reqn">N&gt;p</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>A sequence of user-specified <code>lambda</code> values. <code>lambda</code> is the weight of L1 penalty and a smaller <code>lambda</code> allows more variables to be nonzero. If <code>NULL</code>, then the algorithm will generate a sequence of <code>nlambda</code> many potential 
<code>lambda</code>s according to <code>lambda.factor</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dfmax</code></td>
<td>
<p>The maximum number of selected variables in the model. Default is the number of observations <code>N</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pmax</code></td>
<td>
<p>The maximum number of potential selected variables during iteration. In middle step, the algorithm can select at most <code>pmax</code> variables and then shrink part of them such that the nubmer of final selected variables is less than <code>dfmax</code>. Default is <code class="reqn">\min(dfmax\times 2+20, N)</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pf</code></td>
<td>
<p>Weight of lasso penalty. Default is a vector of value <code>1</code> and length <code>p</code>, representing L1 penalty of length <code class="reqn">p</code>. Can be mofidied to use adaptive lasso penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>Convergence threshold for coordinate descent difference between iterations. Default value is <code>1e-04</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxit</code></td>
<td>
<p>Maximum iteration times for all lambda. Default value is <code>1e+05</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sml</code></td>
<td>
<p>Threshold for ratio of loss function change after each iteration to old loss function value. Default value is <code>1e-06</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Indicates whether print out lambda during iteration or not. Default value is <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>perturb</code></td>
<td>
<p>Perturbation scaler. If it is specified, the value will be added to diagonal of estimated covariance matrix. A small value can be used to accelerate iteration. Default value is <code>NULL</code>.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The <code>catch</code> function fits a linear discriminant analysis model as follows:
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{Z}|(Y=k)\sim N(\boldsymbol{\phi_k},\boldsymbol{\psi}),</code>
</p>

<p style="text-align: center;"><code class="reqn">\mathbf{X}|(\mathbf{Z}=\mathbf{z}, Y=k)\sim TN(\boldsymbol{\mu}_k+\boldsymbol{\alpha}\bar{\times}_{M+1}\mathbf{z},\boldsymbol{\Sigma}_1,\cdots,\boldsymbol{\Sigma}_M).</code>
</p>

<p>The categorical response is predicted from the estimated Bayes rule:
</p>
<p style="text-align: center;"><code class="reqn">\widehat{Y}=\arg\max_{k=1,\cdots,K}{a_k+\boldsymbol{\gamma}_k^T\mathbf{Z}+&lt;\boldsymbol{\beta}_k,\mathbf{X}-\boldsymbol{\alpha}\overline{\times}_{M+1}\mathbf{Z}&gt;},</code>
</p>
 
<p>where <code class="reqn">\mathbf{X}</code> is the tensor, <code class="reqn">\mathbf{Z}</code> is the covariates, <code class="reqn">a_k</code>, <code class="reqn">\boldsymbol{\gamma}_k</code> and <code class="reqn">\boldsymbol{\alpha}</code> are parameters estimated by CATCH. A detailed explanation can be found in reference. When <code>Z</code> is not <code>NULL</code>, the function will first adjust tensor on covariates by modeling
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{X}=\boldsymbol{\mu}_k+\boldsymbol{\alpha}\overline{\times}_{M+1}\mathbf{Z}+\mathbf{E},</code>
</p>
<p> where <code class="reqn">\mathbf{E}</code> is an unobservable tensor normal error independent of <code class="reqn">\mathbf{Z}</code>. 
Then <code>catch</code> fits model on the adjusted training tensor <code class="reqn">\mathbf{X}-\boldsymbol{\alpha}\overline{\times}_{M+1}\mathbf{Z}</code> and makes predictions on testing data by using the adjusted tensor list. If <code>Z</code> is <code>NULL</code>, it reduces to a simple tensor discriminant analysis model. 
</p>
<p>The coefficient of tensor <code class="reqn">\boldsymbol{\beta}</code>, represented by <code>beta</code> in package, is estimated by 
</p>
<p style="text-align: center;"><code class="reqn">\min_{\boldsymbol{\beta}_2,\ldots,\boldsymbol{\beta}_K}\left[\sum_{k=2}^K\left(\langle\boldsymbol{\beta}_k,[\![\boldsymbol{\beta}_k;\widehat{\boldsymbol{\Sigma}}_{1},\dots,\widehat{\boldsymbol{\Sigma}}_{M}]\!]\rangle-2\langle\boldsymbol{\beta}_k,\widehat{\boldsymbol{\mu}}_{k}-\widehat{\boldsymbol{\mu}}_{1}\rangle\right)+\lambda\sum_{j_{1}\dots j_{M}}\sqrt{\sum_{k=2}^{K}\beta_{k,j_{1}\cdots j_{M}}^2}\right].</code>
</p>

<p>When response is multi-class, the group lasso penalty over categories is added to objective function through parameter <code>lambda</code>, and it reduces to a lasso penalty in binary problems.
</p>
<p>The function <code>catch</code> will predict categorical response when testing data is provided. 
If testing data is not provided or if one wishes to perform prediction separately, <code>catch</code> can be used to only fit model with a catch object outcome. The object outcome can be combined with the adjusted tensor list from <code>adjten</code> to perform prediction by <code>predict.catch</code>.
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>Output variable coefficients for each <code>lambda</code>, which is the estimation of <code class="reqn">\boldsymbol{\beta}</code> in the Bayes rule. <code>beta</code> is a list of length being the number of <code>lambda</code>s. Each element of <code>beta</code> is a matrix of dimension <code class="reqn">nvars\times (nclass-1)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
<p>The number of nonzero variables for each value in sequence <code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dim</code></td>
<td>
<p>Dimension of coefficient array.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>The actual <code>lambda</code> sequence used. The user specified sequence or automatically generated sequence could be truncated by constraints on <code>dfmax</code> and <code>pmax</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>obj</code></td>
<td>
<p>Objective function value for each value in sequence <code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>The tensor list after adjustment in training data. If covariate is absent, this is the original input tensor list.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Class label in training data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>npasses</code></td>
<td>
<p>Total number of iterations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>jerr</code></td>
<td>
<p>Error flag.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigma</code></td>
<td>
<p>Estimated covariance matrix on each mode. <code>sigma</code> is a list with the <code>i</code>th element being covariance matrix on <code>i</code>th mode.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta</code></td>
<td>
<p>Estimated delta matrix <code class="reqn">(vec(\widehat{\boldsymbol{\mu}}_2-\widehat{\boldsymbol{\mu}}_1),\cdots,vec(\widehat{\boldsymbol{\mu}}_K-\widehat{\boldsymbol{\mu}}_1))</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu</code></td>
<td>
<p>Estimated mean array of <code class="reqn">\mathbf{X}</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior</code></td>
<td>
<p>Proportion of samples in each class.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>The call that produces this object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>Predicted categorical response for each value in sequence <code>lambda</code> when <code>testx</code> is provided.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Yuqing Pan, Qing Mai, Xin Zhang
</p>


<h3>References</h3>

<p>Pan, Y., Mai, Q., and Zhang, X. (2018), "Covariate-Adjusted Tensor Classification in High-Dimensions." Journal of the American Statistical Association, <em>accepted</em>.
</p>


<h3>See Also</h3>

<p><code>cv.catch</code>, <code>predict.catch</code>, <code>adjten</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">#without prediction
n &lt;- 20
p &lt;- 4
k &lt;- 2
nvars &lt;- p*p*p
x &lt;- array(list(),n)
vec_x &lt;- matrix(rnorm(n*nvars), nrow=n, ncol=nvars)
vec_x[1:10,] &lt;- vec_x[1:10,]+2
z &lt;- matrix(rnorm(n*2), nrow=n, ncol=2)
z[1:10,] &lt;- z[1:10,]+0.5
y &lt;- c(rep(1,10),rep(2,10))
for (i in 1:n){
  x[[i]] &lt;- array(vec_x[i,],dim=c(p,p,p))
}
obj &lt;- catch(x,z,y=y)
</code></pre>


</div>