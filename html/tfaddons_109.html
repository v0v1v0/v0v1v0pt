<div class="container">

<table style="width: 100%;"><tr>
<td>optimizer_decay_sgdw</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Optimizer that implements the Momentum algorithm with weight_decay</h2>

<h3>Description</h3>

<p>This is an implementation of the SGDW optimizer described in "Decoupled Weight Decay Regularization"
by Loshchilov &amp; Hutter (https://arxiv.org/abs/1711.05101) ([pdf])(https://arxiv.org/pdf/1711.05101.pdf).
It computes the update step of tf.keras.optimizers.SGD and additionally decays the variable. Note that this
is different from adding L2 regularization on the variables to the loss. Decoupling the weight decay from other
hyperparameters (in particular the learning rate) simplifies hyperparameter search. For further information see
the documentation of the SGD Optimizer.
</p>


<h3>Usage</h3>

<pre><code class="language-R">optimizer_decay_sgdw(
  weight_decay,
  learning_rate = 0.001,
  momentum = 0,
  nesterov = FALSE,
  name = "SGDW",
  clipnorm = NULL,
  clipvalue = NULL,
  decay = NULL,
  lr = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>weight_decay</code></td>
<td>
<p>weight decay rate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>learning_rate</code></td>
<td>
<p>float hyperparameter &gt;= 0. Learning rate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>momentum</code></td>
<td>
<p>float hyperparameter &gt;= 0 that accelerates SGD in the relevant direction and dampens oscillations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nesterov</code></td>
<td>
<p>boolean. Whether to apply Nesterov momentum.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>Optional name prefix for the operations created when applying gradients. Defaults to 'SGD'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>clipnorm</code></td>
<td>
<p>is clip gradients by norm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>clipvalue</code></td>
<td>
<p>is clip gradients by value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>decay</code></td>
<td>
<p>is included for backward compatibility to allow time inverse decay of learning rate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lr</code></td>
<td>
<p>is included for backward compatibility, recommended to use learning_rate instead.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Optimizer for use with 'keras::compile()'
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## Not run: 

step = tf$Variable(0L, trainable = FALSE)
schedule = tf$optimizers$schedules$PiecewiseConstantDecay(list(c(10000, 15000)),
list(c(1e-0, 1e-1, 1e-2)))
lr = 1e-1 * schedule(step)
wd = lambda: 1e-4 * schedule(step)


## End(Not run)

</code></pre>


</div>