<div class="container">

<table style="width: 100%;"><tr>
<td>chat_completion</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Generate Text Using the OpenAI API's Chat Endpoint</h2>

<h3>Description</h3>

<p>This function generates natural language text in a conversational style using the OpenAI API's chat endpoint.
It takes a series of chat messages as input, either as a data.frame or a chatlog object, and generates a text
completion based on the conversation history and the specified model parameters.
</p>


<h3>Usage</h3>

<pre><code class="language-R">chat_completion(
  msgs,
  model = "gpt-3.5-turbo",
  temperature = NULL,
  max_tokens = NULL,
  n = NULL,
  stop = NULL,
  presence_penalty = NULL,
  frequency_penalty = NULL,
  best_of = NULL,
  logit_bias = NULL,
  stream = FALSE,
  top_p = NULL,
  user = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>msgs</code></td>
<td>
<p>A data.frame containing the chat history to generate text from or a chatlog object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>A character string specifying the ID of the model to use.
The default value is "gpt-3.5-turbo".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>temperature</code></td>
<td>
<p>An optional numeric scalar specifying the sampling temperature to use.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_tokens</code></td>
<td>
<p>An optional integer scalar specifying the maximum number of tokens to generate in the text.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>An optional integer scalar specifying the number of text completions to generate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stop</code></td>
<td>
<p>An optional character string or character vector specifying one or more stop sequences to use when generating the text.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>presence_penalty</code></td>
<td>
<p>An optional numeric scalar specifying the presence penalty to use when generating the text. The default value is NULL.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>frequency_penalty</code></td>
<td>
<p>An optional numeric scalar specifying the frequency penalty to use when generating the text. The default value is NULL.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>best_of</code></td>
<td>
<p>An optional integer scalar specifying the number of completions to generate and return the best one. The default value is NULL.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logit_bias</code></td>
<td>
<p>An optional named numeric vector specifying the logit bias to use for each token in the generated text.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stream</code></td>
<td>
<p>An optional logical scalar specifying whether to use the streaming API. The default value is <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>top_p</code></td>
<td>
<p>An optional numeric scalar specifying the top p sampling ratio. The default value is NULL.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>user</code></td>
<td>
<p>A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A character vector containing the generated text(s).
</p>


<h3>Author(s)</h3>

<p>Ulrich Matter umatter@protonmail.com
</p>


<h3>See Also</h3>

<p><a href="https://platform.openai.com/docs/">https://platform.openai.com/docs/</a> for more information on the OpenAI API.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
openai_api_key("your_api_key_here")
msgs_df &lt;- data.frame(role=c("system",
"user",
"assistant",
"user"),
content=c("You are a helpful assistant",
"Who won the world series in 2020?",
"The Los Angeles Dodgers won the World Series in 2020.",
"Where was it played?"))
chat_completion(msgs_df)

## End(Not run)
</code></pre>


</div>