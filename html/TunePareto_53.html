<div class="container">

<table style="width: 100%;"><tr>
<td>predefinedObjectiveFunctions</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Predefined objective functions for parameter tuning
</h2>

<h3>Description</h3>

<p>Predefined objective functions that calculate several performance criteria of reclassification or cross-validation experiments.
</p>


<h3>Usage</h3>

<pre><code class="language-R">reclassAccuracy(saveModel = FALSE)
reclassError(saveModel = FALSE)
reclassWeightedError(saveModel = FALSE)
reclassSensitivity(caseClass, saveModel = FALSE)
reclassRecall(caseClass, saveModel = FALSE)
reclassTruePositive(caseClass, saveModel = FALSE)
reclassSpecificity(caseClass, saveModel = FALSE)
reclassTrueNegative(caseClass, saveModel = FALSE)
reclassFallout(caseClass, saveModel = FALSE)
reclassFalsePositive(caseClass, saveModel = FALSE)
reclassMiss(caseClass, saveModel = FALSE)
reclassFalseNegative(caseClass, saveModel = FALSE)
reclassPrecision(caseClass, saveModel = FALSE)
reclassPPV(caseClass, saveModel = FALSE)
reclassNPV(caseClass, saveModel = FALSE)
reclassConfusion(trueClass, predictedClass, saveModel = FALSE)

cvAccuracy(nfold = 10, ntimes = 10,
           leaveOneOut = FALSE, stratified = FALSE,
           foldList = NULL,
           saveModel = FALSE) 
cvError(nfold = 10, ntimes = 10, 
        leaveOneOut = FALSE, stratified=FALSE, 
        foldList=NULL,
        saveModel = FALSE)
cvErrorVariance(nfold = 10, ntimes = 10, 
                leaveOneOut = FALSE, stratified=FALSE, 
                foldList=NULL,
                saveModel = FALSE)
cvWeightedError(nfold = 10, ntimes = 10, 
                leaveOneOut = FALSE, stratified=FALSE, 
                foldList=NULL,
                saveModel = FALSE)
cvSensitivity(nfold = 10, ntimes = 10, 
              leaveOneOut = FALSE, stratified=FALSE, 
              foldList=NULL, caseClass,
              saveModel = FALSE)
cvRecall(nfold = 10, ntimes = 10,
         leaveOneOut = FALSE, stratified=FALSE,
         foldList=NULL, caseClass,
         saveModel = FALSE)
cvTruePositive(nfold = 10, ntimes = 10, 
               leaveOneOut = FALSE, stratified=FALSE, 
               foldList=NULL, caseClass,
               saveModel = FALSE)
cvSpecificity(nfold = 10, ntimes = 10, 
              leaveOneOut = FALSE, stratified=FALSE, 
              foldList=NULL, caseClass,
              saveModel = FALSE)
cvTrueNegative(nfold = 10, ntimes = 10, 
               leaveOneOut = FALSE, stratified=FALSE, 
               foldList=NULL, caseClass,
               saveModel = FALSE)
cvFallout(nfold = 10, ntimes = 10, 
          leaveOneOut = FALSE, stratified=FALSE, 
          foldList=NULL, caseClass,
          saveModel = FALSE)
cvFalsePositive(nfold = 10, ntimes = 10, 
                leaveOneOut = FALSE, stratified=FALSE, 
                foldList=NULL, caseClass,
                saveModel = FALSE)          
cvMiss(nfold = 10, ntimes = 10, 
       leaveOneOut = FALSE, stratified=FALSE, 
       foldList=NULL, caseClass,
       saveModel = FALSE)
cvFalseNegative(nfold = 10, ntimes = 10,
                leaveOneOut = FALSE, stratified=FALSE,
                foldList=NULL, caseClass,
                saveModel = FALSE)
cvPrecision(nfold = 10, ntimes = 10,
            leaveOneOut = FALSE, stratified=FALSE,
            foldList=NULL, caseClass,
            saveModel = FALSE)
cvPPV(nfold = 10, ntimes = 10,
      leaveOneOut = FALSE, stratified=FALSE,
      foldList=NULL, caseClass,
      saveModel = FALSE)
cvNPV(nfold = 10, ntimes = 10,
      leaveOneOut = FALSE, stratified=FALSE,
      foldList=NULL, caseClass,
      saveModel = FALSE)
cvConfusion(nfold = 10, ntimes = 10, 
            leaveOneOut = FALSE, stratified=FALSE,
            foldList=NULL, trueClass, predictedClass,
            saveModel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>nfold</code></td>
<td>

<p>The number of groups of the cross-validation. Ignored if <code>leaveOneOut=TRUE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ntimes</code></td>
<td>

<p>The number of repeated runs of the cross-validation. Ignored if <code>leaveOneOut=TRUE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>leaveOneOut</code></td>
<td>

<p>If this is true, a leave-one-out cross-validation is performed, i.e. each sample is left out once in the training phase and used as a test sample
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stratified</code></td>
<td>

<p>If set to true, a stratified cross-validation is carried out. That is, the percentage of samples from different classes in the cross-validation folds corresponds to the class sizes in the complete data set. If set to false, the folds may be unbalanced.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>foldList</code></td>
<td>

<p>If this parameter is set, the other cross-validation parameters (<code>ntimes</code>, <code>nfold</code>, <code>leaveOneOut</code>, <code>stratified</code>) are ignored. Instead, the precalculated cross-validation partition supplied in <code>foldList</code> is used. This allows for using the same cross-validation experiment in multiple <code>tunePareto</code> calls. Partitions can be generated using <code>generateCVRuns</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>caseClass</code></td>
<td>
<p>The class containing the positive samples for the calculation of specificity and sensitivity. All samples with different class labels are regarded as controls (negative samples).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trueClass</code></td>
<td>

<p>When calculating the confusion of two classes, the class to which a sample truly belongs.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>predictedClass</code></td>
<td>

<p>When calculating the confusion of two classes, the class to which a sample is erreneously assigned.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>saveModel</code></td>
<td>

<p>If set to true, the trained model(s) are stored to the <code>additionalData</code> component of the resulting <code>TuneParetoResult</code> objects (see <code>tunePareto</code> for details). In case of a reclassification, a single model is stored. In case of a cross-validation, a list of length <code>nruns</code>, each containing a sub-list of <code>nfold</code> models, is stored. If the size of a model is large, setting <code>saveModel = TRUE</code> can result in a high memory consumption. As the model information is the same for all reclassification objectives or for cross-validation objectives with the same parameters, it is usually sufficient to set <code>saveModel=TRUE</code> for only one of the objective functions.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The functions do not calculate the objectives directly, but return a structure of class <code>TuneParetoObjectives</code> that provides all information on the objective function for later use in <code>tunePareto</code>.
</p>
<p>The behaviour of the functions in <code>tunePareto</code> is as follows:
</p>
<p>The reclassification functions train the classifiers with the full data set. Afterwards, the classifiers are applied to the same data set. <code>reclassAccuracy</code> measures the fraction of correctly classified samples, while <code>reclassError</code> calculates the fraction of misclassified samples. <code>reclassWeightedError</code> calculates the sum of fractions of misclassified samples in each class weighted by the class size. <code>reclassSensitivity</code> measures the sensitivity, and <code>reclassSpecificity</code> measures the specificity of the reclassification experiment. <code>reclassTruePositive</code> and <code>reclassRecall</code> are aliases for <code>reclassSensitivity</code>, and <code>reclassTrueNegative</code> is an alias for <code>reclassSpecificity</code>. <code>reclassFallout</code> and its equivalent alias <code>reclassFalsePositive</code> give the ratio of false positives to all negative samples, and <code>reclassMiss</code> and its alias <code>reclassFalseNegative</code> measure the ratio of false negatives to all positive samples. <code>reclassPrecision</code> calculates the precision of the reclassification experiment, i.e. the ratio of true positives to all samples classified as positive. This is equivalent to the positive predictive value (<code>reclassPPV</code>). <code>reclassNPV</code> measures the negative predictive value, i.e. the ratio of true negatives to all samples classified as negative. <code>reclassConfusion</code> calculates the fraction of samples in <code>trueClass</code> that have been confused with <code>predictedClass</code>.
</p>
<p><code>reclassError</code>, <code>reclassWeightedError</code>, <code>reclassFallout</code>, <code>reclassFalsePositive</code>, <code>reclassMiss</code>, <code>reclassFalsePositive</code>  and <code>reclassConfusion</code> are minimization objectives, whereas <code>reclassAccuracy</code>, <code>reclassSensitivity</code>, <code>reclassTruePositive</code>, <code>reclassRecall</code>, <code>reclassSpecificity</code>, <code>reclassTrueNegative</code> <code>reclassPrecision</code>, <code>reclassPPV</code> and <code>reclassNPV</code> are maximization objectives.
</p>
<p>The cross-validation functions partition the samples in the data set into a number of groups (depending on <code>nfold</code> and <code>leaveOneOut</code>). Each of these groups is left out once in the training phase and used for prediction. The whole procedure is usually repeated several times (as specified in <code>ntimes</code>), and the results are averaged. Similar to the reclassification functions, <code>cvAccuracy</code> calculates the fraction of correctly classified samples over the runs, <code>cvError</code> calculates the average fraction of misclassified samples over the runs, and <code>cvWeightedError</code> calculates the mean sum of fractions of misclassified samples in each class weighted by the class size. <code>cvErrorVariance</code> calculates the variance of the cross-validation error. <code>cvSensitivity</code>, <code>cvRecall</code> and <code>cvTruePositive</code> calculate the average sensitivity, and <code>cvSpecificity</code> and <code>cvTrueNegative</code> calculate the average specificity. <code>cvFallout</code> and <code>cvFalsePositive</code> calculate the average false positive rate over the runs. <code>cvMiss</code> and <code>cvFalseNegative</code> calculate the average false negative rate over the runs. <code>cvPrecision</code> and <code>cvPPV</code> calculate the average precision/positive predictive rate. <code>cvNPV</code> gives the average negative predictive rate over all runs. <code>cvConfusion</code> calculates the average fraction of samples in <code>trueClass</code> that have been confused with <code>predictedClass</code>.
</p>
<p><code>cvError</code>, <code>cvWeightedError</code>, <code>cvErrorVariance</code>, <code>cvFallout</code>, <code>cvFalsePositive</code>, <code>cvMiss</code>, <code>cvFalseNegative</code> and <code>cvConfusion</code> are minimization objectives, and <code>cvAccuracy</code>, <code>cvSensitivity</code>, <code>cvRecall</code>, <code>cvTruePositive</code>, <code>cvSpecificity</code>, <code>cvTrueNegative</code>, <code>cvPrecision</code>, <code>cvPPV</code> and <code>cvNPV</code> are maximization objectives.
</p>


<h3>Value</h3>

<p>An object of class <code>TuneParetoObjective</code> representing the objective function. For more details, see <code>createObjective</code>.
</p>


<h3>See Also</h3>

<p><code>createObjective</code>, <code>tunePareto</code>, <code>generateCVRuns</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# build a list of objective functions
objectiveFunctions &lt;- list(cvError(10, 10),
                           reclassSpecificity(caseClass="setosa"), 
                           reclassSensitivity(caseClass="setosa"))

# pass them to tunePareto
print(tunePareto(data = iris[, -ncol(iris)], 
                 labels = iris[, ncol(iris)],
                 classifier = tunePareto.knn(),
                 k = c(3,5,7,9),
                 objectiveFunctions = objectiveFunctions))
</code></pre>


</div>