<div class="container">

<table style="width: 100%;"><tr>
<td>torch_pinverse</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Pinverse</h2>

<h3>Description</h3>

<p>Pinverse
</p>


<h3>Usage</h3>

<pre><code class="language-R">torch_pinverse(self, rcond = 1e-15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>self</code></td>
<td>
<p>(Tensor) The input tensor of size <code class="reqn">(*, m, n)</code> where <code class="reqn">*</code> is zero or more batch dimensions</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rcond</code></td>
<td>
<p>(float) A floating point value to determine the cutoff for small singular values.                   Default: 1e-15</p>
</td>
</tr>
</table>
<h3>pinverse(input, rcond=1e-15) -&gt; Tensor </h3>

<p>Calculates the pseudo-inverse (also known as the Moore-Penrose inverse) of a 2D tensor.
Please look at <code style="white-space: pre;">⁠Moore-Penrose inverse⁠</code>_ for more details
</p>


<h3>Note</h3>

<div class="sourceCode"><pre>This method is implemented using the Singular Value Decomposition.
</pre></div>
<div class="sourceCode"><pre>The pseudo-inverse is not necessarily a continuous function in the elements of the matrix `[1]`_.
Therefore, derivatives are not always existent, and exist for a constant rank only `[2]`_.
However, this method is backprop-able due to the implementation by using SVD results, and
could be unstable. Double-backward will also be unstable due to the usage of SVD internally.
See `~torch.svd` for more details.
</pre></div>


<h3>Examples</h3>

<pre><code class="language-R">if (torch_is_installed()) {

input = torch_randn(c(3, 5))
input
torch_pinverse(input)
# Batched pinverse example
a = torch_randn(c(2,6,3))
b = torch_pinverse(a)
torch_matmul(b, a)
}
</code></pre>


</div>