<div class="container">

<table style="width: 100%;"><tr>
<td>lr_reduce_on_plateau</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Reduce learning rate on plateau</h2>

<h3>Description</h3>

<p>Reduce learning rate when a metric has stopped improving.
Models often benefit from reducing the learning rate by a factor
of 2-10 once learning stagnates. This scheduler reads a metrics
quantity and if no improvement is seen for a 'patience' number
of epochs, the learning rate is reduced.
</p>


<h3>Usage</h3>

<pre><code class="language-R">lr_reduce_on_plateau(
  optimizer,
  mode = "min",
  factor = 0.1,
  patience = 10,
  threshold = 1e-04,
  threshold_mode = "rel",
  cooldown = 0,
  min_lr = 0,
  eps = 1e-08,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>optimizer</code></td>
<td>
<p>(Optimizer): Wrapped optimizer.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mode</code></td>
<td>
<p>(str): One of <code>min</code>, <code>max</code>. In <code>min</code> mode, lr will be reduced
when the quantity monitored has stopped decreasing; in <code>max</code> mode it will be
reduced when the quantity monitored has stopped increasing. Default: 'min'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>factor</code></td>
<td>
<p>(float): Factor by which the learning rate will be reduced.
new_lr &lt;- lr * factor. Default: 0.1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>patience</code></td>
<td>
<p>(int): Number of epochs with no improvement after which
learning rate will be reduced. For example, if <code>patience = 2</code>, then we will
ignore the first 2 epochs with no improvement, and will only decrease the LR
after the 3rd epoch if the loss still hasn't improved then. Default: 10.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>threshold</code></td>
<td>
<p>(float):Threshold for measuring the new optimum, to only
focus on significant changes. Default: 1e-4.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>threshold_mode</code></td>
<td>
<p>(str): One of <code>rel</code>, <code>abs</code>. In <code>rel</code> mode,
dynamic_threshold &lt;- best * ( 1 + threshold ) in 'max' mode
or best * ( 1 - threshold ) in <code>min</code> mode. In <code>abs</code> mode,
dynamic_threshold &lt;- best + threshold in <code>max</code> mode or
best - threshold in <code>min</code> mode. Default: 'rel'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cooldown</code></td>
<td>
<p>(int): Number of epochs to wait before resuming normal
operation after lr has been reduced. Default: 0.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_lr</code></td>
<td>
<p>(float or list): A scalar or a list of scalars. A lower bound
on the learning rate of all param groups or each group respectively. Default: 0.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>(float): Minimal decay applied to lr. If the difference between
new and old lr is smaller than eps, the update is ignored. Default: 1e-8.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>(bool): If <code>TRUE</code>, prints a message to stdout for
each update. Default: <code>FALSE</code>.</p>
</td>
</tr>
</table>
<h3>Examples</h3>

<pre><code class="language-R">if (torch_is_installed()) {
## Not run:  
optimizer &lt;- optim_sgd(model$parameters(), lr=0.1, momentum=0.9)
scheduler &lt;- lr_reduce_on_plateau(optimizer, 'min')
for (epoch in 1:10) {
 train(...)
 val_loss &lt;- validate(...)
 # note that step should be called after validate
 scheduler$step(val_loss)
}

## End(Not run)
}
</code></pre>


</div>