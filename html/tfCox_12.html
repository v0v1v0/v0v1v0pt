<div class="container">

<table style="width: 100%;"><tr>
<td>tfCox</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fit the additive trend filtering Cox model with a range of tuning parameters</h2>

<h3>Description</h3>

<p>Fit additive trend filtering Cox model where each component function is estimated to be piecewise constant or polynomial.
</p>


<h3>Usage</h3>

<pre><code class="language-R">tfCox(dat, ord=0, alpha=1, lambda.seq=NULL, discrete=NULL, n.lambda=30,
lambda.min.ratio = 0.01, tol=1e-6, niter=1000, stepSize=25, backtracking=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>dat</code></td>
<td>

<p>A list that contains <code>time</code>, <code>status</code> and <code>X</code>. <code>time</code> is failure or censoring time, <code>status</code> is failure indicator with 1 indicating failure and 0 indicating censoring, and <code>X</code> is n x p design matrix and may have p &gt; n. Missing data are not allowed in <code>time</code>, <code>status</code> and <code>X</code>. <code>X</code> should be numeric.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ord</code></td>
<td>

<p>The polynomial order of the trend filtering fit; a non-negative interger (<code>ord&gt;= 3</code> is not recommended). For instance, <code>ord=0</code> will produce piewise constant fit, <code>ord=1</code> will produce piewise linear fit, and <code>ord=2</code> will produce piewise quadratic fit.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>

<p>The trade-off between trend filtering penalty and group lasso penalty. It must be in [0,1]. <code>alpha=1</code> corresponds to the case with only trend filtering penalty to produce piecewise polynomial, and <code>alpha=0</code> corresponds to the case with only group lasso penalty to produce sparsity of the functions. <code>alpha</code> between 0 and 1 is the tradeoff between the strength of these two penalties. For p &lt; n, we suggest using 1.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.seq</code></td>
<td>

<p>A vector of non-negative tuning parameters. If provided, <code>lambda.seq</code> should be a decreasing sequence of values since <code>tfCox</code> uses warm starts for speed. If <code>lambda.seq=NULL</code>, the default will calculate <code>lambda.seq</code> using <code>lambda.min.ratio</code> and <code>n.lambda</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>discrete</code></td>
<td>

<p>A vector of covariate/feature indice that are discrete. Discrete covariates are not penalized in the model. Default <code>NULL</code> means that none of the covariates are discrete thus all covariates will be penalized in the model.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.lambda</code></td>
<td>

<p>The number of lambda values to consider and the default is 30.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.min.ratio</code></td>
<td>

<p>Smallest value for lambda.seq, as a fraction of the maximum lambda value, which is the smallest value such that the penalty term is zero. The default is 0.01.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>

<p>Convergence criterion for estimates.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>niter</code></td>
<td>

<p>Maximum number of iterations.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stepSize</code></td>
<td>

<p>Initial step size. Default is 25.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>backtracking</code></td>
<td>

<p>Whether backtracking should be used 1 (TRUE) or 0 (FALSE). Default is 0 (FALSE). 
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The optimization problem has the form
</p>
<p style="text-align: center;"><code class="reqn"> l(\theta)+\alpha\lambda\sum_{j=1}^p |D_jP_j\theta_j|_1+(1-\alpha)\lambda\sum_{j=1}^p|\theta_j|_2 </code>
</p>

<p>where <code class="reqn">l</code> is the loss function defined as the negative log partial likelihood divided by n, and <code class="reqn">\alpha</code> provides a trade-off between trend filtering penalty and group lasso penalty. Covariate matrix <code>X</code> is not standardized before solving the optimization problem.
</p>


<h3>Value</h3>

<p>An object with S3 class "tfCox".
</p>
<table>
<tr style="vertical-align: top;">
<td><code>ord</code></td>
<td>
<p>the polynomial order of the trend filtering fit. Specified by user (or default).  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>as specified by user (or default). </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.seq</code></td>
<td>
<p>vector of lambda values considered. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>theta.list</code></td>
<td>
<p>list of estimated theta matrices of dimension n x p. Each component in the list corresponds to the fit from <code>lambda.seq</code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num.knots</code></td>
<td>
<p>vector of number of knots of the estimated theta. Each component corresponds to the fit from <code>lambda.seq</code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num.nonsparse</code></td>
<td>
<p>vector of proportion of non-sparse/non-zero covariates/features. Each component corresponds to the fit from <code>lambda.seq</code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dat</code></td>
<td>
<p>as specified by user. </p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Jiacheng Wu
</p>


<h3>References</h3>

<p>Jiacheng Wu &amp; Daniela Witten (2019) Flexible and Interpretable Models for Survival Data, Journal of Computational and Graphical Statistics, DOI: 10.1080/10618600.2019.1592758
</p>


<h3>See Also</h3>

<p><code>summary.tfCox</code>, <code>predict.tfCox</code>, <code>plot.tfCox</code>, <code>cv_tfCox</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">###################################################################
#constant trend filtering (fused lasso) with adaptively chosen knots
#generate data from simulation scenario 1 with piecewise constant functions
set.seed(1234)
dat = sim_dat(n=100, zerof=0, scenario=1)

#fit piecewise constant for alpha=1 and a range of lambda
fit = tfCox(dat, ord=0, alpha=1)
summary(fit)
#plot the fit of lambda index 15 and the first predictor
plot(fit, which.lambda=15, which.predictor=1)

#cross-validation to choose the tuning parameter lambda with fixed alpha=1
cv = cv_tfCox(dat, ord=0, alpha=1, n.fold=2)
summary(cv)
cv$best.lambda
#plot the cross-validation curve
plot(cv)

#fit the model with the best tuning parameter chosen by cross-validation
one.fit = tfCox(dat, ord=0, alpha=1, lambda.seq=cv$best.lambda)
#predict theta from the fitted tfCox object
theta_hat = predict(one.fit, newX=dat$X, which.lambda=1)

#plot the fitted theta_hat (line) with the true theta (dot)
for (i in 1:4) {
  ordi = order(dat$X[,i])
  plot(dat$X[ordi,i], dat$true_theta[ordi,i],
    xlab=paste("predictor",i), ylab="theta" )
  lines(dat$X[ordi,i], theta_hat[ordi,i], type="s")
}


#################################################################
#linear trend filtering with adaptively chosen knots
#generate data from simulation scenario 3 with piecewise linear functions
set.seed(1234)
dat = sim_dat(n=100, zerof=0, scenario=3)

#fit piecewise constant for alpha=1 and a range of lambda
fit = tfCox(dat, ord=1, alpha=1)
summary(fit)
#plot the fit of lambda index 15 and the first predictor
plot(fit, which.lambda=15, which.predictor=1)

#cross-validation to choose the tuning parameter lambda with fixed alpha=1
cv = cv_tfCox(dat, ord=1, alpha=1, n.fold=2)
summary(cv)
#plot the cross-validation curve
plot(cv)

#fit the model with the best tuning parameter chosen by cross-validation
one.fit = tfCox(dat, ord=1, alpha=1, lambda.seq=cv$best.lambda)
#predict theta from the fitted tfCox object
theta_hat = predict(one.fit, newX=dat$X, which.lambda=1)

#plot the fitted theta_hat (line) with the true theta (dot)
for (i in 1:4) {
  ordi = order(dat$X[,i])
  plot(dat$X[ordi,i], dat$true_theta[ordi,i],
       xlab=paste("predictor",i), ylab="theta" )
  lines(dat$X[ordi,i], theta_hat[ordi,i], type="l")
}


</code></pre>


</div>