<div class="container">

<table style="width: 100%;"><tr>
<td>traforest</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Transformation Forests</h2>

<h3>Description</h3>

<p>Partitioned and aggregated transformation models
</p>


<h3>Usage</h3>

<pre><code class="language-R">traforest(object, parm = 1:length(coef(object)), reparm = NULL,
          intercept = c("none", "shift", "scale", "shift-scale"),
          update = TRUE, min_update = length(coef(object)) * 2,
          mltargs = list(),  ...)
## S3 method for class 'traforest'
predict(object,  newdata, mnewdata = data.frame(1), K = 20, q = NULL,
    type = c("weights", "node", "coef", "trafo", "distribution", "survivor", "density",
             "logdensity", "hazard", "loghazard", "cumhazard", "quantile"),
    OOB = FALSE, simplify = FALSE, trace = FALSE, updatestart = FALSE, 
    applyfun = NULL, cores = NULL, ...)
## S3 method for class 'traforest'
logLik(object, newdata, weights = NULL, OOB = FALSE, coef = NULL,  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>an object of class <code>ctm</code> or <code>mlt</code> specifying the
abstract model to be partitioned.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parm</code></td>
<td>
<p>parameters of <code>object</code> those corresponding score is
used for finding partitions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>reparm</code></td>
<td>
<p>optional matrix of contrasts for reparameterisation of the scores.
<code>teststat = "quadratic"</code> is invariant to this operation
but <code>teststat = "max"</code> might be more powerful for
example when formulating an implicit into an explicit intercept term.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>add optional intercept parameters (constraint to zero) to
the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mltargs</code></td>
<td>
<p>arguments to <code>mlt</code> for fitting the
transformation models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>update</code></td>
<td>
<p>logical, if <code>TRUE</code>, models and thus scores are updated in
every node. If <code>FALSE</code>, the model and scores are
computed once in the root node. The latter option is faster
but less accurate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_update</code></td>
<td>
<p>number of observations necessary to refit the model in a
node. If less observations are available, the parameters from the parent
node will be reused.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newdata</code></td>
<td>
<p>an optional data frame of observations for the forest.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mnewdata</code></td>
<td>
<p>an optional data frame of observations for the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>number of grid points to generate (in the absence of <code>q</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>q</code></td>
<td>
<p>quantiles at which to evaluate the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>type of prediction or plot to generate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>OOB</code></td>
<td>
<p>compute out-of-bag predictions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>simplify</code></td>
<td>
<p>simplify predictions (if possible).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trace</code></td>
<td>
<p>a logical indicating if a progress bar shall be printed while
the predictions are computed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>updatestart</code></td>
<td>
<p>try to be smart about starting values for computing
predictions (experimental).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>applyfun</code></td>
<td>
<p>an optional <code>lapply</code>-style function with arguments
<code>function(X, FUN, ...)</code> for looping over <code>newdata</code>.
The default is to use the
basic <code>lapply</code> function unless the <code>cores</code> argument is
specified (see below).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cores</code></td>
<td>
<p>numeric. If set to an integer the <code>applyfun</code> is set to
<code>mclapply</code> with the desired number of <code>cores</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>an optional vector of weights.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coef</code></td>
<td>
<p>an optional matrix of precomputed coefficients for
<code>newdata</code> (using <code>predict</code>). Helps to compute the
coefficients once for later reuse (different weights, for
example).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>arguments to <code>cforest</code>, at least
<code>formula</code> and <code>data</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Conditional inference trees are used for partitioning likelihood-based transformation
models as described in Hothorn and Zeileis (2017). The method can be seen
in action in Hothorn (2018) and the corresponding code is available as
<code>demo("BMI")</code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>traforest</code> with corresponding <code>logLik</code> and
<code>predict</code> methods.
</p>


<h3>References</h3>

<p>Torsten Hothorn and Achim Zeileis (2021). Predictive Distribution 
Modelling Using Transformation Forests. 
<em>Journal of Computational and Graphical Statistics</em>,
<a href="https://doi.org/10.1080/10618600.2021.1872581">doi:10.1080/10618600.2021.1872581</a>.
</p>
<p>Torsten Hothorn (2018). Top-Down Transformation Choice. <em>Statistical
Modelling</em>, <b>3-4</b>, 274-298. <a href="https://doi.org/10.1177/1471082X17748081">doi:10.1177/1471082X17748081</a>.
</p>
<p>Natalia Korepanova, Heidi Seibold, Verena Steffen and Torsten Hothorn
(2019).  Survival Forests under Test: Impact of the Proportional Hazards
Assumption on Prognostic and Predictive Forests for ALS Survival.
<a href="https://doi.org/10.1177/0962280219862586">doi:10.1177/0962280219862586</a>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
### Example: Personalised Medicine Using Partitioned and Aggregated Cox-Models
### A combination of &lt;DOI:10.1177/0962280217693034&gt; and &lt;arXiv:1701.02110&gt;
### based on infrastructure in the mlt R add-on package described in
### https://cran.r-project.org/web/packages/mlt.docreg/vignettes/mlt.pdf

library("trtf")
library("survival")
### German Breast Cancer Study Group 2 data set
data("GBSG2", package = "TH.data")
GBSG2$y &lt;- with(GBSG2, Surv(time, cens))

### set-up Cox model with overall treatment effect in hormonal therapy
cmod &lt;- Coxph(y ~ horTh, data = GBSG2, support = c(100, 2000), order = 5)

### overall log-hazard ratio
coef(cmod)
### roughly the same as 
coef(coxph(y ~ horTh, data = GBSG2))

## Not run: 

### estimate age-dependent Cox models (here ignoring all other covariates)
ctrl &lt;- ctree_control(minsplit = 50, minbucket = 20, mincriterion = 0)
set.seed(290875)
tf_cmod &lt;- traforest(cmod, formula = y ~ horTh | age, control = ctrl, 
                     ntree = 50, mtry = 1, trace = TRUE, data = GBSG2)

### plot age-dependent treatment effects vs. overall treatment effect
nd &lt;- data.frame(age = 30:70)
cf &lt;- predict(tf_cmod, newdata = nd, type = "coef")
nd$logHR &lt;- sapply(cf, function(x) x["horThyes"])
plot(logHR ~ age, data = nd, pch = 19, xlab = "Age", ylab = "log-Hazard Ratio")
abline(h = coef(cmod &lt;- mlt(m, data = GBSG2))["horThyes"])
### treatment most beneficial in very young patients
### NOTE: scale of log-hazard ratios depends on
### corresponding baseline hazard function which  _differs_
### across age; interpretation of positive / negative treatment effect is,
### however, save.

### mclapply doesn't work in Windows
if (.Platform$OS.type != "windows") {

  ### computing predictions: predicted coefficients
  cf1 &lt;- predict(tf_cmod, newdata = nd, type = "coef")
  ### speedup with plenty of RAM and 4 cores
  cf2 &lt;- predict(tf_cmod, newdata = nd, cores = 4, type = "coef")
  ### memory-efficient with low RAM and _one_ core
  cf3 &lt;- predict(tf_cmod, newdata = nd, cores = 4, applyfun = lapply, type = "coef")
  all.equal(cf1, cf2)
  all.equal(cf1, cf3)

}


## End(Not run)

</code></pre>


</div>