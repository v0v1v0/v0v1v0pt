<div class="container">

<table style="width: 100%;"><tr>
<td>ts.lstm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Long Short Term Memory (LSTM) Model for Time Series Forecasting</h2>

<h3>Description</h3>

<p>The LSTM (Long Short-Term Memory) model is a Recurrent Neural Network (RNN) based architecture that is widely used for time series forecasting. Min-Max transformation has been used for data preparation. Here, we have used one LSTM layer as a simple LSTM model and a Dense layer is used as the output layer. Then, compile the model using the loss function, optimizer and metrics. This package is based on 'keras' and TensorFlow modules.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ts.lstm(
  ts,
  xreg = NULL,
  tsLag = NULL,
  xregLag = 0,
  LSTMUnits,
  DenseUnits = NULL,
  DropoutRate = 0,
  Epochs = 10,
  CompLoss = "mse",
  CompMetrics = "mae",
  Optimizer = optimizer_rmsprop,
  ScaleOutput = c(NULL, "scale", "minmax"),
  ScaleInput = c(NULL, "scale", "minmax"),
  BatchSize = 1,
  LSTMActivationFn = "tanh",
  LSTMRecurrentActivationFn = "sigmoid",
  DenseActivationFn = "relu",
  ValidationSplit = 0.1,
  verbose = 2,
  RandomState = NULL,
  EarlyStopping = callback_early_stopping(monitor = "val_loss", min_delta = 0, patience =
    3, verbose = 0, mode = "auto"),
  LagsAsSequences = TRUE,
  Stateful = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>ts</code></td>
<td>
<p>Time series data</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xreg</code></td>
<td>
<p>Exogenous variables</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tsLag</code></td>
<td>
<p>Lag of time series data. If NULL, no lags of the output are used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xregLag</code></td>
<td>
<p>Lag of exogenous variables</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>LSTMUnits</code></td>
<td>
<p>Number of unit in LSTM layers</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>DenseUnits</code></td>
<td>
<p>Number of unit in Extra Dense layers. A Dense layer with a single neuron is always added at the end.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>DropoutRate</code></td>
<td>
<p>Dropout rate</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Epochs</code></td>
<td>
<p>Number of epochs</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>CompLoss</code></td>
<td>
<p>Loss function</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>CompMetrics</code></td>
<td>
<p>Metrics</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Optimizer</code></td>
<td>
<p>'keras' optimizer</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ScaleOutput</code></td>
<td>
<p>Flag to indicate if ts shall be scaled before training</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ScaleInput</code></td>
<td>
<p>Flag to indicate if xreg shall be scaled before training</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>BatchSize</code></td>
<td>
<p>Batch size to use during training</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>LSTMActivationFn</code></td>
<td>
<p>Activation function for LSTM layers</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>LSTMRecurrentActivationFn</code></td>
<td>
<p>Recurrent activation function for LSTM layers</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>DenseActivationFn</code></td>
<td>
<p>Activation function for Extra Dense layers</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ValidationSplit</code></td>
<td>
<p>Validation split ration</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Indicate how much information is given during training. Accepted values, 0, 1 or 2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>RandomState</code></td>
<td>
<p>seed for replication</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>EarlyStopping</code></td>
<td>
<p>EarlyStopping according to 'keras'</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>LagsAsSequences</code></td>
<td>
<p>Use lags as previous timesteps of features, otherwise use them as "extra" features.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Stateful</code></td>
<td>
<p>Flag to indicate if LSTM layers shall retain its state between batches.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Extra arguments passed to keras::layer_lstm</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>LSTMmodel object
</p>


<h3>References</h3>

<p>Paul, R.K. and Garai, S. (2021). Performance comparison of wavelets-based machine learning technique for forecasting agricultural commodity prices, Soft Computing, 25(20), 12857-12873
</p>


<h3>Examples</h3>

<pre><code class="language-R">
  if (keras::is_keras_available()){
      y&lt;-rnorm(100,mean=100,sd=50)
      x1&lt;-rnorm(100,mean=50,sd=50)
      x2&lt;-rnorm(100, mean=50, sd=25)
      x&lt;-cbind(x1,x2)
      TSLSTM&lt;-ts.lstm(ts=y,
                      xreg = x,
                      tsLag=2,
                      xregLag = 0,
                      LSTMUnits=5,
                      ScaleInput = 'scale',
                      ScaleOutput = 'scale',
                      Epochs=2)
  }

</code></pre>


</div>