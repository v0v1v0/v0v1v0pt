<div class="container">

<table style="width: 100%;"><tr>
<td>tepGPLS</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Generalized Partial Least Squares
</h2>

<h3>Description</h3>

<p>Generalized Partial Least Squares (GPLS) via TExPosition. GPLS is to PLS (<code>tepPLS</code>) as PCA <code>epPCA</code> is to GPCA <code>epGPCA</code>.
The major difference between PLS and GPLS is that GPLS allows the use of weights for the columns of each data set (just like GPCA).
</p>


<h3>Usage</h3>

<pre><code class="language-R">tepGPLS(DATA1, DATA2, 
center1 = TRUE, scale1 = "SS1",
center2 = TRUE, scale2 = "SS1",
DESIGN = NULL, make_design_nominal = TRUE,
weights1 = NULL, weights2 = NULL,
graphs = TRUE, k = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>DATA1</code></td>
<td>
<p>Data matrix 1 (X)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>DATA2</code></td>
<td>
<p>Data matrix 2 (Y)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center1</code></td>
<td>
<p>a boolean, vector, or string to center <code>DATA1</code>. See <code>expo.scale</code> for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale1</code></td>
<td>
<p>a boolean, vector, or string to scale <code>DATA1</code>. See <code>expo.scale</code> for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center2</code></td>
<td>
<p>a boolean, vector, or string to center <code>DATA2</code>. See <code>expo.scale</code> for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale2</code></td>
<td>
<p>a boolean, vector, or string to scale <code>DATA2</code>. See <code>expo.scale</code> for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>DESIGN</code></td>
<td>
<p>a design matrix to indicate if rows belong to groups.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>make_design_nominal</code></td>
<td>
<p>a boolean. If TRUE (default), DESIGN is a vector that indicates groups (and will be dummy-coded). If FALSE, DESIGN is a dummy-coded matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights1</code></td>
<td>
<p>a weight vector (or diag matrix) for the columns of DATA1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights2</code></td>
<td>
<p>a weight vector (or diag matrix) for the columns of DATA2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>graphs</code></td>
<td>
<p>a boolean. If TRUE (default), graphs and plots are provided (via <code>tepGraphs</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>number of components to return.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This implementation of Partial Least Squares is a symmetric analysis. It was first described by Tucker (1958), again by Bookstein (1994), and has gained notoriety in Neuroimaging from McIntosh et al., (1996). This particular implementation allows the user to provide weights for the columns of both <code>DATA1</code> and <code>DATA2</code>.
</p>


<h3>Value</h3>

<p>See <code>epGPCA</code> (and also <code>corePCA</code>) for details on what is returned. In addition to the values returned:<br></p>
<table>
<tr style="vertical-align: top;">
<td><code>lx</code></td>
<td>
<p>latent variables from DATA1 computed for observations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ly</code></td>
<td>
<p>latent variables from DATA2 computed for observations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data1.norm</code></td>
<td>
<p>center and scale information for DATA1</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data1.norm</code></td>
<td>
<p>center and scale information for DATA2</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Derek Beaton
</p>


<h3>References</h3>

<p>Tucker, L. R. (1958). An inter-battery method of factor analysis. <em>Psychometrika</em>, <em>23</em>(2), 111–136. <br>
Bookstein, F., (1994). Partial least squares: a dose–response model for measurement in the behavioral and brain sciences. <em>Psycoloquy</em> <em>5</em> (23) <br>
Abdi, H. (2007). Singular Value Decomposition (SVD) and Generalized Singular Value Decomposition (GSVD). In N.J. Salkind (Ed.): <em>Encyclopedia of Measurement and Statistics</em>.Thousand Oaks (CA): Sage. pp. 907-912.<br>
Krishnan, A., Williams, L. J., McIntosh, A. R., &amp; Abdi, H. (2011). Partial Least Squares (PLS) methods for neuroimaging: A tutorial and review. <em>NeuroImage</em>, <em>56</em>(<b>2</b>), 455 – 475.<br>
McIntosh, A. R., &amp; Lobaugh, N. J. (2004). Partial least squares analysis of neuroimaging data: applications and advances. <em>Neuroimage</em>, <em>23</em>, S250–S263.<br></p>


<h3>See Also</h3>

<p><code>corePCA</code>, <code>epPCA</code>, <code>epGPCA</code>,  <code>tepPLS</code>, <code>tepPLSCA</code>, <code>tepBADA</code>, <code>tepDICA</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(beer.tasting.notes)
data1&lt;-beer.tasting.notes$data[,1:8]
data2&lt;-beer.tasting.notes$data[,9:16]
gpls.res &lt;- tepGPLS(data1,data2)
</code></pre>


</div>