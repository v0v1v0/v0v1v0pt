<div class="container">

<table style="width: 100%;"><tr>
<td>nn_nll_loss</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Nll loss</h2>

<h3>Description</h3>

<p>The negative log likelihood loss. It is useful to train a classification
problem with <code>C</code> classes.
</p>


<h3>Usage</h3>

<pre><code class="language-R">nn_nll_loss(weight = NULL, ignore_index = -100, reduction = "mean")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>weight</code></td>
<td>
<p>(Tensor, optional): a manual rescaling weight given to each
class. If given, it has to be a Tensor of size <code>C</code>. Otherwise, it is
treated as if having all ones.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ignore_index</code></td>
<td>
<p>(int, optional): Specifies a target value that is ignored
and does not contribute to the input gradient.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>reduction</code></td>
<td>
<p>(string, optional): Specifies the reduction to apply to the output:
<code>'none'</code> | <code>'mean'</code> | <code>'sum'</code>. <code>'none'</code>: no reduction will
be applied, <code>'mean'</code>: the weighted mean of the output is taken,
<code>'sum'</code>: the output will be summed.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>If provided, the optional argument <code>weight</code> should be a 1D Tensor assigning
weight to each of the classes. This is particularly useful when you have an
unbalanced training set.
</p>
<p>The <code>input</code> given through a forward call is expected to contain
log-probabilities of each class. <code>input</code> has to be a Tensor of size either
<code class="reqn">(minibatch, C)</code> or <code class="reqn">(minibatch, C, d_1, d_2, ..., d_K)</code>
with <code class="reqn">K \geq 1</code> for the <code>K</code>-dimensional case (described later).
</p>
<p>Obtaining log-probabilities in a neural network is easily achieved by
adding a  <code>LogSoftmax</code>  layer in the last layer of your network.
</p>
<p>You may use <code>CrossEntropyLoss</code> instead, if you prefer not to add an extra
layer.
</p>
<p>The <code>target</code> that this loss expects should be a class index in the range <code class="reqn">[0, C-1]</code>
where <code style="white-space: pre;">⁠C = number of classes⁠</code>; if <code>ignore_index</code> is specified, this loss also accepts
this class index (this index may not necessarily be in the class range).
</p>
<p>The unreduced (i.e. with <code>reduction</code> set to <code>'none'</code>) loss can be described as:
</p>
<p style="text-align: center;"><code class="reqn">
\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
l_n = - w_{y_n} x_{n,y_n}, \quad
w_{c} = \mbox{weight}[c] \cdot \mbox{1}\{c \not= \mbox{ignore\_index}\},
</code>
</p>

<p>where <code class="reqn">x</code> is the input, <code class="reqn">y</code> is the target, <code class="reqn">w</code> is the weight, and
<code class="reqn">N</code> is the batch size. If <code>reduction</code> is not <code>'none'</code>
(default <code>'mean'</code>), then
</p>
<p style="text-align: center;"><code class="reqn">
\ell(x, y) = \begin{array}{ll}
\sum_{n=1}^N \frac{1}{\sum_{n=1}^N w_{y_n}} l_n, &amp;
  \mbox{if reduction} = \mbox{'mean';}\\
\sum_{n=1}^N l_n,  &amp;
  \mbox{if reduction} = \mbox{'sum'.}
\end{array}
</code>
</p>

<p>Can also be used for higher dimension inputs, such as 2D images, by providing
an input of size <code class="reqn">(minibatch, C, d_1, d_2, ..., d_K)</code> with <code class="reqn">K \geq 1</code>,
where <code class="reqn">K</code> is the number of dimensions, and a target of appropriate shape
(see below). In the case of images, it computes NLL loss per-pixel.
</p>


<h3>Shape</h3>


<ul>
<li>
<p> Input: <code class="reqn">(N, C)</code> where <code style="white-space: pre;">⁠C = number of classes⁠</code>, or
<code class="reqn">(N, C, d_1, d_2, ..., d_K)</code> with <code class="reqn">K \geq 1</code>
in the case of <code>K</code>-dimensional loss.
</p>
</li>
<li>
<p> Target: <code class="reqn">(N)</code> where each value is <code class="reqn">0 \leq \mbox{targets}[i] \leq C-1</code>, or
<code class="reqn">(N, d_1, d_2, ..., d_K)</code> with <code class="reqn">K \geq 1</code> in the case of
K-dimensional loss.
</p>
</li>
<li>
<p> Output: scalar.
</p>
</li>
</ul>
<p>If <code>reduction</code> is <code>'none'</code>, then the same size as the target: <code class="reqn">(N)</code>, or
<code class="reqn">(N, d_1, d_2, ..., d_K)</code> with <code class="reqn">K \geq 1</code> in the case
of K-dimensional loss.
</p>


<h3>Examples</h3>

<pre><code class="language-R">if (torch_is_installed()) {
m &lt;- nn_log_softmax(dim = 2)
loss &lt;- nn_nll_loss()
# input is of size N x C = 3 x 5
input &lt;- torch_randn(3, 5, requires_grad = TRUE)
# each element in target has to have 0 &lt;= value &lt; C
target &lt;- torch_tensor(c(2, 1, 5), dtype = torch_long())
output &lt;- loss(m(input), target)
output$backward()

# 2D loss example (used, for example, with image inputs)
N &lt;- 5
C &lt;- 4
loss &lt;- nn_nll_loss()
# input is of size N x C x height x width
data &lt;- torch_randn(N, 16, 10, 10)
conv &lt;- nn_conv2d(16, C, c(3, 3))
m &lt;- nn_log_softmax(dim = 1)
# each element in target has to have 0 &lt;= value &lt; C
target &lt;- torch_empty(N, 8, 8, dtype = torch_long())$random_(1, C)
output &lt;- loss(m(conv(data)), target)
output$backward()
}
</code></pre>


</div>