<div class="container">

<table style="width: 100%;"><tr>
<td>Doc2Vec</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Conversion of text documents to word-vector-representation features ( Doc2Vec )</h2>

<h3>Description</h3>

<p>Conversion of text documents to word-vector-representation features ( Doc2Vec )
</p>
<p>Conversion of text documents to word-vector-representation features ( Doc2Vec )
</p>


<h3>Usage</h3>

<pre><code class="language-R"># utl &lt;- Doc2Vec$new(token_list = NULL, word_vector_FILE = NULL,

       #                    print_every_rows = 10000, verbose = FALSE,

       #                    copy_data = FALSE)
</code></pre>


<h3>Details</h3>

<p>the <em>pre_processed_wv</em> method should be used after the initialization of the <em>Doc2Vec</em> class, if the <em>copy_data</em> parameter is set to TRUE, in order to inspect the pre-processed word-vectors.
</p>
<p>The <em>global_term_weights</em> method is part of the <em>sparse_term_matrix</em> R6 class of the <em>textTinyR package</em>. One can come to the correct <em>global_term_weights</em> by using the
<em>sparse_term_matrix</em> class and by setting the <em>tf_idf</em> parameter to FALSE and the <em>normalize</em> parameter to NULL. In <em>Doc2Vec</em> class, if method equals to <em>idf</em> then the <em>global_term_weights</em> parameter should not be equal to NULL.
</p>
<p>Explanation of the various <em>methods</em> :
</p>

<dl>
<dt>sum_sqrt</dt>
<dd>
<p>Assuming that a single sublist of the token list will be taken into consideration : the wordvectors of each word of the sublist of tokens will be accumulated to a vector equal to the length of the wordvector (INITIAL_WORD_VECTOR). Then a scalar will be computed using this INITIAL_WORD_VECTOR in the following way : the INITIAL_WORD_VECTOR will be raised to the power of 2.0, then the resulted wordvector will be summed and the square-root will be calculated. The INITIAL_WORD_VECTOR will be divided by the resulted scalar</p>
</dd>
<dt>min_max_norm</dt>
<dd>
<p>Assuming that a single sublist of the token list will be taken into consideration : the wordvectors of each word of the sublist of tokens will be first <em>min-max</em> normalized and then will be accumulated to a vector equal to the length of the initial wordvector</p>
</dd>
<dt>idf</dt>
<dd>
<p>Assuming that a single sublist of the token list will be taken into consideration : the word-vector of each term in the sublist will be multiplied with the corresponding <em>idf</em> of the <em>global weights term</em></p>
</dd>
</dl>
<p>There might be slight differences in the output data for each method depending on the input value of the <em>copy_data</em> parameter (if it's either TRUE or FALSE).

</p>


<h3>Value</h3>

<p>a matrix
</p>


<h3>Methods</h3>


<dl>
<dt><code>Doc2Vec$new(token_list = NULL, word_vector_FILE = NULL, print_every_rows = 10000, verbose = FALSE, copy_data = FALSE)</code></dt>
<dd></dd>
<dt><code>--------------</code></dt>
<dd></dd>
<dt><code>doc2vec_methods(method = "sum_sqrt", global_term_weights = NULL, threads = 1)</code></dt>
<dd></dd>
<dt><code>--------------</code></dt>
<dd></dd>
<dt><code>pre_processed_wv()</code></dt>
<dd></dd>
</dl>
<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-documents_to_wordvectors-new"><code>Doc2Vec$new()</code></a>
</p>
</li>
<li> <p><a href="#method-documents_to_wordvectors-doc2vec_methods"><code>Doc2Vec$doc2vec_methods()</code></a>
</p>
</li>
<li> <p><a href="#method-documents_to_wordvectors-pre_processed_wv"><code>Doc2Vec$pre_processed_wv()</code></a>
</p>
</li>
<li> <p><a href="#method-documents_to_wordvectors-clone"><code>Doc2Vec$clone()</code></a>
</p>
</li>
</ul>
<hr>
<a id="method-documents_to_wordvectors-new"></a>



<h4>Method <code>new()</code>
</h4>



<h5>Usage</h5>

<div class="r"><pre>Doc2Vec$new(
  token_list = NULL,
  word_vector_FILE = NULL,
  print_every_rows = 10000,
  verbose = FALSE,
  copy_data = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>token_list</code></dt>
<dd>
<p>either NULL or a list of tokenized text documents</p>
</dd>
<dt><code>word_vector_FILE</code></dt>
<dd>
<p>a valid path to a text file, where the word-vectors are saved</p>
</dd>
<dt><code>print_every_rows</code></dt>
<dd>
<p>a numeric value greater than 1 specifying the print intervals. Frequent output in the R session can slow down the function especially in case of big files.</p>
</dd>
<dt><code>verbose</code></dt>
<dd>
<p>either TRUE or FALSE. If TRUE then information will be printed out in the R session.</p>
</dd>
<dt><code>copy_data</code></dt>
<dd>
<p>either TRUE or FALSE. If FALSE then a pointer will be created and no copy of the initial data takes place (memory efficient especially for big datasets). This is an alternative way to pre-process the data.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-documents_to_wordvectors-doc2vec_methods"></a>



<h4>Method <code>doc2vec_methods()</code>
</h4>



<h5>Usage</h5>

<div class="r"><pre>Doc2Vec$doc2vec_methods(
  method = "sum_sqrt",
  global_term_weights = NULL,
  threads = 1
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>method</code></dt>
<dd>
<p>a character string specifying the method to use. One of <em>sum_sqrt</em>, <em>min_max_norm</em> or <em>idf</em>. See the details section for more information.</p>
</dd>
<dt><code>global_term_weights</code></dt>
<dd>
<p>either NULL or the output of the <em>global_term_weights</em> method of the textTinyR package. See the details section for more information.</p>
</dd>
<dt><code>threads</code></dt>
<dd>
<p>a numeric value specifying the number of cores to run in parallel</p>
</dd>
</dl>
</div>


<hr>
<a id="method-documents_to_wordvectors-pre_processed_wv"></a>



<h4>Method <code>pre_processed_wv()</code>
</h4>



<h5>Usage</h5>

<div class="r"><pre>Doc2Vec$pre_processed_wv()</pre></div>


<hr>
<a id="method-documents_to_wordvectors-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>Doc2Vec$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>Examples</h3>

<pre><code class="language-R">
library(textTinyR)

#---------------------------------
# tokenized text in form of a list
#---------------------------------

tok_text = list(c('the', 'result', 'of'), c('doc2vec', 'are', 'vector', 'features'))

#-------------------------
# path to the word vectors
#-------------------------

PATH = system.file("example_files", "word_vecs.txt", package = "textTinyR")


init = Doc2Vec$new(token_list = tok_text, word_vector_FILE = PATH)


out = init$doc2vec_methods(method = "sum_sqrt")
</code></pre>


</div>