<div class="container">

<table style="width: 100%;"><tr>
<td>claude</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Call the Anthropic API to interact with Claude models</h2>

<h3>Description</h3>

<p>Call the Anthropic API to interact with Claude models
</p>


<h3>Usage</h3>

<pre><code class="language-R">claude(
  .llm,
  .model = "claude-3-5-sonnet-20240620",
  .max_tokens = 1024,
  .temperature = NULL,
  .top_k = NULL,
  .top_p = NULL,
  .metadata = NULL,
  .stop_sequences = NULL,
  .tools = NULL,
  .api_url = "https://api.anthropic.com/",
  .verbose = FALSE,
  .wait = TRUE,
  .min_tokens_reset = 0L,
  .timeout = 60,
  .stream = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>.llm</code></td>
<td>
<p>An existing LLMMessage object or an initial text prompt.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.model</code></td>
<td>
<p>The model identifier (default: "claude-3-5-sonnet-20240620").</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.max_tokens</code></td>
<td>
<p>The maximum number of tokens to generate (default: 1024).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.temperature</code></td>
<td>
<p>Control for randomness in response generation (optional).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.top_k</code></td>
<td>
<p>Top k sampling parameter (optional).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.top_p</code></td>
<td>
<p>Nucleus sampling parameter (optional).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.metadata</code></td>
<td>
<p>Additional metadata for the request (optional).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.stop_sequences</code></td>
<td>
<p>Sequences that stop generation (optional).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.tools</code></td>
<td>
<p>Additional tools used by the model (optional).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.api_url</code></td>
<td>
<p>Base URL for the API (default: "https://api.anthropic.com/v1/messages").</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.verbose</code></td>
<td>
<p>Should additional information be shown after the API call</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.wait</code></td>
<td>
<p>Should we wait for rate limits if necessary?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.min_tokens_reset</code></td>
<td>
<p>How many tokens should be remaining to wait until we wait for token reset?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.timeout</code></td>
<td>
<p>Request timeout in seconds (default: 60).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.stream</code></td>
<td>
<p>Stream back the response piece by piece (default: FALSE).</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Returns an updated LLMMessage object.
</p>


</div>