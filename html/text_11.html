<div class="container">

<table style="width: 100%;"><tr>
<td>textClassify</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Predict label and probability of a text using a pretrained classifier language model. (experimental)</h2>

<h3>Description</h3>

<p>Predict label and probability of a text using a pretrained classifier language model. (experimental)
</p>


<h3>Usage</h3>

<pre><code class="language-R">textClassify(
  x,
  model = "distilbert-base-uncased-finetuned-sst-2-english",
  device = "cpu",
  tokenizer_parallelism = FALSE,
  logging_level = "error",
  return_incorrect_results = FALSE,
  return_all_scores = FALSE,
  function_to_apply = "none",
  set_seed = 202208
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>(string)  A character variable or a tibble/dataframe with at least one character variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>(string)  Specification of a pre-trained classifier language model.
For full list of options see pretrained classifier models at
<a href="https://huggingface.co/transformers/pretrained_models.html">HuggingFace</a>.
For example use "cardiffnlp/twitter-roberta-base-sentiment", "distilbert-base-uncased-finetuned-sst-2-english".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>device</code></td>
<td>
<p>(string)  Device to use: 'cpu', 'gpu', or 'gpu:k' where k is a specific device number.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tokenizer_parallelism</code></td>
<td>
<p>(boolean)  If TRUE this will turn on tokenizer parallelism.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logging_level</code></td>
<td>
<p>(string)  Set the logging level.
Options (ordered from less logging to more logging): critical, error, warning, info, debug</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return_incorrect_results</code></td>
<td>
<p>(boolean)  Stop returning some incorrectly formatted/structured results.
This setting does CANOT evaluate the actual results (whether or not they make sense, exist, etc.).
All it does is to ensure the returned results are formatted correctly (e.g., does the question-answering
dictionary contain the key "answer", is sentiments from textClassify containing the labels "positive"
and "negative").</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return_all_scores</code></td>
<td>
<p>(boolean)  Whether to return all prediction scores or just the one of the predicted class.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>function_to_apply</code></td>
<td>
<p>(string)  The function to apply to the model outputs to retrieve the scores.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>set_seed</code></td>
<td>
<p>(Integer) Set seed.
There are four different values:
"default": if the model has a single label, will apply the sigmoid function on the output.
If the model has several labels,
the softmax function will be applied on the output.
"sigmoid": Applies the sigmoid function on the output.
"softmax": Applies the softmax function on the output.
"none": Does not apply any function on the output.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A tibble with predicted labels and scores for each text variable.
The comment of the object show the model-name and computation time.
</p>


<h3>See Also</h3>

<p>see <code>textGeneration</code>, <code>textNER</code>,
<code>textSum</code>, <code>textQA</code>, <code>textTranslate</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# classifications &lt;- textClassify(x = Language_based_assessment_data_8[1:2, 1:2])
# classifications
# comment(classifications)

</code></pre>


</div>