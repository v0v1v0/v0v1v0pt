<div class="container">

<table style="width: 100%;"><tr>
<td>tenFM.est</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Estimation for Tucker structure Factor Models of Tensor-Valued Time Series</h2>

<h3>Description</h3>

<p>Estimation function for Tucker structure factor models of tensor-valued time series.
Two unfolding methods of the auto-covariance tensor, Time series Outer-Product Unfolding Procedure (TOPUP), Time series Inner-Product Unfolding Procedure (TIPUP),
are included, as determined by the value of <code>method</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">tenFM.est(x,r,h0=1,method='TIPUP',iter=TRUE,tol=1e-4,maxiter=100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p><code class="reqn">T \times d_1 \times \cdots \times d_K</code> tensor-valued time series.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r</code></td>
<td>
<p>input rank of factor tensor.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>h0</code></td>
<td>
<p>the number of lags used in auto-covariance tensor. If h0=0, covariance tensor is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>character string, specifying the type of the estimation method to be used. </p>

<dl>
<dt><code>"TIPUP",</code></dt>
<dd>
<p>TIPUP method.</p>
</dd>
<dt><code>"TOPUP",</code></dt>
<dd>
<p>TOPUP method.</p>
</dd>
</dl>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iter</code></td>
<td>
<p>boolean, specifying using an iterative approach or an non-iterative approach.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>tolerance in terms of the Frobenius norm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxiter</code></td>
<td>
<p>maximum number of iterations if error stays above <code>tol</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Tensor factor model with Tucker structure has the following form,
</p>
<p style="text-align: center;"><code class="reqn">X_t = F_t \times_{1} A_1 \times_{2} \cdots \times_{K} A_k + E_t,</code>
</p>

<p>where <code class="reqn">A_k</code> is the deterministic loading matrix of size <code class="reqn">d_k \times r_k</code> and <code class="reqn">r_k \ll d_k</code>,
the core tensor <code class="reqn">F_t</code> itself is a latent tensor factor process of dimension <code class="reqn">r_1 \times \cdots \times r_K</code>,
and the idiosyncratic noise tensor <code class="reqn">E_t</code> is uncorrelated (white) across time. Two estimation approaches, named TOPUP and TIPUP, are studied.
Time series Outer-Product Unfolding Procedure (TOPUP) are based on
</p>
<p style="text-align: center;"><code class="reqn"> {\rm{TOPUP}}_{k}(X_{1:T}) = \left(\sum_{t=h+1}^T \frac{{\rm{mat}}_{k}( X_{t-h}) \otimes {\rm{mat}}_k(X_t)} {T-h}, \ h=1,...,h_0 \right),</code>
</p>

<p>where <code class="reqn">h_0</code> is a predetermined positive integer, <code class="reqn">\otimes</code> is tensor product. Note that
<code class="reqn"> {\rm{TOPUP}}_k(\cdot)</code> is a function mapping a tensor time series to an order-5 tensor.
Time series Inner-Product Unfolding Procedure (TIPUP) replaces the tensor product in TOPUP with the inner product:
</p>
<p style="text-align: center;"><code class="reqn"> {\rm{TIPUP}}_k(X_{1:T})={\rm{mat}}_1\left(\sum_{t=h+1}^T \frac{{\rm{mat}}_k(X_{t-h}) {\rm{mat}}_k^\top(X_t)} {T-h}, \ h=1,...,h_0 \right).</code>
</p>



<h3>Value</h3>

<p>returns a list containing the following:</p>

<dl>
<dt><code>Ft</code></dt>
<dd>
<p>estimated factor processes of dimension <code class="reqn">T \times r_1 \times r_2 \times \cdots \times r_k</code>.</p>
</dd>
<dt><code>Ft.all</code></dt>
<dd>
<p>Summation of factor processes over time, of dimension <code class="reqn">r_1,r_2,\cdots,r_k</code>.</p>
</dd>
<dt><code>Q</code></dt>
<dd>
<p>a list of estimated factor loading matrices <code class="reqn">Q_1,Q_2,\cdots,Q_K</code>. </p>
</dd>
<dt><code>x.hat</code></dt>
<dd>
<p>fitted signal tensor, of dimension <code class="reqn">T \times d_1 \times d_2 \times \cdots \times d_k</code>.</p>
</dd>
<dt><code>niter</code></dt>
<dd>
<p>number of iterations.</p>
</dd>
<dt><code>fnorm.resid</code></dt>
<dd>
<p>Frobenius norm of residuals, divide the Frobenius norm of the original tensor.</p>
</dd>
</dl>
<h3>References</h3>

<p>Chen, Rong, Dan Yang, and Cun-Hui Zhang. "Factor models for high-dimensional tensor time series." Journal of the American Statistical Association (2021): 1-59.
</p>
<p>Han, Yuefeng, Rong Chen, Dan Yang, and Cun-Hui Zhang. "Tensor factor model estimation by iterative projection." arXiv preprint arXiv:2006.02611 (2020).
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(333)
dims &lt;- c(16,18,20) # dimensions of tensor time series
r &lt;- c(3,3,3)  # dimensions of factor series
Ft &lt;- tenAR.sim(t=100, dim=r, R=1, P=1, rho=0.9, cov='iid')
lambda &lt;- sqrt(prod(dims))
x &lt;- tenFM.sim(Ft,dims=dims,lambda=lambda,A=NULL,cov='iid') # generate t*dims tensor time series
result &lt;- tenFM.est(x,r,h0=1,iter=TRUE,method='TIPUP')  # Estimation
Ft &lt;- result$Ft
</code></pre>


</div>