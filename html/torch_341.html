<div class="container">

<table style="width: 100%;"><tr>
<td>nn_utils_weight_norm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>nn_utils_weight_norm</h2>

<h3>Description</h3>

<p>Applies weight normalization to a parameter in the given module.
</p>


<h3>Details</h3>

<div class="sourceCode"><pre>    \eqn{\mathbf{w} = g \dfrac{\mathbf{v}}{\|\mathbf{v}\|}}
</pre></div>
<p>Weight normalization is a reparameterization that decouples the magnitude
of a weight tensor from its direction. This replaces the parameter specified
by <code>name</code>  (e.g. <code>'weight'</code>) with two parameters: one specifying the
magnitude (e.g. <code>'weight_g'</code>) and one specifying the direction
(e.g. <code>'weight_v'</code>).
</p>


<h3>Value</h3>

<p>The original module with the weight_v and weight_g paramters.
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-nn_utils_weight_norm-new"><code>nn_utils_weight_norm$new()</code></a>
</p>
</li>
<li> <p><a href="#method-nn_utils_weight_norm-compute_weight"><code>nn_utils_weight_norm$compute_weight()</code></a>
</p>
</li>
<li> <p><a href="#method-nn_utils_weight_norm-apply"><code>nn_utils_weight_norm$apply()</code></a>
</p>
</li>
<li> <p><a href="#method-nn_utils_weight_norm-call"><code>nn_utils_weight_norm$call()</code></a>
</p>
</li>
<li> <p><a href="#method-nn_utils_weight_norm-recompute"><code>nn_utils_weight_norm$recompute()</code></a>
</p>
</li>
<li> <p><a href="#method-nn_utils_weight_norm-remove"><code>nn_utils_weight_norm$remove()</code></a>
</p>
</li>
<li> <p><a href="#method-nn_utils_weight_norm-clone"><code>nn_utils_weight_norm$clone()</code></a>
</p>
</li>
</ul>
<hr>
<a id="method-nn_utils_weight_norm-new"></a>



<h4>Method <code>new()</code>
</h4>



<h5>Usage</h5>

<div class="r"><pre>nn_utils_weight_norm$new(name, dim)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>name</code></dt>
<dd>
<p>(str, optional): name of weight parameter</p>
</dd>
<dt><code>dim</code></dt>
<dd>
<p>(int, optional): dimension over which to compute the norm</p>
</dd>
</dl>
</div>


<hr>
<a id="method-nn_utils_weight_norm-compute_weight"></a>



<h4>Method <code>compute_weight()</code>
</h4>



<h5>Usage</h5>

<div class="r"><pre>nn_utils_weight_norm$compute_weight(module, name = NULL, dim = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>module</code></dt>
<dd>
<p>(Module): containing module</p>
</dd>
<dt><code>name</code></dt>
<dd>
<p>(str, optional): name of weight parameter</p>
</dd>
<dt><code>dim</code></dt>
<dd>
<p>(int, optional): dimension over which to compute the norm</p>
</dd>
</dl>
</div>


<hr>
<a id="method-nn_utils_weight_norm-apply"></a>



<h4>Method <code>apply()</code>
</h4>



<h5>Usage</h5>

<div class="r"><pre>nn_utils_weight_norm$apply(module, name = NULL, dim = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>module</code></dt>
<dd>
<p>(Module): containing module</p>
</dd>
<dt><code>name</code></dt>
<dd>
<p>(str, optional): name of weight parameter</p>
</dd>
<dt><code>dim</code></dt>
<dd>
<p>(int, optional): dimension over which to compute the norm</p>
</dd>
</dl>
</div>


<hr>
<a id="method-nn_utils_weight_norm-call"></a>



<h4>Method <code>call()</code>
</h4>



<h5>Usage</h5>

<div class="r"><pre>nn_utils_weight_norm$call(module)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>module</code></dt>
<dd>
<p>(Module): containing module</p>
</dd>
</dl>
</div>


<hr>
<a id="method-nn_utils_weight_norm-recompute"></a>



<h4>Method <code>recompute()</code>
</h4>



<h5>Usage</h5>

<div class="r"><pre>nn_utils_weight_norm$recompute(module)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>module</code></dt>
<dd>
<p>(Module): containing module</p>
</dd>
</dl>
</div>


<hr>
<a id="method-nn_utils_weight_norm-remove"></a>



<h4>Method <code>remove()</code>
</h4>



<h5>Usage</h5>

<div class="r"><pre>nn_utils_weight_norm$remove(module, name = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>module</code></dt>
<dd>
<p>(Module): containing module</p>
</dd>
<dt><code>name</code></dt>
<dd>
<p>(str, optional): name of weight parameter</p>
</dd>
</dl>
</div>


<hr>
<a id="method-nn_utils_weight_norm-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>nn_utils_weight_norm$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>Note</h3>

<p>The pytorch Weight normalization is implemented via a hook that recomputes
the weight tensor from the magnitude and direction before every <code>forward()</code>
call. Since torch for R still do not support hooks, the weight recomputation
need to be done explicitly inside the <code>forward()</code> definition trough a call of
the <code>recompute()</code> method. See examples.
</p>
<p>By default, with <code>dim = 0</code>, the norm is computed independently per output
channel/plane. To compute a norm over the entire weight tensor, use
<code>dim = NULL</code>.
</p>
<p>@references https://arxiv.org/abs/1602.07868
</p>


<h3>Examples</h3>

<pre><code class="language-R">if (torch_is_installed()) {
x = nn_linear(in_features = 20, out_features = 40)
weight_norm = nn_utils_weight_norm$new(name = 'weight', dim = 2)
weight_norm$apply(x)
x$weight_g$size()
x$weight_v$size()
x$weight

# the recompute() method recomputes the weight using g and v. It must be called
# explicitly inside `forward()`.
weight_norm$recompute(x)

}
</code></pre>


</div>