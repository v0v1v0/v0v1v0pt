<div class="container">

<table style="width: 100%;"><tr>
<td>tfd_autoregressive</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Autoregressive distribution</h2>

<h3>Description</h3>

<p>The Autoregressive distribution enables learning (often) richer multivariate
distributions by repeatedly applying a <a href="https://en.wikipedia.org/wiki/Diffeomorphism">diffeomorphic</a>
transformation (such as implemented by <code>Bijector</code>s).
</p>


<h3>Usage</h3>

<pre><code class="language-R">tfd_autoregressive(
  distribution_fn,
  sample0 = NULL,
  num_steps = NULL,
  validate_args = FALSE,
  allow_nan_stats = TRUE,
  name = "Autoregressive"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>distribution_fn</code></td>
<td>
<p>Function which constructs a <code>tfd$Distribution</code>-like instance from a <code>Tensor</code>
(e.g., <code>sample0</code>). The function must respect the "autoregressive property",
i.e., there exists a permutation of event such that each coordinate is a
diffeomorphic function of on preceding coordinates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sample0</code></td>
<td>
<p>Initial input to <code>distribution_fn</code>; used to
build the distribution in <code style="white-space: pre;">⁠__init__⁠</code> which in turn specifies this
distribution's properties, e.g., <code>event_shape</code>, <code>batch_shape</code>, <code>dtype</code>.
If unspecified, then <code>distribution_fn</code> should be default constructable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num_steps</code></td>
<td>
<p>Number of times <code>distribution_fn</code> is composed from samples,
e.g., <code>num_steps=2</code> implies <code>distribution_fn(distribution_fn(sample0)$sample(n))$sample()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>validate_args</code></td>
<td>
<p>Logical, default FALSE. When TRUE distribution parameters are checked
for validity despite possibly degrading runtime performance. When FALSE invalid inputs may
silently render incorrect outputs. Default value: FALSE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>allow_nan_stats</code></td>
<td>
<p>Logical, default TRUE. When TRUE, statistics (e.g., mean, mode, variance)
use the value NaN to indicate the result is undefined. When FALSE, an exception is raised if
one or more of the statistic's batch members are undefined.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>name prefixed to Ops created by this class.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Regarding terminology,
"Autoregressive models decompose the joint density as a product of
conditionals, and model each conditional in turn. Normalizing flows
transform a base density (e.g. a standard Gaussian) into the target density
by an invertible transformation with tractable Jacobian." (Papamakarios et al., 2016)
</p>
<p>In other words, the "autoregressive property" is equivalent to the
decomposition, <code style="white-space: pre;">⁠p(x) = prod{ p(x[i] | x[0:i]) : i=0, ..., d }⁠</code>. The provided
<code>shift_and_log_scale_fn</code>, <code>tfb_masked_autoregressive_default_template</code>, achieves
this property by zeroing out weights in its <code>masked_dense</code> layers.
Practically speaking the autoregressive property means that there exists a
permutation of the event coordinates such that each coordinate is a
diffeomorphic function of only preceding coordinates
(van den Oord et al., 2016).
</p>
<p>Mathematical Details
</p>
<p>The probability function is
</p>
<div class="sourceCode"><pre>prob(x; fn, n) = fn(x).prob(x)
</pre></div>
<p>And a sample is generated by
</p>
<div class="sourceCode"><pre>x = fn(...fn(fn(x0).sample()).sample()).sample()
</pre></div>
<p>where the ellipses (<code>...</code>) represent <code>n-2</code> composed calls to <code>fn</code>, <code>fn</code>
constructs a <code>tfd$Distribution</code>-like instance, and <code>x0</code> is a fixed initializing <code>Tensor</code>.
</p>


<h3>Value</h3>

<p>a distribution instance.
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://arxiv.org/abs/1705.07057">George Papamakarios, Theo Pavlakou, and Iain Murray. Masked Autoregressive Flow for Density Estimation. In <em>Neural Information Processing Systems</em>, 2017.</a>
</p>
</li>
<li> <p><a href="https://arxiv.org/abs/1606.05328">Aaron van den Oord, Nal Kalchbrenner, Oriol Vinyals, Lasse Espeholt, Alex Graves, and Koray Kavukcuoglu. Conditional Image Generation with PixelCNN Decoders. In <em>Neural Information Processing Systems</em>, 2016.</a>
</p>
</li>
</ul>
<h3>See Also</h3>

<p>For usage examples see e.g. <code>tfd_sample()</code>, <code>tfd_log_prob()</code>, <code>tfd_mean()</code>.
</p>
<p>Other distributions: 
<code>tfd_batch_reshape()</code>,
<code>tfd_bates()</code>,
<code>tfd_bernoulli()</code>,
<code>tfd_beta_binomial()</code>,
<code>tfd_beta()</code>,
<code>tfd_binomial()</code>,
<code>tfd_categorical()</code>,
<code>tfd_cauchy()</code>,
<code>tfd_chi2()</code>,
<code>tfd_chi()</code>,
<code>tfd_cholesky_lkj()</code>,
<code>tfd_continuous_bernoulli()</code>,
<code>tfd_deterministic()</code>,
<code>tfd_dirichlet_multinomial()</code>,
<code>tfd_dirichlet()</code>,
<code>tfd_empirical()</code>,
<code>tfd_exp_gamma()</code>,
<code>tfd_exp_inverse_gamma()</code>,
<code>tfd_exponential()</code>,
<code>tfd_gamma_gamma()</code>,
<code>tfd_gamma()</code>,
<code>tfd_gaussian_process_regression_model()</code>,
<code>tfd_gaussian_process()</code>,
<code>tfd_generalized_normal()</code>,
<code>tfd_geometric()</code>,
<code>tfd_gumbel()</code>,
<code>tfd_half_cauchy()</code>,
<code>tfd_half_normal()</code>,
<code>tfd_hidden_markov_model()</code>,
<code>tfd_horseshoe()</code>,
<code>tfd_independent()</code>,
<code>tfd_inverse_gamma()</code>,
<code>tfd_inverse_gaussian()</code>,
<code>tfd_johnson_s_u()</code>,
<code>tfd_joint_distribution_named_auto_batched()</code>,
<code>tfd_joint_distribution_named()</code>,
<code>tfd_joint_distribution_sequential_auto_batched()</code>,
<code>tfd_joint_distribution_sequential()</code>,
<code>tfd_kumaraswamy()</code>,
<code>tfd_laplace()</code>,
<code>tfd_linear_gaussian_state_space_model()</code>,
<code>tfd_lkj()</code>,
<code>tfd_log_logistic()</code>,
<code>tfd_log_normal()</code>,
<code>tfd_logistic()</code>,
<code>tfd_mixture_same_family()</code>,
<code>tfd_mixture()</code>,
<code>tfd_multinomial()</code>,
<code>tfd_multivariate_normal_diag_plus_low_rank()</code>,
<code>tfd_multivariate_normal_diag()</code>,
<code>tfd_multivariate_normal_full_covariance()</code>,
<code>tfd_multivariate_normal_linear_operator()</code>,
<code>tfd_multivariate_normal_tri_l()</code>,
<code>tfd_multivariate_student_t_linear_operator()</code>,
<code>tfd_negative_binomial()</code>,
<code>tfd_normal()</code>,
<code>tfd_one_hot_categorical()</code>,
<code>tfd_pareto()</code>,
<code>tfd_pixel_cnn()</code>,
<code>tfd_poisson_log_normal_quadrature_compound()</code>,
<code>tfd_poisson()</code>,
<code>tfd_power_spherical()</code>,
<code>tfd_probit_bernoulli()</code>,
<code>tfd_quantized()</code>,
<code>tfd_relaxed_bernoulli()</code>,
<code>tfd_relaxed_one_hot_categorical()</code>,
<code>tfd_sample_distribution()</code>,
<code>tfd_sinh_arcsinh()</code>,
<code>tfd_skellam()</code>,
<code>tfd_spherical_uniform()</code>,
<code>tfd_student_t_process()</code>,
<code>tfd_student_t()</code>,
<code>tfd_transformed_distribution()</code>,
<code>tfd_triangular()</code>,
<code>tfd_truncated_cauchy()</code>,
<code>tfd_truncated_normal()</code>,
<code>tfd_uniform()</code>,
<code>tfd_variational_gaussian_process()</code>,
<code>tfd_vector_diffeomixture()</code>,
<code>tfd_vector_exponential_diag()</code>,
<code>tfd_vector_exponential_linear_operator()</code>,
<code>tfd_vector_laplace_diag()</code>,
<code>tfd_vector_laplace_linear_operator()</code>,
<code>tfd_vector_sinh_arcsinh_diag()</code>,
<code>tfd_von_mises_fisher()</code>,
<code>tfd_von_mises()</code>,
<code>tfd_weibull()</code>,
<code>tfd_wishart_linear_operator()</code>,
<code>tfd_wishart_tri_l()</code>,
<code>tfd_wishart()</code>,
<code>tfd_zipf()</code>
</p>


</div>