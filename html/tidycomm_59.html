<div class="container">

<table style="width: 100%;"><tr>
<td>test_icr</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Perform an intercoder reliability test</h2>

<h3>Description</h3>

<p>Performs an intercoder reliability test by computing various intercoder
reliability estimates for the included variables
</p>


<h3>Usage</h3>

<pre><code class="language-R">test_icr(
  data,
  unit_var,
  coder_var,
  ...,
  levels = NULL,
  na.omit = FALSE,
  agreement = TRUE,
  holsti = TRUE,
  kripp_alpha = TRUE,
  cohens_kappa = FALSE,
  fleiss_kappa = FALSE,
  brennan_prediger = FALSE,
  lotus = FALSE,
  s_lotus = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>a tibble or a tdcmm model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>unit_var</code></td>
<td>
<p>Variable with unit identifiers</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coder_var</code></td>
<td>
<p>Variable with coder identifiers</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Variables to compute intercoder reliability estimates for. Leave
empty to compute for all variables (excluding <code>unit_var</code> and 'coder_var“)
in data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>levels</code></td>
<td>
<p>Optional named vector with levels of test variables</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.omit</code></td>
<td>
<p>Logical indicating whether <code>NA</code> values should be stripped
before computation. Defaults to <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>agreement</code></td>
<td>
<p>Logical indicating whether simple percent agreement should
be computed. Defaults to <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>holsti</code></td>
<td>
<p>Logical indicating whether Holsti's reliability estimate
(mean pairwise agreement) should be computed. Defaults to <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kripp_alpha</code></td>
<td>
<p>Logical indicating whether Krippendorff's Alpha should
be computed. Defaults to <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cohens_kappa</code></td>
<td>
<p>Logical indicating whether Cohen's Kappa should
be computed. Defaults to <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fleiss_kappa</code></td>
<td>
<p>Logical indicating whether Fleiss' Kappa should
be computed. Defaults to <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>brennan_prediger</code></td>
<td>
<p>Logical indicating whether Brennan &amp; Prediger's Kappa
should be computed (extension to 3+ coders as proposed by von Eye (2006)).
Defaults to <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lotus</code></td>
<td>
<p>Logical indicating whether Fretwurst's Lotus should be
computed. Defaults to <code>FALSE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>s_lotus</code></td>
<td>
<p>Logical indicating whether Fretwurst's standardized Lotus
(S-Lotus) should be computed. Defaults to <code>FALSE</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a tdcmm model
</p>


<h3>References</h3>

<p>Brennan, R. L., &amp; Prediger, D. J. (1981). Coefficient Kappa: Some
uses, misuses, and alternatives. Educational and Psychological Measurement,
41(3), 687-699. https://doi.org/10.1177/001316448104100307
</p>
<p>Cohen, J. (1960). A coefficient of agreement for nominal scales.
Educational and Psychological Measurement, 20(1), 37-46.
https://doi.org/10.1177/001316446002000104
</p>
<p>Fleiss, J. L. (1971). Measuring nominal scale agreement among many raters.
Psychological Bulletin, 76(5), 378-382. https://doi.org/10.1037/h0031619
</p>
<p>Fretwurst, B. (2015). Reliabilität und Validität von Inhaltsanalysen.
Mit Erläuterungen zur Berechnung des Reliabilitätskoeffizienten „Lotus“ mit SPSS.
In W. Wirth, K. Sommer, M. Wettstein, &amp; J. Matthes (Ed.),
Qualitätskriterien in der Inhaltsanalyse (S. 176–203). Herbert von Halem.
</p>
<p>Krippendorff, K. (2011). Computing Krippendorff's Alpha-Reliability.
Retrieved from http://repository.upenn.edu/asc_papers/43
</p>
<p>von Eye, A. (2006). An Alternative to Cohen's Kappa. European Psychologist, 11(1),
12-24. https://doi.org/10.1027/1016-9040.11.1.12
</p>


<h3>Examples</h3>

<pre><code class="language-R">fbposts %&gt;% test_icr(post_id, coder_id, pop_elite, pop_othering)
fbposts %&gt;% test_icr(post_id, coder_id, levels = c(n_pictures = "ordinal"), fleiss_kappa = TRUE)

</code></pre>


</div>