<div class="container">

<table style="width: 100%;"><tr>
<td>layer_filter_response_normalization</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>FilterResponseNormalization</h2>

<h3>Description</h3>

<p>Filter response normalization layer.
</p>


<h3>Usage</h3>

<pre><code class="language-R">layer_filter_response_normalization(
  object,
  epsilon = 1e-06,
  axis = c(1, 2),
  beta_initializer = "zeros",
  gamma_initializer = "ones",
  beta_regularizer = NULL,
  gamma_regularizer = NULL,
  beta_constraint = NULL,
  gamma_constraint = NULL,
  learned_epsilon = FALSE,
  learned_epsilon_constraint = NULL,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>Model or layer object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>epsilon</code></td>
<td>
<p>Small positive float value added to variance to avoid dividing by zero.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>axis</code></td>
<td>
<p>List of axes that should be normalized. This should represent the spatial dimensions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta_initializer</code></td>
<td>
<p>Initializer for the beta weight.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma_initializer</code></td>
<td>
<p>Initializer for the gamma weight.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta_regularizer</code></td>
<td>
<p>Optional regularizer for the beta weight.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma_regularizer</code></td>
<td>
<p>Optional regularizer for the gamma weight.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta_constraint</code></td>
<td>
<p>Optional constraint for the beta weight.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma_constraint</code></td>
<td>
<p>Optional constraint for the gamma weight.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>learned_epsilon</code></td>
<td>
<p>(bool) Whether to add another learnable epsilon parameter or not.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>learned_epsilon_constraint</code></td>
<td>
<p>learned_epsilon_constraint</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>Optional name for the layer</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Filter Response Normalization (FRN), a normalization
method that enables models trained with per-channel
normalization to achieve high accuracy. It performs better than
all other normalization techniques for small batches and is par
with Batch Normalization for bigger batch sizes.
</p>


<h3>Value</h3>

<p>A tensor
</p>


<h3>Note</h3>

<p>Input shape Arbitrary. Use the keyword argument 'input_shape' (list of integers,
does not include the samples axis) when using this layer as the first layer in a model.
This layer, as of now, works on a 4-D tensor where the tensor should have the
shape [N X H X W X C] TODO: Add support for NCHW data format and FC layers. Output shape
Same shape as input. References - [Filter Response Normalization Layer: Eliminating Batch
Dependence in the training of Deep Neural Networks] (https://arxiv.org/abs/1911.09737)
</p>


</div>