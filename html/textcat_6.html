<div class="container">

<table style="width: 100%;"><tr>
<td>textcat_profile_db</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Textcat Profile Dbs</h2>

<h3>Description</h3>

<p>Create <code class="reqn">n</code>-gram profile dbs for text categorization.
</p>


<h3>Usage</h3>

<pre><code class="language-R">textcat_profile_db(x, id = NULL, method = NULL, ...,
                   options = list(), profiles = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a character vector of text documents, or an <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> object of text
documents extractable via <code>as.character</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>id</code></td>
<td>
<p>a character vector giving the categories of the texts to be 
recycled to the length of <code>x</code>, or <code>NULL</code> (default),
indicating to treat each text document separately.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>a character string specifying a built-in method, or a
user-defined function for computing distances between <code class="reqn">n</code>-gram
profiles, or <code>NULL</code> (default), corresponding to using the
method and options used for creating <code>profiles</code> if this is not
<code>NULL</code>, or otherwise the current value of <span class="pkg">textcat</span> option
<code>profile_method</code> (see <code>textcat_options</code>).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>options to be passed to the method for creating profiles.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>options</code></td>
<td>
<p>a list of such options.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>profiles</code></td>
<td>
<p>a textcat profile db object.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The text documents are split according to the given categories, and
<code class="reqn">n</code>-gram profiles are computed using the specified method, with
options either those used for creating <code>profiles</code> if this is not
<code>NULL</code>, or by combining the options given in <code>...</code> and
<code>options</code> and merging with the default profile options specified
by the <span class="pkg">textcat</span> option <code>profile_options</code> using <em>exact</em>
name matching.  The method and options employed for building the db
are stored in the db as attributes <code>"method"</code> and
<code>"options"</code>, respectively.
</p>
<p>There is a <code>c</code> method for combining profile dbs provided
that these have identical options.  There are also a <code>[</code> method
for subscripting and <code>as.matrix</code> and
<code>as.simple_triplet_matrix</code> methods to
“export” the profiles to a dense matrix or the sparse simple
triplet matrix representation provided by package <span class="pkg">slam</span>,
respectively.
</p>
<p>Currently, the only available built-in method is <code>"textcnt"</code>,
which has the following options:
</p>

<dl>
<dt>
<code>n</code>:</dt>
<dd>
<p>A numeric vector giving the numbers of characters or bytes in the
<code class="reqn">n</code>-gram profiles.
</p>
<p>Default: <code>1 : 5</code>.
</p>
</dd>
<dt>
<code>split</code>:</dt>
<dd>
<p>The regular expression pattern to be used in word splitting.
</p>
<p>Default: <code>"[[:space:][:punct:][:digit:]]+"</code>.
</p>
</dd>
<dt>
<code>perl</code>:</dt>
<dd>
<p>A logical indicating whether to use Perl-compatible regular
expressions in word splitting.
</p>
<p>Default: <code>FALSE</code>.
</p>
</dd>
<dt>
<code>tolower</code>:</dt>
<dd>
<p>A logical indicating whether to transform texts to lower case
(after word splitting).
</p>
<p>Default: <code>TRUE</code>.
</p>
</dd>
<dt>
<code>reduce</code>:</dt>
<dd>
<p>A logical indicating whether a representation of <code class="reqn">n</code>-grams
more efficient than the one used by Cavnar and Trenkle should be
employed.
</p>
<p>Default: <code>TRUE</code>.
</p>
</dd>
<dt>
<code>useBytes</code>:</dt>
<dd>
<p>A logical indicating whether to use byte <code class="reqn">n</code>-grams rather than
character <code class="reqn">n</code>-grams.
</p>
<p>Default: <code>FALSE</code>.
</p>
</dd>
<dt>
<code>ignore</code>:</dt>
<dd>
<p>a character vector of <code class="reqn">n</code>-grams to be ignored when computing
<code class="reqn">n</code>-gram profiles.
</p>
<p>Default: <code>"_"</code> (corresponding to a word boundary).
</p>
</dd>
<dt>
<code>size</code>:</dt>
<dd>
<p>The maximal number of <code class="reqn">n</code>-grams used for a profile.
</p>
<p>Default: <code>1000L</code>.
</p>
</dd>
</dl>
<p>This method uses <code>textcnt</code> in package <span class="pkg">tau</span> for
computing <code class="reqn">n</code>-gram profiles, with <code>n</code>, <code>split</code>,
<code>perl</code> and <code>useBytes</code> corresponding to the respective
<code>textcnt</code> arguments, and option <code>reduce</code> setting argument
<code>marker</code> as needed.  <code class="reqn">N</code>-grams listed in option <code>ignore</code>
are removed, and only the most frequent remaining ones retained, with
the maximal number given by option <code>size</code>.  
</p>
<p>Unless the profile db uses bytes rather than characters (i.e., option
<code>useBytes</code> is <code>TRUE</code>), text documents in <code>x</code> containing
non-ASCII characters must declare their encoding (see
<code>Encoding</code>), and will be re-encoded to UTF-8.
</p>
<p>Note that option <code>n</code> specifies <em>all</em> numbers of characters
or bytes to be used in the profiles, and not just the maximal number:
e.g., taking <code>n = 3</code> will create profiles only containing
tri-grams.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Obtain the texts of the standard licenses shipped with R.
files &lt;- dir(file.path(R.home("share"), "licenses"), "^[A-Z]",
             full.names = TRUE)
texts &lt;- sapply(files,
                function(f) paste(readLines(f), collapse = "\n"))
names(texts) &lt;- basename(files)
## Build a profile db using the same method and options as for building
## the ECIMCI character profiles.
profiles &lt;- textcat_profile_db(texts, profiles = ECIMCI_profiles)
## Inspect the 10 most frequent n-grams in each profile.
lapply(profiles, head, 10L)
## Combine into one frequency table.
tab &lt;- as.matrix(profiles)
tab[, 1 : 10]
## Determine languages.
textcat(profiles, ECIMCI_profiles)
</code></pre>


</div>