<div class="container">

<table style="width: 100%;"><tr>
<td>MeilaVariationOfInformation</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Use variation of clustering information to compare pairs of splits</h2>

<h3>Description</h3>

<p>Compare a pair of splits viewed as clusterings of taxa, using the variation
of clustering information proposed by (Meila 2007).
</p>


<h3>Usage</h3>

<pre><code class="language-R">MeilaVariationOfInformation(split1, split2)

MeilaMutualInformation(split1, split2)
</code></pre>


<h3>Arguments</h3>

<table><tr style="vertical-align: top;">
<td><code>split1, split2</code></td>
<td>
<p>Logical vectors listing leaves in a consistent order,
identifying each leaf as a member of the ingroup (<code>TRUE</code>) or outgroup
(<code>FALSE</code>) of the split in question.</p>
</td>
</tr></table>
<h3>Details</h3>

<p>This is equivalent to the mutual clustering information
(Vinh et al. 2010).
For the total information content, multiply the VoI by the number of leaves.
</p>


<h3>Value</h3>

<p><code>MeilaVariationOfInformation()</code> returns the variation of (clustering)
information, measured in bits.
</p>
<p><code>MeilaMutualInformation()</code> returns the mutual information,
measured in bits.
</p>


<h3>Author(s)</h3>

<p><a href="https://orcid.org/0000-0001-5660-1727">Martin R. Smith</a>
(<a href="mailto:martin.smith@durham.ac.uk">martin.smith@durham.ac.uk</a>)
</p>


<h3>References</h3>

<p>Meila M (2007).
“Comparing clusterings—an information based distance.”
<em>Journal of Multivariate Analysis</em>, <b>98</b>(5), 873–895.
<a href="https://doi.org/10.1016/j.jmva.2006.11.013">doi:10.1016/j.jmva.2006.11.013</a>.<br><br> Vinh NX, Epps J, Bailey J (2010).
“Information theoretic measures for clusterings comparison: variants, properties, normalization and correction for chance.”
<em>Journal of Machine Learning Research</em>, <b>11</b>, 2837–2854.
<a href="https://doi.org/10.1145/1553374.1553511">doi:10.1145/1553374.1553511</a>.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Maximum variation = information content of each split separately
A &lt;- TRUE
B &lt;- FALSE
MeilaVariationOfInformation(c(A, A, A, B, B, B), c(A, A, A, A, A, A))
Entropy(c(3, 3) / 6) + Entropy(c(0, 6) / 6)

# Minimum variation = 0
MeilaVariationOfInformation(c(A, A, A, B, B, B), c(A, A, A, B, B, B))

# Not always possible for two evenly-sized splits to reach maximum
# variation of information
Entropy(c(3, 3) / 6) * 2  # = 2
MeilaVariationOfInformation(c(A, A, A,B ,B, B), c(A, B, A, B, A, B)) # &lt; 2

# Phylogenetically uninformative groupings contain spliting information
Entropy(c(1, 5) / 6)
MeilaVariationOfInformation(c(B, A, A, A, A, A), c(A, A, A, A, A, B))
</code></pre>


</div>