<div class="container">

<table style="width: 100%;"><tr>
<td>run_TIGER</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Run TIGER to eliminate technical variation</h2>

<h3>Description</h3>

<p>Use TIGER algorithm to eliminate the technical variation in metabolomics data. TIGER supports targeted and untargeted metabolomics data and is competent to perform both intra- and inter-batch technical variation removal.
</p>


<h3>Usage</h3>

<pre><code class="language-R">run_TIGER(
  test_samples,
  train_samples,
  col_sampleID,
  col_sampleType,
  col_batchID,
  col_order = NULL,
  col_position = NULL,
  targetVal_external = NULL,
  targetVal_method = c("mean", "median"),
  targetVal_batchWise = FALSE,
  targetVal_removeOutlier = !targetVal_batchWise,
  selectVar_external = NULL,
  selectVar_corType = c("cor", "pcor"),
  selectVar_corMethod = c("pearson", "spearman"),
  selectVar_minNum = 5,
  selectVar_maxNum = 10,
  selectVar_batchWise = FALSE,
  mtry_percent = seq(0.2, 0.8, 0.2),
  nodesize_percent = seq(0.2, 0.8, 0.2),
  ...,
  parallel.cores = 2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>test_samples</code></td>
<td>
<p>(required) a data.frame containing the samples to be corrected (for example, subject samples). This data.frame should contain columns of
</p>

<ul>
<li>
<p> sample ID (required): name or label for each sample,
</p>
</li>
<li>
<p> sample type (required): indicating the type of each sample,
</p>
</li>
<li>
<p> batch ID (required): the batch of each sample,
</p>
</li>
<li>
<p> order information (optional): injection order or temporal information of each sample,
</p>
</li>
<li>
<p> position information (optional): well position of each sample,
</p>
</li>
<li>
<p> metabolite values (required): values to be normalised. Infinite values are not allowed.
</p>
</li>
</ul>
<p>Row: sample. Column: variable. See Examples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>train_samples</code></td>
<td>
<p>(required) a data.frame containing the quality control (QC) samples used for model training. The columns in this data.frame should correspond to the columns in <code>test_samples</code>. And <code>test_samples</code> and <code>train_samples</code> should have the identical column names.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>col_sampleID</code></td>
<td>
<p>(required) a character string indicating the name of the column that specifies the sample ID of each sample. The values in this column will not affect the data correction process but can act as labels for different samples. See Examples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>col_sampleType</code></td>
<td>
<p>(required) a character string indicating the name of the column that specifies the type (such as QC1, QC2, subject) of each sample. This column can be used to indicate different kinds of QC samples in <code>train_samples</code>. QC samples of the <strong>same type</strong> should have the <strong>same type name</strong>. See Examples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>col_batchID</code></td>
<td>
<p>(required) a character string indicating the name of the column that specifies the batch ID of each sample. See Examples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>col_order</code></td>
<td>
<p>(optional) <code>NULL</code> or a character string indicating the name of the column that contains the injection order or temporal information (numeric values). This can explicitly ask the algorithm capture the technical variation introduced by injection order, which might be useful when your data have very obvious temporal drifts. If <code>NULL</code> (default), <code>train_samples</code> and <code>test_samples</code> should have <strong>No</strong> column contains injection order information.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>col_position</code></td>
<td>
<p>(optional) <code>NULL</code> or a character string indicating the name of the column that contains the well position information (numeric values). This can explicitly ask the algorithm capture the technical variation introduced by well position, which might be useful when the well position has a great impact during data acquisition. If <code>NULL</code> (default), <code>train_samples</code> and <code>test_samples</code> should have <strong>No</strong> column contains well position information.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>targetVal_external</code></td>
<td>
<p>(optional) a list generated by function <code>compute_targetVal</code>. See Details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>targetVal_method</code></td>
<td>
<p>a character string specifying how target values are to be computed. Can be <code>"mean"</code> (default) or <code>"median"</code>. Ignored if a list of external target values has been assigned to  <code>targetVal_external</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>targetVal_batchWise</code></td>
<td>
<p>logical. If <code>TRUE</code>, the target values will be computed based on each batch, otherwise, based on the whole dataset. Setting <code>TRUE</code> might be useful if your dataset has very obvious batch effects, but this may also make the algorithm less robust. Default: <code>FALSE</code>. Ignored if a list of external target values has been assigned to  <code>targetVal_external</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>targetVal_removeOutlier</code></td>
<td>
<p>logical. If <code>TRUE</code>, outliers will be removed before the computation. Outliers are determined with 1.5 * IQR (interquartile range) rule. We recommend turning this off when the target values are computed based on batches. Default: <code>!targetVal_batchWise</code>. Ignored if a list of external target values has been assigned to  <code>targetVal_external</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selectVar_external</code></td>
<td>
<p>(optional) a list generated by function <code>select_variable</code>. See Details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selectVar_corType</code></td>
<td>
<p>a character string indicating correlation (<code>"cor"</code>, default) or partial correlation (<code>"pcor"</code>) is to be used. Can be abbreviated. Ignored if a list of selected variables has been assigned to <code>selectVar_external</code>. <strong>Note</strong>: computing partial correlations of a large dataset can be very time-consuming.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selectVar_corMethod</code></td>
<td>
<p>a character string indicating which correlation coefficient is to be computed. One of <code>"spearman"</code> (default) or <code>"pearson"</code>. Can be abbreviated. Ignored if a list of selected variables has been assigned to <code>selectVar_external</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selectVar_minNum</code></td>
<td>
<p>an integer specifying the minimum number of the selected metabolite variables (injection order and well position are not regarded as metabolite variables). If <code>NULL</code>, no limited, but 1 at least. Default: <code>5</code>. Ignored if a list of selected variables has been assigned to <code>selectVar_external</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selectVar_maxNum</code></td>
<td>
<p>an integer specifying the maximum number of the selected metabolite variables (injection order and well position are not regarded as metabolite variables). If <code>NULL</code>, no limited, but no more than the number of all available metabolite variables. Default: <code>10</code>. Ignored if a list of selected variables has been assigned to <code>selectVar_external</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selectVar_batchWise</code></td>
<td>
<p>(advanced) logical. Specify whether the variable selection should be performed based on each batch. Default: <code>FALSE</code>. Ignored if a list of selected variables has been assigned to <code>selectVar_external</code>. <strong>Note</strong>: the support of batch-wise variable selection is provided for data requiring special processing (for example, data with strong batch effects). But in most case, batch-wise variable selection is not necessary. Setting <code>TRUE</code> can make the algorithm less robust.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mtry_percent</code></td>
<td>
<p>(advanced) a numeric vector indicating the percentages of selected variables randomly sampled as candidates at each split when training random forest models (base learners). <strong>Note</strong>: providing more arguments will include more base learners into the ensemble model, which will increase the processing time. Default: <code>seq(0.2, 0.8, 0.2)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nodesize_percent</code></td>
<td>
<p>(advanced) a numeric vector indicating the percentages of sample size used as the minimum sizes of the terminal nodes in random forest models (base learners). <strong>Note</strong>: providing more arguments will include more base learners into the ensemble model, which will increase the processing time. Default: <code>seq(0.2, 0.8, 0.2)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>(advanced) optional arguments (except <code>mtry</code> and <code>nodesize</code>) to be passed to <code>randomForest</code> for model training. Arguments <code>mtry</code> and <code>nodesize</code> are determined by <code>mtry_percent</code> and <code>nodesize_percent</code>. See <code>randomForest</code> and Examples. <strong>Note</strong>: providing more arguments will include more base learners into the ensemble model, which will increase the processing time.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parallel.cores</code></td>
<td>
<p>an integer (== -1 or &gt;= 1) specifying the number of cores for parallel computation. Setting <code>-1</code> to run with all cores. Default: <code>2</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>TIGER can effectively process the datasets with its default setup. The following hyperparameters are provided to customise the algorithm and achieve the best possible performance. These hyperparameters are also practical for some special purposes (such as cross-kit adjustment, longitudinal dataset correction) or datasets requiring special processing (for example, data with very strong temporal drifts or batch effects). We recommend users to examine the normalised result with different metrics, such as RSD (relative standard deviation), MAPE (mean absolute percentage error) and PCA (principal component analysis), especially when using advanced options of TIGER.
</p>
<p><strong>Hyperparameters for target value computation</strong>
</p>

<ul>
<li> <p><code>targetVal_external</code>
</p>
<p>TIGER by default captures and eliminate the technical variation within the input dataset, and the target values are automatically computed from <code>train_samples</code>. The target values can also be calculated from a reference dataset using function <code>compute_targetVal</code> and then passed to this function as an argument. This will enable TIGER to align <code>test_samples</code> with the reference dataset. In this case, <code>train_samples</code> is still the accompanying QC samples of <code>test_samples</code>. And argument <code>targetVal_external</code> accepts external target values (a list). If the list of external target values is provided, values in <code>targetVal_method</code>, <code>targetVal_batchWise</code> and <code>targetVal_removeOutlier</code> will be ignored.
</p>
</li>
<li> <p><code>targetVal_method</code>
</p>
<p>The target values can be the mean or median values of metabolite values. The target values of different kinds of QC samples are computed separately. <code>"mean"</code> is recommended here, but the optimal selection can differ for different datasets.
</p>
</li>
<li> <p><code>targetVal_batchWise</code>
</p>
<p>The target values can be computed from the whole dataset or from different batches. By default, the target values are computed based on the whole dataset. Computing based on batches (<code>targetVal_batchWise = TRUE</code>) is only recommended when the samples has very strong batch effects. For example, we set this as <code>TRUE</code> when normalising WaveICA's Amide dataset in our original paper.
</p>
</li>
<li>  <p><code>targetVal_removeOutlier</code>
</p>
<p>If computing is based on the whole dataset (<code>targetVal_batchWise = TRUE</code>), users can remove the outliers in each metabolite by setting <code>targetVal_removeOutlier</code> as <code>TRUE</code>. This can weaken the impact of extreme values. If <code>targetVal_batchWise = FALSE</code>, it is generally not recommended to remove outliers, as we assume the input data have strong batch effects and contain extreme valuesâ€”we hope TIGER can take these into account. Code for checking outliers is adapted from <code>boxplot.stats</code>.
</p>
</li>
</ul>
<p><strong>Hyperparameters for variable selection</strong>
</p>

<ul>
<li> <p><code>selectVar_external</code>:
</p>
<p>This argument accepts a list of selected variables generated by <code>select_variable</code>. This is helpful when you want to use the same selected variables to correct several datasets. You can also pass a self-defined list to this argument, as long as the self-defined list has similar data structure as the one generated by <code>select_variable</code>.
</p>
</li>
<li> <p><code>selectVar_corType</code> and <code>selectVar_corMethod</code>:
</p>
<p>TIGER supports Pearson product-moment correlation (<code>"pearson"</code>) and Spearman's rank correlation (<code>"spearman"</code>) to compute correlation coefficients (<code>"cor"</code>) or partial correlation coefficients (<code>"por"</code>) for variable selection. See <code>cor</code> and <code>pcor</code> for further details.
</p>
</li>
<li> <p><code>selectVar_minNum</code> and <code>selectVar_maxNum</code>:
</p>
<p>For an objective metabolite to be corrected, the intersection of its top <em>t</em> highly-correlated metabolites calculated from training and test samples are selected to train the ensemble model. The highly-correlated metabolites are the ones with correlation coefficients greater than 0.5 (the objective metabolite itself will not be regarded as its highly-correlated metabolite). Arguments <code>selectVar_minNum</code> and <code>selectVar_maxNum</code> are used to avoid selecting too many or too few metabolites. Selecting too many metabolites can lower the process, sometimes even lower the accuracy.
</p>
</li>
<li> <p><code>selectVar_batchWise</code>:
</p>
<p>Advanced option designed for special cases. Setting it <code>TRUE</code> might be useful when your data have very obvious batch effects.
</p>
</li>
</ul>
<p><strong>Hyperparameters for model construction</strong>
</p>

<ul><li> <p><code>mtry_percent</code>, <code>nodesize_percent</code> and <code>...</code>:
</p>
<p>Advanced options to specify <code>mtry</code>, <code>nodesize</code> and other related arguments in <code>randomForest</code> for a customised ensemble learning architecture. See Examples.
</p>
</li></ul>
<h3>Value</h3>

<p>This function returns a data.frame with the same data structure as the input <code>test_samples</code>, but the metabolite values are the normalised/corrected ones. <code>NA</code> and zeros in the original <code>test_samples</code> will not be changed or normalised.
</p>


<h3>Reference</h3>

<p>Han S. <em>et al</em>. TIGER: technical variation elimination for metabolomics data using ensemble learning architecture. <em>Briefings in Bioinformatics</em> (2022) bbab535. doi: <a href="https://doi.org/10.1093/bib/bbab535">10.1093/bib/bbab535</a>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data(FF4_qc) # load demo dataset

# QC as training samples; QC1, QC2 and QC3 as test samples:
train_samples &lt;- FF4_qc[FF4_qc$sampleType == "QC",]
test_samples  &lt;- FF4_qc[FF4_qc$sampleType != "QC",]

# col_sampleID includes labels. You can assign names for different samples:
train_samples$sampleID &lt;- "train"
test_samples$sampleID  &lt;- "test"

# Use default setting and
# include injection order and well position into feature set:
test_norm_1 &lt;- run_TIGER(test_samples = test_samples,
                         train_samples = train_samples,
                         col_sampleID  = "sampleID",     # input column name
                         col_sampleType = "sampleType",  # input column name
                         col_batchID = "plateID",        # input column name
                         col_order = "injectionOrder",   # input column name
                         col_position = "wellPosition",  # input column name
                         parallel.cores = 2)

# If the information of injection order and well position is not available,
# or you don't want to use them:
train_data &lt;- train_samples[-c(4:5)]  # remove the two columns
test_data  &lt;- test_samples[-c(4:5)]   # remove the two columns

test_norm_2 &lt;- run_TIGER(test_samples = test_data,
                         train_samples = train_data,
                         col_sampleID  = "sampleID",
                         col_sampleType = "sampleType",
                         col_batchID = "plateID",
                         col_order = NULL,                # set NULL
                         col_position = NULL,             # set NULL
                         parallel.cores = 2)

# If use external target values and selected variables with
# customised settings:
target_val &lt;- compute_targetVal(QC_num = train_samples[-c(1:5)],
                                sampleType = train_samples$sampleType,
                                batchID = train_samples$plateID,
                                targetVal_method = "median",
                                targetVal_batchWise = TRUE)

select_var &lt;- select_variable(train_num = train_samples[-c(1:5)],
                              test_num = test_samples[-c(1:5)],
                              train_batchID = train_samples$plateID,
                              test_batchID = test_samples$plateID,
                              selectVar_corType = "pcor",
                              selectVar_corMethod = "spearman",
                              selectVar_minNum = 10,
                              selectVar_maxNum = 30,
                              selectVar_batchWise = TRUE)

test_norm_3 &lt;- run_TIGER(test_samples = test_samples,
                         train_samples = train_samples,
                         col_sampleID  = "sampleID",
                         col_sampleType = "sampleType",
                         col_batchID = "plateID",
                         col_order = "injectionOrder",
                         col_position = "wellPosition",
                         targetVal_external = target_val,
                         selectVar_external = select_var,
                         parallel.cores = 2)

# The definitions of other hyperparameters correspond to
# randomForest::randomForest().
# If want to include more hyperparameters into model training,
# put hyperparameter values like this:
mtry_percent &lt;- c(0.4, 0.8)
nodesize_percent &lt;- c(0.4, 0.8)
replace &lt;- c(TRUE, FALSE)
ntree &lt;- c(100, 200, 300)

test_norm_4 &lt;- run_TIGER(test_samples = test_data,
                         train_samples = train_data,
                         col_sampleID  = "sampleID",
                         col_sampleType = "sampleType",
                         col_batchID = "plateID",
                         mtry_percent = mtry_percent,
                         nodesize_percent = nodesize_percent,
                         replace = replace,
                         ntree = ntree,
                         parallel.cores = 2)

# test_norm_4 is corrected by the ensemble model consisted of base learners
# trained with (around) 24 different hyperparameter combinations:
expand.grid(mtry_percent, nodesize_percent, replace, ntree)

# Note: mtry and nodesize are calculated by mtry_percent and nodesize_percent,
#       duplicated hyperparameter combinations, if any, will be removed.
#       Thus, the total number of hyperparameter combinations can be less than 24.
#       This is determined by the shape of your input datasets.

</code></pre>


</div>