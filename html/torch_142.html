<div class="container">

<table style="width: 100%;"><tr>
<td>nnf_ctc_loss</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Ctc_loss</h2>

<h3>Description</h3>

<p>The Connectionist Temporal Classification loss.
</p>


<h3>Usage</h3>

<pre><code class="language-R">nnf_ctc_loss(
  log_probs,
  targets,
  input_lengths,
  target_lengths,
  blank = 0,
  reduction = c("mean", "sum", "none"),
  zero_infinity = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>log_probs</code></td>
<td>
<p><code class="reqn">(T, N, C)</code> where C = number of characters in alphabet including blank,
T = input length, and N = batch size. The logarithmized probabilities of
the outputs (e.g. obtained with nnf_log_softmax).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>targets</code></td>
<td>
<p><code class="reqn">(N, S)</code> or <code>(sum(target_lengths))</code>. Targets cannot be blank.
In the second form, the targets are assumed to be concatenated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>input_lengths</code></td>
<td>
<p><code class="reqn">(N)</code>. Lengths of the inputs (must each be <code class="reqn">\leq T</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>target_lengths</code></td>
<td>
<p><code class="reqn">(N)</code>. Lengths of the targets</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>blank</code></td>
<td>
<p>(int, optional) Blank label. Default <code class="reqn">0</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>reduction</code></td>
<td>
<p>(string, optional) â€“ Specifies the reduction to apply to the
output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean':
the sum of the output will be divided by the number of elements in the output,
'sum': the output will be summed. Default: 'mean'</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>zero_infinity</code></td>
<td>
<p>(bool, optional) Whether to zero infinite losses and the
associated gradients. Default: <code>FALSE</code> Infinite losses mainly occur when the
inputs are too short to be aligned to the targets.</p>
</td>
</tr>
</table>
</div>