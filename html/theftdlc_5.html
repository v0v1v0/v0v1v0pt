<div class="container">

<table style="width: 100%;"><tr>
<td>compare_features</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Conduct statistical testing on time-series feature classification performance to identify top features or compare entire sets</h2>

<h3>Description</h3>

<p>Conduct statistical testing on time-series feature classification performance to identify top features or compare entire sets
</p>


<h3>Usage</h3>

<pre><code class="language-R">compare_features(
  data,
  metric = c("accuracy", "precision", "recall", "f1"),
  by_set = TRUE,
  hypothesis = c("null", "pairwise"),
  p_adj = c("none", "holm", "hochberg", "hommel", "bonferroni", "BH", "BY", "fdr")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p><code>list</code> object containing the classification outputs produce by <code>tsfeature_classifier</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metric</code></td>
<td>
<p><code>character</code> denoting the classification performance metric to use in statistical testing. Can be one of <code>"accuracy"</code>, <code>"precision"</code>, <code>"recall"</code>, <code>"f1"</code>. Defaults to <code>"accuracy"</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>by_set</code></td>
<td>
<p><code>Boolean</code> specifying whether you want to compare feature sets (if <code>TRUE</code>) or individual features (if <code>FALSE</code>). Defaults to <code>TRUE</code> but this is contingent on whether you computed by set or not in <code>tsfeature_classifier</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hypothesis</code></td>
<td>
<p><code>character</code> denoting whether p-values should be calculated for each feature set or feature (depending on <code>by_set</code> argument) individually relative to the null if <code>use_null = TRUE</code> in <code>tsfeature_classifier</code> through <code>"null"</code>, or whether pairwise comparisons between each set or feature should be conducted on main model fits only through <code>"pairwise"</code>. Defaults to <code>"null"</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p_adj</code></td>
<td>
<p><code>character</code> denoting the adjustment made to p-values for multiple comparisons. Should be a valid argument to <code>stats::p.adjust</code>. Defaults to <code>"none"</code> for no adjustment. <code>"holm"</code> is recommended as a starting point for adjustments</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p><code>data.frame</code> containing the results
</p>


<h3>Author(s)</h3>

<p>Trent Henderson
</p>


<h3>References</h3>

<p>Henderson, T., Bryant, A. G., and Fulcher, B. D. Never a Dull Moment: Distributional Properties as a Baseline for Time-Series Classification. 27th Pacific-Asia Conference on Knowledge Discovery and Data Mining, (2023).
</p>


<h3>Examples</h3>

<pre><code class="language-R">
library(theft)

features &lt;- theft::calculate_features(theft::simData,
  group_var = "process",
  feature_set = NULL,
  features = list("mean" = mean, "sd" = sd))

classifiers &lt;- classify(features,
                        by_set = FALSE,
                        n_resamples = 3)

compare_features(classifiers,
                 by_set = FALSE,
                 hypothesis = "pairwise")

</code></pre>


</div>