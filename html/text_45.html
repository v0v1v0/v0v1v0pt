<div class="container">

<table style="width: 100%;"><tr>
<td>textSum</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Summarize texts. (experimental)</h2>

<h3>Description</h3>

<p>Summarize texts. (experimental)
</p>


<h3>Usage</h3>

<pre><code class="language-R">textSum(
  x,
  min_length = 10L,
  max_length = 20L,
  model = "t5-small",
  device = "cpu",
  tokenizer_parallelism = FALSE,
  logging_level = "warning",
  return_incorrect_results = FALSE,
  return_text = TRUE,
  return_tensors = FALSE,
  clean_up_tokenization_spaces = FALSE,
  set_seed = 202208L
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>(string)  A variable or a tibble/dataframe with at least one character variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_length</code></td>
<td>
<p>(explicit integer; e.g., 10L)  The minimum number of tokens in the summed output.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_length</code></td>
<td>
<p>(explicit integer higher than min_length; e.g., 20L)  The maximum number of tokens
in the summed output.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>(string)  Specififcation of a pre-trained language model that have been fine-tuned on a
summarization task, such as ’bart-large-cnn’, ’t5-small’, ’t5-base’, ’t5-large’, ’t5-3b’, ’t5-11b’.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>device</code></td>
<td>
<p>(string)  Device to use: 'cpu', 'gpu', or 'gpu:k' where k is a specific device number.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tokenizer_parallelism</code></td>
<td>
<p>(boolean)  If TRUE this will turn on tokenizer parallelism.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logging_level</code></td>
<td>
<p>(string)  Set the logging level.
Options (ordered from less logging to more logging): critical, error, warning, info, debug</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return_incorrect_results</code></td>
<td>
<p>(boolean)  Stop returning some incorrectly formatted/structured results.
This setting does CANOT evaluate the actual results (whether or not they make sense, exist, etc.).
All it does is to ensure the returned results are formatted correctly (e.g., does the question-answering
dictionary contain the key "answer", is sentiments from textClassify containing the labels "positive"
and "negative").</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return_text</code></td>
<td>
<p>(boolean)  Whether or not the outputs should include the decoded text.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return_tensors</code></td>
<td>
<p>(boolean)  Whether or not the output should include the prediction tensors (as token indices).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>clean_up_tokenization_spaces</code></td>
<td>
<p>(boolean)  Option to clean up the potential extra spaces in the returned text.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>set_seed</code></td>
<td>
<p>(Integer) Set seed.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A tibble with summed text(s).
</p>


<h3>See Also</h3>

<p>see <code>textClassify</code>, <code>textGeneration</code>, <code>textNER</code>,
<code>textSum</code>, <code>textQA</code>, <code>textTranslate</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# sum_examples &lt;- textSum(Language_based_assessment_data_8[1:2,1:2],
# min_length = 5L,
# max_length = 10L)

</code></pre>


</div>