<div class="container">

<table style="width: 100%;"><tr>
<td>refit.tidylda</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Update a Latent Dirichlet Allocation topic model</h2>

<h3>Description</h3>

<p>Update an LDA model using collapsed Gibbs sampling.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'tidylda'
refit(
  object,
  new_data,
  iterations = NULL,
  burnin = -1,
  prior_weight = 1,
  additional_k = 0,
  additional_eta_sum = 250,
  optimize_alpha = FALSE,
  calc_likelihood = FALSE,
  calc_r2 = FALSE,
  return_data = FALSE,
  threads = 1,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>a fitted object of class <code>tidylda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>new_data</code></td>
<td>
<p>A document term matrix or term co-occurrence matrix of class dgCMatrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iterations</code></td>
<td>
<p>Integer number of iterations for the Gibbs sampler to run.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>burnin</code></td>
<td>
<p>Integer number of burnin iterations. If <code>burnin</code> is greater than -1,
the resulting "beta" and "theta" matrices are an average over all iterations
greater than <code>burnin</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior_weight</code></td>
<td>
<p>Numeric, 0 or greater or <code>NA</code>. The weight of the 
<code>beta</code> as a prior from the base model. See Details, below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>additional_k</code></td>
<td>
<p>Integer number of topics to add, defaults to 0.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>additional_eta_sum</code></td>
<td>
<p>Numeric magnitude of prior for additional topics.
Ignored if <code>additional_k</code> is 0. Defaults to 250.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optimize_alpha</code></td>
<td>
<p>Logical. Experimental. Do you want to optimize alpha
every iteration? Defaults to <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>calc_likelihood</code></td>
<td>
<p>Logical. Do you want to calculate the log likelihood every iteration?
Useful for assessing convergence. Defaults to <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>calc_r2</code></td>
<td>
<p>Logical. Do you want to calculate R-squared after the model is trained?
Defaults to <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return_data</code></td>
<td>
<p>Logical. Do you want <code>new_data</code> returned as part of the model object?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>threads</code></td>
<td>
<p>Number of parallel threads, defaults to 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Logical. Do you want to print a progress bar out to the console?
Defaults to <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional arguments, currently unused</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>refit</code> allows you to (a) update the probabilities (i.e. weights) of
a previously-fit model with new data or additional iterations and (b) optionally
use <code>beta</code> of a previously-fit LDA topic model as the <code>eta</code> prior
for the new model. This is tuned by setting <code>beta_as_prior = FALSE</code> or
<code>beta_as_prior = TRUE</code> respectively.
</p>
<p><code>prior_weight</code> tunes how strong the base model is represented in the prior.
If <code>prior_weight = 1</code>, then the tokens from the base model's training data
have the same relative weight as tokens in <code>new_data</code>. In other words,
it is like just adding training data. If <code>prior_weight</code> is less than 1,
then tokens in <code>new_data</code> are given more weight. If <code>prior_weight</code>
is greater than 1, then the tokens from the base model's training data are
given more weight.
</p>
<p>If <code>prior_weight</code> is <code>NA</code>, then the new <code>eta</code> is equal to 
<code>eta</code> from the old model, with new tokens folded in. 
(For handling of new tokens, see below.) Effectively, this just controls
how the sampler initializes (described below), but does not give prior
weight to the base model.
</p>
<p>Instead of initializing token-topic assignments in the manner for new
models (see <code>tidylda</code>), the update initializes in 2
steps:
</p>
<p>First, topic-document probabilities (i.e. <code>theta</code>) are obtained by a
call to <code>predict.tidylda</code> using <code>method = "dot"</code>
for the documents in <code>new_data</code>. Next, both <code>beta</code> and <code>theta</code> are
passed to an internal function, <code>initialize_topic_counts</code>,
which assigns topics to tokens in a manner approximately proportional to 
the posteriors and executes a single Gibbs iteration.
</p>
<p><code>refit</code> handles the addition of new vocabulary by adding a flat prior
over new tokens. Specifically, each entry in the new prior is equal to the
10th percentile of <code>eta</code> from the old model. The resulting model will
have the total vocabulary of the old model plus any new vocabulary tokens.
In other words, after running <code>refit.tidylda</code> <code>ncol(beta) &gt;= ncol(new_data)</code>
where <code>beta</code> is from the new model and <code>new_data</code> is the additional data.
</p>
<p>You can add additional topics by setting the <code>additional_k</code> parameter
to an integer greater than zero. New entries to <code>alpha</code> have a flat
prior equal to the median value of <code>alpha</code> in the old model. (Note that
if <code>alpha</code> itself is a flat prior, i.e. scalar, then the new topics have
the same value for their prior.) New entries to <code>eta</code> have a shape 
from the average of all previous topics in <code>eta</code> and scaled by
<code>additional_eta_sum</code>.
</p>


<h3>Value</h3>

<p>Returns an S3 object of class c("tidylda").
</p>


<h3>Note</h3>

<p>Updates are, as of this writing, are almost-surely useful but their behaviors
have not been optimized or well-studied. Caveat emptor!
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# load a document term matrix
data(nih_sample_dtm)

d1 &lt;- nih_sample_dtm[1:50, ]

d2 &lt;- nih_sample_dtm[51:100, ]

# fit a model
m &lt;- tidylda(d1,
  k = 10,
  iterations = 200, burnin = 175
)

# update an existing model by adding documents using old model as prior
m2 &lt;- refit(
  object = m,
  new_data = rbind(d1, d2),
  iterations = 200,
  burnin = 175,
  prior_weight = 1
)

# use an old model to initialize new model and not use old model as prior
m3 &lt;- refit(
  object = m,
  new_data = d2, # new documents only
  iterations = 200,
  burnin = 175,
  prior_weight = NA
)

# add topics while updating a model by adding documents
m4 &lt;- refit(
  object = m,
  new_data = rbind(d1, d2),
  additional_k = 3,
  iterations = 200,
  burnin = 175
)

</code></pre>


</div>