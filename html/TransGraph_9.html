<div class="container">

<table style="width: 100%;"><tr>
<td>trans_GGMM</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Transfer learning of high-dimensional Gaussian graphical mixture models.</h2>

<h3>Description</h3>

<p>Transfer learning of high-dimensional Gaussian graphical mixture models.
</p>


<h3>Usage</h3>

<pre><code class="language-R">trans_GGMM(t.data, lambda.t, M, A.data, lambda.A.list, M.A.vec,
                  pseudo.cov="soft", cov.method="opt", cn.lam2=0.5, clambda.m=1,
                  theta.algm="cd", initial.selection="K-means", preselect.aux=0,
                  sel.type="L2", trace=FALSE )
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>t.data</code></td>
<td>
<p>The target data, a n * p matrix, where n is the sample size and p is data dimension.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.t</code></td>
<td>
<p>A list, the sequences of the tuning parameters (lambda1, lambda2, and lambda3) used in the initialization of the target domain.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>M</code></td>
<td>
<p>Int, a selected upper bound of the true numbers of subgroups in the target domain.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>A.data</code></td>
<td>
<p>The auxiliary data in K auxiliary domains, a list with K elements, each of which is a nk * p matrix, where nk is the sample size of the k-th auxiliary domain.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.A.list</code></td>
<td>
<p>A list consisting of K lists, the k-th list is the sequences of the tuning parameters (lambda1, lambda2, and lambda3) used in the initialization of the k-th auxiliary domain.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>M.A.vec</code></td>
<td>
<p>A vector composed of K integers, the k-th element is a selected upper bound of the true numbers of subgroups in the k-th auxiliary domain.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pseudo.cov</code></td>
<td>
<p>The method for calculating pseudo covariance matricex in auxiliary domains, which can be selected from "soft"(default, subgroups based on samples of soft clustering via posterior probability ) and "hard" (subgroups based on samples of hard clustering).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cov.method</code></td>
<td>
<p>The method of aggregating K auxiliary covariance matrices, which can be selected as "size" (the sum weighted by the sample sizes), "weight" (the sum weighted by the differences) or "opt" (select the optimal one).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cn.lam2</code></td>
<td>
<p>A vector or a float value: the coefficients set in tuning parameters used to solve the target precision matrix, default is cn.lam2*sqrt( log(p) / n ).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>clambda.m</code></td>
<td>
<p>The coefficients set in tuning parameters used in transfer learning for mean eatimation, and the default setting is clambda.m * sqrt( log(p) / n ).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>theta.algm</code></td>
<td>
<p>The optimization algorithm used to solve the precision, which can be selected as "admm" (ADMM algorithm) or "cd" (coordinate descent).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>initial.selection</code></td>
<td>
<p>The different initial values from two clustering methods, which can be selected from c("K-means","dbscan").</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>preselect.aux</code></td>
<td>
<p>Whether to pre-select informative auxiliary domains based on the distance between initially estimated auxiliary and target parameters. The default is 0, which means that pre-selection will not be performed. If "preselect.aux" is specified as a real number greater than zero, then the threshold value is forpreselect.aux<em>s</em>sqrt( log(p) / n ).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sel.type</code></td>
<td>
<p>If pre-selection should be performed, "sel.type" is the type of distance. The default is L2 norm, and can be specified as "L1" to use L1 norm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trace</code></td>
<td>
<p>The logical variable, whether or not to output the number of identified subgroups during the search for parameters in the initialization.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A result list including:
</p>

<dl>
<dt>res.target</dt>
<dd>
<p>A list including transfer learning results of the target domain.</p>
</dd>
<dt>res.target$opt_Mu_hat</dt>
<dd>
<p>The final estimation of means in all detected subgroups via transfer learning.</p>
</dd>
<dt>res.target$opt_Theta_hat</dt>
<dd>
<p>The final estimation of precision matrices in all detected subgroups via transfer learning.</p>
</dd>
<dt>res.target0</dt>
<dd>
<p>A list including initial results of the target domain.</p>
</dd>
<dt>res.target0$opt_Mu_hat</dt>
<dd>
<p>The initial estimation of means in all detected subgroups.</p>
</dd>
<dt>res.target0$opt_Theta_hat</dt>
<dd>
<p> The initial estimation of precision matrices in all detected subgroups.</p>
</dd>
<dt>t.res</dt>
<dd>
<p>A list including results of the transfer precision matrix for each subgroup.</p>
</dd>
</dl>
<h3>Author(s)</h3>

<p>Mingyang Ren <a href="mailto:renmingyang17@mails.ucas.ac.cn">renmingyang17@mails.ucas.ac.cn</a>.
</p>


<h3>References</h3>

<p>Ren, M. and Wang J. (2023). Local transfer learning of Gaussian graphical mixture models.
</p>


<h3>Examples</h3>

<pre><code class="language-R">"Will be supplemented in the next version."


</code></pre>


</div>