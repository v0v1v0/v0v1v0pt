<div class="container">

<table style="width: 100%;"><tr>
<td>load_savedmodel</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Load a SavedModel</h2>

<h3>Description</h3>

<p>Loads a SavedModel using the given TensorFlow session and
returns the model's graph.
</p>


<h3>Usage</h3>

<pre><code class="language-R">load_savedmodel(sess = NULL, model_dir = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>sess</code></td>
<td>
<p>The TensorFlow session. <code>NULL</code> if using Eager execution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model_dir</code></td>
<td>
<p>The path to the exported model, as a string. Defaults to
a "savedmodel" path or the latest training run.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Loading a model improves performance over multiple <code>predict_savedmodel()</code>
calls.
</p>


<h3>See Also</h3>

<p><code>export_savedmodel()</code>, <code>predict_savedmodel()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
# start session
sess &lt;- tensorflow::tf$Session()

# preload an existing model into a TensorFlow session
graph &lt;- tfdeploy::load_savedmodel(
  sess,
  system.file("models/tensorflow-mnist", package = "tfdeploy")
)

# perform prediction based on a pre-loaded model
tfdeploy::predict_savedmodel(
  list(rep(9, 784)),
  graph
)

# close session
sess$close()

## End(Not run)

</code></pre>


</div>