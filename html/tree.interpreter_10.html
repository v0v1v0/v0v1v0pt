<div class="container">

<table style="width: 100%;"><tr>
<td>tree.interpreter</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Random Forest Prediction Decomposition and Feature Importance Measure</h2>

<h3>Description</h3>

<p>An R re-implementation of the 'treeinterpreter' package on PyPI.
&lt;https://pypi.org/project/treeinterpreter/&gt;. Each prediction can be
decomposed as 'prediction = bias + feature_1_contribution + ... +
feature_n_contribution'. This decomposition is then used to calculate the
Mean Decrease Impurity (MDI) and Mean Decrease Impurity using out-of-bag
samples (MDI-oob) feature importance measures based on the work of Li et al.
(2019) &lt;arXiv:1906.10845&gt;.
</p>


<h3><code>tidyRF</code></h3>

<p>The function <code>tidyRF</code> can turn a <code>randomForest</code> or <code>ranger</code>
object into a package-agnostic random forest object. All other functions
in this package operate on such a <code>tidyRF</code> object.
</p>


<h3>The <code>featureContrib</code> and <code>trainsetBias</code> families</h3>

<p>The <code>featureContrib</code> and <code>trainsetBias</code> families can decompose the
prediction of regression/classification trees/forests into bias and feature
contribution components.
</p>


<h3>The <code>MDI</code> and <code>MDIoob</code> families</h3>

<p>The <code>MDI</code> family can calculate the good old MDI feature importance
measure, which unfortunately has some feature selection bias. MDI-oob is a
debiased MDI feature importance measure that has achieved state-of-the-art
performance in feature selection for both simulated and real data. It can be
calculated with functions from the <code>MDIoob</code> family.
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(ranger)
rfobj &lt;- ranger(mpg ~ ., mtcars, keep.inbag = TRUE)
tidy.RF &lt;- tidyRF(rfobj, mtcars[, -1], mtcars[, 1])
MDIoob(tidy.RF, mtcars[, -1], mtcars[, 1])

</code></pre>


</div>