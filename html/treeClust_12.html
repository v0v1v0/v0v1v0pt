<div class="container">

<table style="width: 100%;"><tr>
<td>treeClust</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Build a tree-based dissimilarity for clustering, and optionally
perform the clustering
</h2>

<h3>Description</h3>

<p>This function uses a set of classification or regression trees to build
an inter-point dissimilarity in which two points are similar when they
tend to fall in the same leaves of trees. The user can pass in a clustering
algorithm and/or ask for the dissimilarities or the set of trees.
</p>


<h3>Usage</h3>

<pre><code class="language-R">treeClust(dfx, d.num = 1, col.range = 1:ncol(dfx), verbose = F, 
  final.algorithm, k, control = treeClust.control(), rcontrol = rpart.control(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>dfx</code></td>
<td>

<p>Input data frame. Columns may be numeric or categorical. Missing values
are permitted.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>d.num</code></td>
<td>

<p>Integer: Dissimilarity specifier. When d.num = 1, the dissimilarity between 
two observations is the proportion of trees where they disagree. 
With d.num = 2,
those counts are weighted according to tree quality. In d.num = 3, 
dissimilarities are variable with trees, reflecting the belief that some pairs
of leaves are closer together than others. With d.num = 4, those 
dissimilarities are weighted by tree quality.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>col.range</code></td>
<td>

<p>Integer: the indices of the columns used. Defaults to all.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>

<p>If non-zero, print degugging messages to the screen.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>final.algorithm</code></td>
<td>

<p>Final algorithm, to be used to cluster the computed distances. This may
be "pam", "agnes", "clara" or "kmeans".
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>

<p>If final.algorithm is supplied, the number of clusters is required.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>

<p>List of the sort produced by <code>treeClust.control</code>, giving
specifications for the fitting routine.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rcontrol</code></td>
<td>

<p>List of the sort produced by <code>rpart.control</code>, giving
arguments for the rpart routine.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>Other arguments, to be passed to the final clustering algorithm if specified.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The treeClust approach builds a set of classification or regresion trees,
one for each variable. Trees are pruned, and those that are pruned to the
root are discarded. For each remaining tree, an observation's leaf membership
serves as the starting point for a dissimilarity measurement.
</p>


<h3>Value</h3>

<p>If control$cluster.only is TRUE, a vector of cluster assignments, as produced
by the final algorthm. Otherwise, a list with these items:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>call </code></td>
<td>
<p>The call that produced the object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>d.num </code></td>
<td>
<p>d.num, as supplied</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tbl </code></td>
<td>
<p>Two-column matrix with one row for each tree retained, giving
size and deviance ratio</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>extended.tbl </code></td>
<td>
<p>Two-column matrix like tbl, but with one row for every
variable, giving size and deviance ratio (these will be 1 and 0 for variables
whose trees were discarded</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>final.algorithm </code></td>
<td>
<p>final.algorithm, as supplied</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>final.clust </code></td>
<td>
<p>If final.algorithm is supplied, the output from the final 
clustering algorithm; otherwise, NULL</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>additional.args </code></td>
<td>
<p>Any additional arguments specified</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tree </code></td>
<td>
<p>If control$return.trees is TRUE, a list holding all the
retained trees. This can make the resulting object very large.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dists </code></td>
<td>
<p>If control$return.dists is TRUE, an object of class dist
with the set of pairwise inter-point dissimilarities</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mat </code></td>
<td>
<p>If control$return.mat is TRUE, a data frame. If final.algorithm is
"pam" or "agnes" this contains leaf assignment indices. Otherwise this 
holds a dataset useful as input to k-means or clara. Experimental.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Sam Buttrey, buttrey@nps.edu
</p>


<h3>References</h3>

<p>Buttrey and Whitaker, "treeClust: An R Package for Tree-Based Clustering
Dissimilarities," The R Journal, 7/2, 2015.
</p>


<h3>See Also</h3>

<p><code>treeClust.control</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">iris.km6 &lt;- treeClust (iris[,-5], d.num = 2, final.algorithm = "kmeans", k=6)
table (iris.km6$final.clust$cluster, iris$Species)
</code></pre>


</div>