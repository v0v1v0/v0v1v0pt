<div class="container">

<table style="width: 100%;"><tr>
<td>tfd_gaussian_process_regression_model</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Posterior predictive distribution in a conjugate GP regression model.</h2>

<h3>Description</h3>

<p>Posterior predictive distribution in a conjugate GP regression model.
</p>


<h3>Usage</h3>

<pre><code class="language-R">tfd_gaussian_process_regression_model(
  kernel,
  index_points = NULL,
  observation_index_points = NULL,
  observations = NULL,
  observation_noise_variance = 0,
  predictive_noise_variance = NULL,
  mean_fn = NULL,
  jitter = 1e-06,
  validate_args = FALSE,
  allow_nan_stats = FALSE,
  name = "GaussianProcessRegressionModel"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>kernel</code></td>
<td>
<p><code>PositiveSemidefiniteKernel</code>-like instance representing the
GP's covariance function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>index_points</code></td>
<td>
<p><code>float</code> <code>Tensor</code> representing finite (batch of) vector(s) of
points in the index set over which the GP is defined. Shape has the
form <code style="white-space: pre;">⁠[b1, ..., bB, e1, f1, ..., fF]⁠</code> where <code>F</code> is the number of feature
dimensions and must equal <code>kernel$feature_ndims</code> and <code>e1</code> is the number
(size) of index points in each batch (we denote it <code>e1</code> to distinguish
it from the numer of inducing index points, denoted <code>e2</code> below).
Ultimately the GaussianProcess distribution corresponds to an
<code>e1</code>-dimensional multivariate normal. The batch shape must be
broadcastable with <code>kernel$batch_shape</code>, the batch shape of
<code>inducing_index_points</code>, and any batch dims yielded by <code>mean_fn</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>observation_index_points</code></td>
<td>
<p>Tensor representing finite collection, or batch
of collections, of points in the index set for which some data has been observed.
Shape has the form [b1, ..., bB, e, f1, ..., fF] where F is the number of
feature dimensions and must equal <code>kernel$feature_ndims</code>, and e is the number
(size) of index points in each batch. [b1, ..., bB, e] must be broadcastable
with the shape of observations, and [b1, ..., bB] must be broadcastable with
the shapes of all other batched parameters (kernel.batch_shape, index_points, etc).
The default value is None, which corresponds to the empty set of observations,
and simply results in the prior predictive model (a GP with noise of variance
<code>predictive_noise_variance</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>observations</code></td>
<td>
<p>Tensor representing collection, or batch of collections,
of observations corresponding to observation_index_points. Shape has the
form [b1, ..., bB, e], which must be brodcastable with the batch and example
shapes of observation_index_points. The batch shape [b1, ..., bB\ ] must be
broadcastable with the shapes of all other batched parameters (kernel.batch_shape,
index_points, etc.). The default value is None, which corresponds to the empty
set of observations, and simply results in the prior predictive model (a GP
with noise of variance <code>predictive_noise_variance</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>observation_noise_variance</code></td>
<td>
<p><code>float</code> <code>Tensor</code> representing the variance
of the noise in the Normal likelihood distribution of the model. May be
batched, in which case the batch shape must be broadcastable with the
shapes of all other batched parameters (<code>kernel$batch_shape</code>, <code>index_points</code>, etc.).
Default value: <code>0.</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>predictive_noise_variance</code></td>
<td>
<p>Tensor representing the variance in the posterior
predictive model. If None, we simply re-use observation_noise_variance for the
posterior predictive noise. If set explicitly, however, we use this value. This
allows us, for example, to omit predictive noise variance (by setting this to zero)
to obtain noiseless posterior predictions of function values, conditioned on noisy
observations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mean_fn</code></td>
<td>
<p>callable that acts on <code>index_points</code> to produce a collection, or
batch of collections, of mean values at index_points. Takes a Tensor of shape
[b1, ..., bB, f1, ..., fF] and returns a Tensor whose shape is broadcastable
with [b1, ..., bB]. Default value: None implies the constant zero function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>jitter</code></td>
<td>
<p><code>float</code> scalar <code>Tensor</code> added to the diagonal of the covariance
matrix to ensure positive definiteness of the covariance matrix. Default value: <code>1e-6</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>validate_args</code></td>
<td>
<p>Logical, default FALSE. When TRUE distribution parameters are checked
for validity despite possibly degrading runtime performance. When FALSE invalid inputs may
silently render incorrect outputs. Default value: FALSE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>allow_nan_stats</code></td>
<td>
<p>Logical, default TRUE. When TRUE, statistics (e.g., mean, mode, variance)
use the value NaN to indicate the result is undefined. When FALSE, an exception is raised if
one or more of the statistic's batch members are undefined.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>name prefixed to Ops created by this class.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a distribution instance.
</p>


<h3>See Also</h3>

<p>For usage examples see e.g. <code>tfd_sample()</code>, <code>tfd_log_prob()</code>, <code>tfd_mean()</code>.
</p>
<p>Other distributions: 
<code>tfd_autoregressive()</code>,
<code>tfd_batch_reshape()</code>,
<code>tfd_bates()</code>,
<code>tfd_bernoulli()</code>,
<code>tfd_beta_binomial()</code>,
<code>tfd_beta()</code>,
<code>tfd_binomial()</code>,
<code>tfd_categorical()</code>,
<code>tfd_cauchy()</code>,
<code>tfd_chi2()</code>,
<code>tfd_chi()</code>,
<code>tfd_cholesky_lkj()</code>,
<code>tfd_continuous_bernoulli()</code>,
<code>tfd_deterministic()</code>,
<code>tfd_dirichlet_multinomial()</code>,
<code>tfd_dirichlet()</code>,
<code>tfd_empirical()</code>,
<code>tfd_exp_gamma()</code>,
<code>tfd_exp_inverse_gamma()</code>,
<code>tfd_exponential()</code>,
<code>tfd_gamma_gamma()</code>,
<code>tfd_gamma()</code>,
<code>tfd_gaussian_process()</code>,
<code>tfd_generalized_normal()</code>,
<code>tfd_geometric()</code>,
<code>tfd_gumbel()</code>,
<code>tfd_half_cauchy()</code>,
<code>tfd_half_normal()</code>,
<code>tfd_hidden_markov_model()</code>,
<code>tfd_horseshoe()</code>,
<code>tfd_independent()</code>,
<code>tfd_inverse_gamma()</code>,
<code>tfd_inverse_gaussian()</code>,
<code>tfd_johnson_s_u()</code>,
<code>tfd_joint_distribution_named_auto_batched()</code>,
<code>tfd_joint_distribution_named()</code>,
<code>tfd_joint_distribution_sequential_auto_batched()</code>,
<code>tfd_joint_distribution_sequential()</code>,
<code>tfd_kumaraswamy()</code>,
<code>tfd_laplace()</code>,
<code>tfd_linear_gaussian_state_space_model()</code>,
<code>tfd_lkj()</code>,
<code>tfd_log_logistic()</code>,
<code>tfd_log_normal()</code>,
<code>tfd_logistic()</code>,
<code>tfd_mixture_same_family()</code>,
<code>tfd_mixture()</code>,
<code>tfd_multinomial()</code>,
<code>tfd_multivariate_normal_diag_plus_low_rank()</code>,
<code>tfd_multivariate_normal_diag()</code>,
<code>tfd_multivariate_normal_full_covariance()</code>,
<code>tfd_multivariate_normal_linear_operator()</code>,
<code>tfd_multivariate_normal_tri_l()</code>,
<code>tfd_multivariate_student_t_linear_operator()</code>,
<code>tfd_negative_binomial()</code>,
<code>tfd_normal()</code>,
<code>tfd_one_hot_categorical()</code>,
<code>tfd_pareto()</code>,
<code>tfd_pixel_cnn()</code>,
<code>tfd_poisson_log_normal_quadrature_compound()</code>,
<code>tfd_poisson()</code>,
<code>tfd_power_spherical()</code>,
<code>tfd_probit_bernoulli()</code>,
<code>tfd_quantized()</code>,
<code>tfd_relaxed_bernoulli()</code>,
<code>tfd_relaxed_one_hot_categorical()</code>,
<code>tfd_sample_distribution()</code>,
<code>tfd_sinh_arcsinh()</code>,
<code>tfd_skellam()</code>,
<code>tfd_spherical_uniform()</code>,
<code>tfd_student_t_process()</code>,
<code>tfd_student_t()</code>,
<code>tfd_transformed_distribution()</code>,
<code>tfd_triangular()</code>,
<code>tfd_truncated_cauchy()</code>,
<code>tfd_truncated_normal()</code>,
<code>tfd_uniform()</code>,
<code>tfd_variational_gaussian_process()</code>,
<code>tfd_vector_diffeomixture()</code>,
<code>tfd_vector_exponential_diag()</code>,
<code>tfd_vector_exponential_linear_operator()</code>,
<code>tfd_vector_laplace_diag()</code>,
<code>tfd_vector_laplace_linear_operator()</code>,
<code>tfd_vector_sinh_arcsinh_diag()</code>,
<code>tfd_von_mises_fisher()</code>,
<code>tfd_von_mises()</code>,
<code>tfd_weibull()</code>,
<code>tfd_wishart_linear_operator()</code>,
<code>tfd_wishart_tri_l()</code>,
<code>tfd_wishart()</code>,
<code>tfd_zipf()</code>
</p>


</div>