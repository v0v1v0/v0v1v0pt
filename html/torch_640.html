<div class="container">

<table style="width: 100%;"><tr>
<td>torch_quantize_per_channel</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Quantize_per_channel</h2>

<h3>Description</h3>

<p>Quantize_per_channel
</p>


<h3>Usage</h3>

<pre><code class="language-R">torch_quantize_per_channel(self, scales, zero_points, axis, dtype)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>self</code></td>
<td>
<p>(Tensor) float tensor to quantize</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scales</code></td>
<td>
<p>(Tensor) float 1D tensor of scales to use, size should match <code>input.size(axis)</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>zero_points</code></td>
<td>
<p>(int) integer 1D tensor of offset to use, size should match <code>input.size(axis)</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>axis</code></td>
<td>
<p>(int) dimension on which apply per-channel quantization</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dtype</code></td>
<td>
<p>(<code>torch.dtype</code>) the desired data type of returned tensor.        Has to be one of the quantized dtypes: <code>torch_quint8</code>, <code>torch.qint8</code>, <code>torch.qint32</code></p>
</td>
</tr>
</table>
<h3>quantize_per_channel(input, scales, zero_points, axis, dtype) -&gt; Tensor </h3>

<p>Converts a float tensor to per-channel quantized tensor with given scales and zero points.
</p>


<h3>Examples</h3>

<pre><code class="language-R">if (torch_is_installed()) {
x = torch_tensor(matrix(c(-1.0, 0.0, 1.0, 2.0), ncol = 2, byrow = TRUE))
torch_quantize_per_channel(x, torch_tensor(c(0.1, 0.01)), 
                           torch_tensor(c(10L, 0L)), 0, torch_quint8())
torch_quantize_per_channel(x, torch_tensor(c(0.1, 0.01)), 
                           torch_tensor(c(10L, 0L)), 0, torch_quint8())$int_repr()
}
</code></pre>


</div>