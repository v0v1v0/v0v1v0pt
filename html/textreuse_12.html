<div class="container">

<table style="width: 100%;"><tr>
<td>TextReuseTextDocument</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>TextReuseTextDocument</h2>

<h3>Description</h3>

<p>This is the constructor function for <code>TextReuseTextDocument</code> objects.
This class is used for comparing documents.
</p>


<h3>Usage</h3>

<pre><code class="language-R">TextReuseTextDocument(
  text,
  file = NULL,
  meta = list(),
  tokenizer = tokenize_ngrams,
  ...,
  hash_func = hash_string,
  minhash_func = NULL,
  keep_tokens = FALSE,
  keep_text = TRUE,
  skip_short = TRUE
)

is.TextReuseTextDocument(x)

has_content(x)

has_tokens(x)

has_hashes(x)

has_minhashes(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>text</code></td>
<td>
<p>A character vector containing the text of the document. This
argument can be skipped if supplying <code>file</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>file</code></td>
<td>
<p>The path to a text file, if <code>text</code> is not provided.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>meta</code></td>
<td>
<p>A list with named elements for the metadata associated with this
document. If a document is created using the <code>text</code> parameter, then
you must provide an <code>id</code> field, e.g., <code>meta = list(id =
"my_id")</code>. If the document is created using <code>file</code>, then the ID will
be created from the file name.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tokenizer</code></td>
<td>
<p>A function to split the text into tokens. See
<code>tokenizers</code>. If value is <code>NULL</code>, then tokenizing and
hashing will be skipped.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Arguments passed on to the <code>tokenizer</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hash_func</code></td>
<td>
<p>A function to hash the tokens. See
<code>hash_string</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>minhash_func</code></td>
<td>
<p>A function to create minhash signatures of the document.
See <code>minhash_generator</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keep_tokens</code></td>
<td>
<p>Should the tokens be saved in the document that is
returned or discarded?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keep_text</code></td>
<td>
<p>Should the text be saved in the document that is returned or
discarded?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>skip_short</code></td>
<td>
<p>Should short documents be skipped? (See details.)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>An R object to check.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This constructor function follows a three-step process. It reads in
the text, either from a file or from memory. It then tokenizes that text.
Then it hashes the tokens. Most of the comparison functions in this package
rely only on the hashes to make the comparison. By passing <code>FALSE</code> to
<code>keep_tokens</code> and <code>keep_text</code>, you can avoid saving those
objects, which can result in significant memory savings for large corpora.
</p>
<p>If <code>skip_short = TRUE</code>, this function will return <code>NULL</code> for very
short or empty documents. A very short document is one where there are two
few words to create at least two n-grams. For example, if five-grams are
desired, then a document must be at least six words long. If no value of
<code>n</code> is provided, then the function assumes a value of <code>n = 3</code>. A
warning will be printed with the document ID of a skipped document.
</p>


<h3>Value</h3>

<p>An object of class <code>TextReuseTextDocument</code>. This object inherits
from the virtual S3 class <code>TextDocument</code> in the NLP
package. It contains the following elements: </p>
 <dl>
<dt>content</dt>
<dd>
<p>The
text of the document.</p>
</dd> <dt>tokens</dt>
<dd>
<p>The tokens created from the text.</p>
</dd>
<dt>hashes</dt>
<dd>
<p>Hashes created from the tokens.</p>
</dd> <dt>minhashes</dt>
<dd>
<p>The minhash
signature of the document.</p>
</dd> <dt>metadata</dt>
<dd>
<p>The document metadata,
including the filename (if any) in <code>file</code>.</p>
</dd> </dl>
<h3>See Also</h3>

<p>Accessors for TextReuse
objects.
</p>


<h3>Examples</h3>

<pre><code class="language-R">file &lt;- system.file("extdata/legal/ny1850-match.txt", package = "textreuse")
doc  &lt;- TextReuseTextDocument(file = file, meta = list(id = "ny1850"))
print(doc)
meta(doc)
head(tokens(doc))
head(hashes(doc))
## Not run: 
content(doc)

## End(Not run)
</code></pre>


</div>