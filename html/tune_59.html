<div class="container">

<table style="width: 100%;"><tr>
<td>control_grid</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Control aspects of the grid search process</h2>

<h3>Description</h3>

<p>Control aspects of the grid search process
</p>


<h3>Usage</h3>

<pre><code class="language-R">control_grid(
  verbose = FALSE,
  allow_par = TRUE,
  extract = NULL,
  save_pred = FALSE,
  pkgs = NULL,
  save_workflow = FALSE,
  event_level = "first",
  parallel_over = NULL,
  backend_options = NULL
)

control_resamples(
  verbose = FALSE,
  allow_par = TRUE,
  extract = NULL,
  save_pred = FALSE,
  pkgs = NULL,
  save_workflow = FALSE,
  event_level = "first",
  parallel_over = NULL,
  backend_options = NULL
)

new_backend_options(..., class = character())
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>A logical for logging results (other than warnings and errors,
which are always shown) as they are generated during training in a single
R process. When using most parallel backends, this argument typically will
not result in any logging. If using a dark IDE theme, some logging messages
might be hard to see; try setting the <code>tidymodels.dark</code> option with
<code>options(tidymodels.dark = TRUE)</code> to print lighter colors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>allow_par</code></td>
<td>
<p>A logical to allow parallel processing (if a parallel
backend is registered).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>extract</code></td>
<td>
<p>An optional function with at least one argument (or <code>NULL</code>)
that can be used to retain arbitrary objects from the model fit object,
recipe, or other elements of the workflow.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>save_pred</code></td>
<td>
<p>A logical for whether the out-of-sample predictions should
be saved for each model <em>evaluated</em>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pkgs</code></td>
<td>
<p>An optional character string of R package names that should be
loaded (by namespace) during parallel processing.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>save_workflow</code></td>
<td>
<p>A logical for whether the workflow should be appended
to the output as an attribute.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>event_level</code></td>
<td>
<p>A single string containing either <code>"first"</code> or <code>"second"</code>.
This argument is passed on to yardstick metric functions when any type
of class prediction is made, and specifies which level of the outcome
is considered the "event".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parallel_over</code></td>
<td>
<p>A single string containing either <code>"resamples"</code> or
<code>"everything"</code> describing how to use parallel processing. Alternatively,
<code>NULL</code> is allowed, which chooses between <code>"resamples"</code> and <code>"everything"</code>
automatically.
</p>
<p>If <code>"resamples"</code>, then tuning will be performed in parallel over resamples
alone. Within each resample, the preprocessor (i.e. recipe or formula) is
processed once, and is then reused across all models that need to be fit.
</p>
<p>If <code>"everything"</code>, then tuning will be performed in parallel at two levels.
An outer parallel loop will iterate over resamples. Additionally, an
inner parallel loop will iterate over all unique combinations of
preprocessor and model tuning parameters for that specific resample. This
will result in the preprocessor being re-processed multiple times, but
can be faster if that processing is extremely fast.
</p>
<p>If <code>NULL</code>, chooses <code>"resamples"</code> if there are more than one resample,
otherwise chooses <code>"everything"</code> to attempt to maximize core utilization.
</p>
<p>Note that switching between <code>parallel_over</code> strategies is not guaranteed
to use the same random number generation schemes. However, re-tuning a
model using the same <code>parallel_over</code> strategy is guaranteed to be
reproducible between runs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>backend_options</code></td>
<td>
<p>An object of class <code>"tune_backend_options"</code> as created
by <code>tune::new_backend_options()</code>, used to pass arguments to specific tuning
backend. Defaults to <code>NULL</code> for default backend options.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>For <code>extract</code>, this function can be used to output the model object, the
recipe (if used), or some components of either or both. When evaluated, the
function's sole argument has a fitted workflow If the formula method is used,
the recipe element will be <code>NULL</code>.
</p>
<p>The results of the <code>extract</code> function are added to a list column in the
output called <code>.extracts</code>. Each element of this list is a tibble with tuning
parameter column and a list column (also called <code>.extracts</code>) that contains
the results of the function. If no extraction function is used, there is no
<code>.extracts</code> column in the resulting object. See <code>tune_bayes()</code> for more
specific details.
</p>
<p>Note that for <code>collect_predictions()</code>, it is possible that each row of the
original data point might be represented multiple times per tuning
parameter. For example, if the bootstrap or repeated cross-validation are
used, there will be multiple rows since the sample data point has been
evaluated multiple times. This may cause issues when merging the predictions
with the original data.
</p>
<p><code>control_resamples()</code> is an alias for <code>control_grid()</code> and is meant to be
used with <code>fit_resamples()</code>.
</p>


<h3>Hyperparameters and extracted objects</h3>

<p>When making use of submodels, tune can generate predictions and calculate
metrics for multiple model <code>.config</code>urations using only one model fit.
However, this means that if a function was supplied to a
control function's <code>extract</code> argument, tune can only
execute that extraction on the one model that was fitted. As a result,
in the <code>collect_extracts()</code> output, tune opts to associate the
extracted objects with the hyperparameter combination used to
fit that one model workflow, rather than the hyperparameter
combination of a submodel. In the output, this appears like
a hyperparameter entry is recycled across many <code>.config</code>
entriesâ€”this is intentional.
</p>
<p>See <a href="https://parsnip.tidymodels.org/articles/Submodels.html">https://parsnip.tidymodels.org/articles/Submodels.html</a> to learn
more about submodels.
</p>


</div>