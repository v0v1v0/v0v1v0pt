<div class="container">

<table style="width: 100%;"><tr>
<td>textPredict</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Trained models created by e.g., textTrain() or stored on e.g., github can be used to predict
new scores or classes from embeddings or text using textPredict.</h2>

<h3>Description</h3>

<p>Trained models created by e.g., textTrain() or stored on e.g., github can be used to predict
new scores or classes from embeddings or text using textPredict.
</p>


<h3>Usage</h3>

<pre><code class="language-R">textPredict(
  model_info = NULL,
  word_embeddings = NULL,
  texts = NULL,
  x_append = NULL,
  type = NULL,
  dim_names = TRUE,
  save_model = TRUE,
  threshold = NULL,
  show_texts = FALSE,
  device = "cpu",
  participant_id = NULL,
  save_embeddings = TRUE,
  save_dir = "wd",
  save_name = "textPredict",
  story_id = NULL,
  dataset_to_merge_predictions = NULL,
  previous_sentence = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model_info</code></td>
<td>
<p>(character or r-object) model_info has four options. 1: R model object
(e.g, saved output from textTrainRegression). 2: Link to a model stored in a github repo
(e.g, "https://github.com/CarlViggo/pretrained_swls_model/raw/main/trained_github_model_logistic.RDS").
3: Link to a model stored in a osf project (e.g, https://osf.io/8fp7v).
4: Path to a model stored locally (e.g, "path/to/your/model"). Information about some accessible models
can be found at: <a href="https://r-text.org/articles/pre_trained_models.html">r-text.org</a>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>word_embeddings</code></td>
<td>
<p>(tibble) Embeddings from e.g., textEmbed(). If you're using a pre-trained model,
then texts and embeddings cannot be submitted simultaneously (default = NULL).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>texts</code></td>
<td>
<p>(character) Text to predict. If this argument is specified, then arguments "word_embeddings"
and "premade embeddings" cannot be defined (default = NULL).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x_append</code></td>
<td>
<p>(tibble) Variables to be appended after the word embeddings (x).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>(character) Defines what output to give after logistic regression prediction.
Either probabilities, classifications or both are returned (default = "class".
For probabilities use "prob". For both use "class_prob").</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dim_names</code></td>
<td>
<p>(boolean) Account for specific dimension names from textEmbed()
(rather than generic names including Dim1, Dim2 etc.). If FALSE the models need to have been trained on
word embeddings created with dim_names FALSE, so that embeddings were only called Dim1, Dim2 etc.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>save_model</code></td>
<td>
<p>(boolean) The model will by default be saved in your work-directory (default = TRUE).
If the model already exists in your work-directory, it will automatically be loaded from there.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>threshold</code></td>
<td>
<p>(numeric) Determine threshold if you are using a logistic model (default = 0.5).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>show_texts</code></td>
<td>
<p>(boolean) Show texts together with predictions (default = FALSE).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>device</code></td>
<td>
<p>Name of device to use: 'cpu', 'gpu', 'gpu:k' or 'mps'/'mps:k' for MacOS, where k is a
specific device number such as 'mps:1'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>participant_id</code></td>
<td>
<p>(list) Vector of participant-ids. Specify this for getting person level scores
(i.e., summed sentence probabilities to the person level corrected for word count). (default = NULL)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>save_embeddings</code></td>
<td>
<p>(boolean) If set to TRUE, embeddings will be saved with a unique identifier, and
will be automatically opened next time textPredict is run with the same text. (default = TRUE)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>save_dir</code></td>
<td>
<p>(character) Directory to save embeddings. (default = "wd" (i.e, work-directory))</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>save_name</code></td>
<td>
<p>(character) Name of the saved embeddings (will be combined with a unique identifier).
(default = ""). Obs: If no save_name is provided, and model_info is a character, then save_name will be set
to model_info.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>story_id</code></td>
<td>
<p>(vector) Vector of story-ids. Specify this to get story level scores (i.e., summed sentence
probabilities corrected for word count). When there is both story_id and participant_id indicated, the function
returns a list including both story level and person level prediction corrected for word count. (default = NULL)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dataset_to_merge_predictions</code></td>
<td>
<p>(R-object, tibble) Insert your data here to integrate predictions to your dataset,
(default = NULL).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>previous_sentence</code></td>
<td>
<p>If set to TRUE, word-embeddings will be averaged over the current and previous
sentence per story-id. For this, both participant-id and story-id must be specified.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Setting from stats::predict can be called.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Predictions from word-embedding or text input.
</p>


<h3>See Also</h3>

<p>See <code>textTrain</code>, <code>textTrainLists</code> and
<code>textTrainRandomForest</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 

# Text data from Language_based_assessment_data_8
text_to_predict &lt;- "I am not in harmony in my life as much as I would like to be."

# Example 1: (predict using pre-made embeddings and an R model-object)
prediction1 &lt;- textPredict(
  model_info = trained_model,
  word_embeddings_4$texts$satisfactiontexts
)

# Example 2: (predict using a pretrained github model)
prediction2 &lt;- textPredict(
  texts = text_to_predict,
  model_info = "https://github.com/CarlViggo/pretrained-models/raw/main/trained_hils_model.RDS"
)

# Example 3: (predict using a pretrained logistic github model and return
# probabilities and classifications)
prediction3 &lt;- textPredict(
  texts = text_to_predict,
  model_info = "https://github.com/CarlViggo/pretrained-models/raw/main/
  trained_github_model_logistic.RDS",
  type = "class_prob",
  threshold = 0.7
)

# Example 4: (predict from texts using a pretrained model stored in an osf project)
prediction4 &lt;- textPredict(
  texts = text_to_predict,
  model_info = "https://osf.io/8fp7v"
)
##### Automatic implicit motive coding section ######

# Create example dataset
implicit_motive_data &lt;- dplyr::mutate(.data = Language_based_assessment_data_8,
participant_id = dplyr::row_number())

# Code implicit motives.
implicit_motives &lt;- textPredict(
  texts = implicit_motive_data$satisfactiontexts,
  model_info = "implicit_power_roberta_large_L23_v1",
  participant_id = implicit_motive_data$participant_id,
  dataset_to_merge_predictions = implicit_motive_data
)

# Examine results
implicit_motives$sentence_predictions
implicit_motives$person_predictions

## End(Not run)

## Not run: 
# Examine the correlation between the predicted values and
# the Satisfaction with life scale score (pre-included in text).

psych::corr.test(
  predictions1$word_embeddings__ypred,
  Language_based_assessment_data_8$swlstotal
)

## End(Not run)
</code></pre>


</div>